# LLMé…ç½®æ–‡ä»¶
llm:
  # é»˜è®¤é…ç½®
  default:
    primary_provider: "ollama_local"  # ğŸ”¥ åˆ‡æ¢åˆ°æœ¬åœ°æ¨¡å‹
    fallback_provider: "deepseek"     # äº‘ç«¯æ¨¡å‹ä½œä¸ºå¤‡ç”¨
    cache_enabled: true
    cache_ttl: "30m"
    max_retries: 3
    timeout_seconds: 120  # ğŸ”¥ ä¿®å¤ï¼šå¢åŠ åˆ°120ç§’ï¼Œé€‚åº”å¤æ‚LLMåˆ†æ
    enable_routing: true

  # æä¾›å•†é…ç½®
  providers:
    openai:
      api_key: "${OPENAI_API_KEY}"
      base_url: "https://api.openai.com/v1"
      model: "gpt-3.5-turbo"
      max_retries: 3
      timeout: "120s"  # å¢åŠ åˆ°120ç§’
      rate_limit: 60
      extra:
        organization: ""

    claude:
      api_key: "${CLAUDE_API_KEY}"
      base_url: "https://api.anthropic.com/v1"
      model: "claude-3-sonnet-20240229"
      max_retries: 3
      timeout: "120s"  # å¢åŠ åˆ°120ç§’
      rate_limit: 60
      extra:
        version: "2023-06-01"

    qianwen:
      api_key: "${QIANWEN_API_KEY}"
      base_url: "https://dashscope.aliyuncs.com/api/v1"
      model: "qwen-turbo"
      max_retries: 3
      timeout: "120s"  # å¢åŠ åˆ°120ç§’
      rate_limit: 60
      extra:
        region: "cn-beijing"

    deepseek:
      api_key: "${DEEPSEEK_API_KEY}"
      base_url: "https://api.deepseek.com/v1"
      model: "deepseek-chat"
      max_retries: 3
      timeout: "120s"  # å¢åŠ åˆ°120ç§’ï¼Œé€‚åº”å¤æ‚LLMåˆ†æ
      rate_limit: 6000  # æµ‹è¯•ç¯å¢ƒæ”¾å®½åˆ°6000 RPM (100 RPS)
      extra:
        stream: false

    # ğŸ†• Ollamaæœ¬åœ°æ¨¡å‹ç»Ÿä¸€é…ç½®
    ollama_local:
      api_key: ""  # æœ¬åœ°æ¨¡å‹ä¸éœ€è¦API Key
      base_url: "http://localhost:11434"
      model: "deepseek-coder-v2:16b"  # é»˜è®¤æ¨¡å‹ï¼Œå¯é€šè¿‡é…ç½®åˆ‡æ¢
      max_retries: 3
      timeout: "60s"  # æœ¬åœ°æ¨¡å‹å“åº”æ›´å¿«
      rate_limit: 0   # æœ¬åœ°æ— é™æµé™åˆ¶
      extra:
        available_models:
          - "codeqwen:7b"
          - "deepseek-coder:33b"
          - "deepseek-coder:33b-instruct"
          - "deepseek-coder:6.7b-instruct"
          - "deepseek-coder:6.7b"
          - "deepseek-coder-v2:16b"
        model_descriptions:
          "codeqwen:7b": "CodeQwen 7B - ä»£ç ç”Ÿæˆå’Œç†è§£ä¸“ç”¨"
          "deepseek-coder:33b": "DeepSeek Coder 33B - é«˜æ€§èƒ½ä»£ç æ¨¡å‹"
          "deepseek-coder:33b-instruct": "DeepSeek Coder 33B Instruct - æŒ‡ä»¤ä¼˜åŒ–ç‰ˆæœ¬"
          "deepseek-coder:6.7b-instruct": "DeepSeek Coder 6.7B Instruct - å¹³è¡¡æ€§èƒ½ç‰ˆæœ¬"
          "deepseek-coder:6.7b": "DeepSeek Coder 6.7B - åŸºç¡€ä»£ç æ¨¡å‹"
          "deepseek-coder-v2:16b": "DeepSeek Coder V2 16B - æ–°ä¸€ä»£ä»£ç æ¨¡å‹"

  # è·¯ç”±è§„åˆ™
  routing:
    three_elements_analysis:
      primary: "deepseek"  # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨deepseekè€Œä¸æ˜¯claude
      fallback: ["openai", "claude"]
      conditions:
        accuracy_required: true
        max_latency_ms: 5000

    query_rewrite:
      primary: "deepseek"  # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨deepseekè€Œä¸æ˜¯qianwen
      fallback: ["openai", "claude"]
      conditions:
        speed_required: true
        max_latency_ms: 2000

    code_analysis:
      primary: "deepseek"
      fallback: ["openai"]
      conditions:
        code_understanding: true
        max_latency_ms: 3000

    default:
      primary: "ollama_local"  # ğŸ”¥ é»˜è®¤ä½¿ç”¨æœ¬åœ°æ¨¡å‹
      fallback: ["deepseek", "openai", "claude"]

    # ğŸ†• æœ¬åœ°æ¨¡å‹è·¯ç”±è§„åˆ™
    local_code_analysis:
      primary: "ollama_local"  # ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿›è¡Œä»£ç åˆ†æ
      fallback: ["deepseek", "openai"]
      conditions:
        local_preferred: true
        code_understanding: true
        cost_sensitive: true

  # Prompté…ç½®
  prompt:
    default_language: "zh-CN"
    max_tokens: 4096
    temperature: 0.7
    custom_vars:
      company_name: "Context-Keeper"
      product_name: "æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å¹³å°"
