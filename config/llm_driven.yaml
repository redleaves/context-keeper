# Context-Keeper LLMé©±åŠ¨æ™ºèƒ½åŒ–é…ç½®æ–‡ä»¶
# ğŸ”¥ é»˜è®¤å…³é—­æ‰€æœ‰æ–°åŠŸèƒ½ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§

# æ€»å¼€å…³
enabled: true   # ğŸ”¥ å¼€å¯LLMé©±åŠ¨æ™ºèƒ½åŠŸèƒ½

# åŠŸèƒ½å¼€å…³
features:
  semantic_analysis: true     # è¯­æ–™åˆ†æå¼•æ“
  multi_dimensional: true     # å¤šç»´åº¦æ£€ç´¢å¼•æ“
  content_synthesis: true     # å†…å®¹åˆæˆå¼•æ“
  context_updates: false      # ä¸Šä¸‹æ–‡æ›´æ–°åŠŸèƒ½æš‚æ—¶å…³é—­

# é™çº§ç­–ç•¥
fallback:
  enable_auto_fallback: true  # å¯ç”¨è‡ªåŠ¨é™çº§
  fallback_threshold: 3       # è¿ç»­å¤±è´¥3æ¬¡åè‡ªåŠ¨é™çº§
  max_retries: 2              # æœ€å¤§é‡è¯•æ¬¡æ•°

# LLMé…ç½®
llm:
  provider: "openai"          # LLMæä¾›å•†
  model: "gpt-4"              # ä½¿ç”¨çš„æ¨¡å‹
  max_tokens: 4000            # æœ€å¤§Tokenæ•°
  temperature: 0.1            # æ¸©åº¦å‚æ•°
  timeout: 30                 # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

# å­˜å‚¨é…ç½®
storage:
  timeline_db:
    enabled: false            # TimescaleDBé›†æˆæš‚æ—¶å…³é—­
    connection_string: ""
  
  knowledge_graph:
    enabled: false            # Neo4jé›†æˆæš‚æ—¶å…³é—­
    connection_string: ""

# ğŸ†• æ™ºèƒ½å­˜å‚¨é…ç½®
smart_storage:
  # ç½®ä¿¡åº¦é˜ˆå€¼é…ç½®
  confidence_thresholds:
    timeline_storage: 0.7           # æ—¶é—´çº¿å­˜å‚¨é˜ˆå€¼
    knowledge_graph_storage: 0.6    # çŸ¥è¯†å›¾è°±å­˜å‚¨é˜ˆå€¼
    vector_storage: 0.5             # å‘é‡å­˜å‚¨é˜ˆå€¼
    context_only_threshold: 0.7     # ä»…ä¸Šä¸‹æ–‡è®°å½•é˜ˆå€¼ï¼ˆè°ƒæ•´åˆ°0.7ï¼‰

  # å¤šå‘é‡é…ç½®
  multi_vector:
    enabled_dimensions:             # å¯ç”¨çš„ç»´åº¦
      - "core_intent"               # æ ¸å¿ƒæ„å›¾ç»´åº¦
      - "domain_context"            # é¢†åŸŸä¸Šä¸‹æ–‡ç»´åº¦
      - "scenario"                  # åœºæ™¯ç»´åº¦
    default_weights:                # é»˜è®¤æƒé‡é…ç½®
      core_intent: 0.5              # æ ¸å¿ƒæ„å›¾æƒé‡ï¼ˆæœ€é«˜ï¼‰
      domain_context: 0.3           # é¢†åŸŸä¸Šä¸‹æ–‡æƒé‡
      scenario: 0.15                # åœºæ™¯æƒé‡
      completeness: 0.05            # å®Œæ•´åº¦æƒé‡
    max_dimensions: 4               # æœ€å¤§ç»´åº¦æ•°é‡

  # å­˜å‚¨ç­–ç•¥é…ç½®
  strategy:
    enable_fallback: true           # å¯ç”¨é™çº§æœºåˆ¶
    fallback_to_single_vector: true # é™çº§åˆ°å•å‘é‡å­˜å‚¨
    log_analysis_details: true      # è®°å½•åˆ†æè¯¦æƒ…
    enable_async_storage: false     # å¼‚æ­¥å­˜å‚¨ï¼ˆæš‚æ—¶å…³é—­ï¼‰
    storage_timeout_seconds: 30     # å­˜å‚¨è¶…æ—¶æ—¶é—´

# æ€§èƒ½é…ç½®
performance:
  max_concurrent_requests: 10 # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
  request_timeout: 60         # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
  cache_enabled: true         # å¯ç”¨ç¼“å­˜
  cache_ttl: 300              # ç¼“å­˜TTLï¼ˆç§’ï¼‰

# ç›‘æ§é…ç½®
monitoring:
  metrics_enabled: true       # å¯ç”¨æŒ‡æ ‡æ”¶é›†
  log_level: "info"           # æ—¥å¿—çº§åˆ«
  alert_enabled: false        # å‘Šè­¦åŠŸèƒ½æš‚æ—¶å…³é—­

# ç¯å¢ƒå˜é‡è¯´æ˜
# ä»¥ä¸‹ç¯å¢ƒå˜é‡å¯ä»¥è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ï¼š
#
# æ€»å¼€å…³:
# - LLM_DRIVEN_ENABLED=true/false
#
# åŠŸèƒ½å¼€å…³:
# - LLM_DRIVEN_SEMANTIC_ANALYSIS=true/false
# - LLM_DRIVEN_MULTI_DIMENSIONAL=true/false
# - LLM_DRIVEN_CONTENT_SYNTHESIS=true/false
#
# LLMé…ç½®:
# - LLM_PROVIDER=openai
# - LLM_MODEL=gpt-4
# - LLM_MAX_TOKENS=4000
# - LLM_TEMPERATURE=0.1
#
# é™çº§é…ç½®:
# - LLM_DRIVEN_AUTO_FALLBACK=true/false
# - LLM_DRIVEN_FALLBACK_THRESHOLD=3
