package services

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"strconv"
	"strings"
	"time"

	"github.com/contextkeeper/service/internal/engines"
	"github.com/contextkeeper/service/internal/engines/multi_dimensional_retrieval/knowledge"
	"github.com/contextkeeper/service/internal/engines/multi_dimensional_retrieval/timeline"
	"github.com/contextkeeper/service/internal/llm"
	"github.com/contextkeeper/service/internal/models"
	"github.com/contextkeeper/service/internal/store"
	"github.com/contextkeeper/service/internal/utils"
)

// LLMDrivenContextService LLMé©±åŠ¨çš„ä¸Šä¸‹æ–‡æœåŠ¡
// ç›´æ¥æ›¿ä»£AgenticContextServiceï¼ŒåŸºäºContextServiceæ„å»º
type LLMDrivenContextService struct {
	// åŸºç¡€æœåŠ¡ï¼ˆç›´æ¥åŒ…è£…ContextServiceï¼‰
	contextService *ContextService

	// LLMé©±åŠ¨ç»„ä»¶
	semanticAnalyzer   *engines.SemanticAnalysisEngine
	multiRetriever     MultiDimensionalRetriever
	contentSynthesizer ContentSynthesisEngine

	// ğŸ†• ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆå…³é”®é—­ç¯ç»„ä»¶ï¼‰
	contextManager *UnifiedContextManager

	// é…ç½®å’Œå¼€å…³
	config  *LLMDrivenConfig
	enabled bool
	metrics *LLMDrivenMetrics
}

// LLMDrivenConfig LLMé©±åŠ¨æœåŠ¡é…ç½®
type LLMDrivenConfig struct {
	// æ€»å¼€å…³
	Enabled bool `json:"enabled" yaml:"enabled"`

	// åŠŸèƒ½å¼€å…³
	SemanticAnalysis bool `json:"semantic_analysis" yaml:"semantic_analysis"`
	MultiDimensional bool `json:"multi_dimensional" yaml:"multi_dimensional"`
	ContentSynthesis bool `json:"content_synthesis" yaml:"content_synthesis"`
	// ğŸ”¥ çŸ­æœŸè®°å¿†LLMé©±åŠ¨å¼€å…³ï¼ˆç‹¬ç«‹æ§åˆ¶ï¼Œé»˜è®¤å…³é—­ï¼‰
	ShortTermMemoryLLM bool `json:"short_term_memory_llm" yaml:"short_term_memory_llm"`

	// é™çº§ç­–ç•¥
	AutoFallback      bool `json:"auto_fallback" yaml:"auto_fallback"`
	FallbackThreshold int  `json:"fallback_threshold" yaml:"fallback_threshold"`

	// LLMé…ç½®
	LLM struct {
		Provider    string  `json:"provider" yaml:"provider"`
		Model       string  `json:"model" yaml:"model"`
		MaxTokens   int     `json:"max_tokens" yaml:"max_tokens"`
		Temperature float64 `json:"temperature" yaml:"temperature"`
	} `json:"llm" yaml:"llm"`
}

// LLMDrivenMetrics LLMé©±åŠ¨æœåŠ¡ç›‘æ§æŒ‡æ ‡
type LLMDrivenMetrics struct {
	TotalRequests     int64         `json:"total_requests"`
	LLMDrivenRequests int64         `json:"llm_driven_requests"`
	FallbackRequests  int64         `json:"fallback_requests"`
	SuccessRate       float64       `json:"success_rate"`
	AverageLatency    time.Duration `json:"average_latency"`
	ErrorCount        int64         `json:"error_count"`
	LastUpdated       time.Time     `json:"last_updated"`
}

// æ¥å£å®šä¹‰
type SemanticAnalysisEngine interface {
	AnalyzeQuery(ctx context.Context, query string, sessionID string) (*engines.SemanticAnalysisResult, error)
	SetEnabled(enabled bool)
	GetMetrics() interface{}
}

type MultiDimensionalRetriever interface {
	ParallelRetrieve(ctx context.Context, queries *RetrievalQueries) (*RetrievalResults, error)
	GetTimelineAdapter() TimelineAdapter                                                                         // ğŸ†• æ–°å¢æ–¹æ³•
	DirectTimelineQuery(ctx context.Context, req *models.TimelineSearchRequest) ([]*models.TimelineEvent, error) // ğŸ†• ç›´æ¥æ—¶é—´çº¿æŸ¥è¯¢
}

type ContentSynthesisEngine interface {
	SynthesizeResponse(ctx context.Context, query string, analysis *engines.SemanticAnalysisResult, retrieval *RetrievalResults) (models.ContextResponse, error)
}

// ğŸ†• TimelineAdapter æ—¶é—´çº¿é€‚é…å™¨æ¥å£
type TimelineAdapter interface {
	Retrieve(ctx context.Context, req *TimelineRetrievalRequest) ([]*models.TimelineEvent, error)
}

// ğŸ†• TimelineRetrievalRequest æ—¶é—´çº¿æ£€ç´¢è¯·æ±‚
type TimelineRetrievalRequest struct {
	UserID      string     `json:"user_id"`
	WorkspaceID string     `json:"workspace_id"`
	Query       string     `json:"query"`
	Limit       int        `json:"limit"`
	StartTime   *time.Time `json:"start_time,omitempty"`
	EndTime     *time.Time `json:"end_time,omitempty"`
}

// æ•°æ®ç»“æ„å®šä¹‰
type SemanticAnalysisResult struct {
	Intent         models.IntentType             `json:"intent"`
	Confidence     float64                       `json:"confidence"`
	Categories     []string                      `json:"categories"`
	Keywords       []string                      `json:"keywords"`
	Entities       []models.Entity               `json:"entities"`
	Queries        *models.MultiDimensionalQuery `json:"queries"`
	ProcessingTime time.Duration                 `json:"processing_time"`
	TokenUsage     int                           `json:"token_usage"`
	Metadata       map[string]interface{}        `json:"metadata"`
}

type RetrievalQueries = models.MultiDimensionalQuery

type RetrievalResults struct {
	Results []interface{} `json:"results"`
	Sources []string      `json:"sources"`
}

// MultiDimensionalRetrieverAdapter å¤šç»´åº¦æ£€ç´¢å™¨é€‚é…å™¨
type MultiDimensionalRetrieverAdapter struct {
	Impl *engines.MultiDimensionalRetrieverImpl
}

// SimpleTimelineAdapter ç®€å•æ—¶é—´çº¿é€‚é…å™¨
type SimpleTimelineAdapter struct {
	impl *engines.MultiDimensionalRetrieverImpl
}

// Retrieve å®ç°TimelineAdapteræ¥å£
func (adapter *SimpleTimelineAdapter) Retrieve(ctx context.Context, req *TimelineRetrievalRequest) ([]*models.TimelineEvent, error) {
	log.Printf("ğŸ“¥ [SimpleTimelineAdapter] æŸ¥è¯¢å‚æ•°: %+v", req)

	// ğŸ”¥ çœŸæ­£å®ç°ï¼šè°ƒç”¨å¤šç»´æ£€ç´¢å™¨çš„DirectTimelineQueryæ–¹æ³•
	if adapter.impl != nil {
		// æ„å»ºæ—¶é—´çº¿æœç´¢è¯·æ±‚
		searchReq := &models.TimelineSearchRequest{
			UserID:      req.UserID,
			WorkspaceID: req.WorkspaceID,
			Query:       req.Query, // ç©ºæŸ¥è¯¢ï¼Œçº¯æ—¶é—´èŒƒå›´è¿‡æ»¤
			Limit:       req.Limit,
			StartTime:   req.StartTime, // ğŸ”¥ å…³é”®ï¼šä¼ é€’æ—¶é—´èŒƒå›´
			EndTime:     req.EndTime,   // ğŸ”¥ å…³é”®ï¼šä¼ é€’æ—¶é—´èŒƒå›´
		}

		log.Printf("ğŸ” [SimpleTimelineAdapter] è°ƒç”¨å¤šç»´æ£€ç´¢å™¨çš„DirectTimelineQuery")

		// ğŸ”¥ å…³é”®ï¼šè°ƒç”¨æ–°å¢çš„DirectTimelineQueryæ–¹æ³•ï¼Œä¼šçœŸå®æ‰§è¡ŒSQLæŸ¥è¯¢
		events, err := adapter.impl.DirectTimelineQuery(ctx, searchReq)
		if err != nil {
			log.Printf("âŒ [SimpleTimelineAdapter] ç›´æ¥æ—¶é—´çº¿æŸ¥è¯¢å¤±è´¥: %v", err)
			return nil, err
		}

		log.Printf("âœ… [SimpleTimelineAdapter] æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› %d ä¸ªäº‹ä»¶", len(events))
		return events, nil
	}

	log.Printf("âŒ [SimpleTimelineAdapter] å¤šç»´æ£€ç´¢å™¨æœªåˆå§‹åŒ–")
	return []*models.TimelineEvent{}, nil
}

// convertTimelineEventToModel è½¬æ¢æ—¶é—´çº¿äº‹ä»¶åˆ°æ¨¡å‹
func convertTimelineEventToModel(event *timeline.TimelineEvent) *models.TimelineEvent {
	return &models.TimelineEvent{
		ID:              event.ID,
		UserID:          event.UserID,
		SessionID:       event.SessionID,
		WorkspaceID:     event.WorkspaceID,
		Timestamp:       event.Timestamp,
		EventType:       event.EventType,
		Title:           event.Title,
		Content:         event.Content,
		Summary:         event.Summary,
		ImportanceScore: event.ImportanceScore,
		RelevanceScore:  event.RelevanceScore,
		CreatedAt:       event.CreatedAt,
		UpdatedAt:       event.UpdatedAt,
	}
}

// GetTimelineAdapter å®ç°MultiDimensionalRetrieveræ¥å£
func (adapter *MultiDimensionalRetrieverAdapter) GetTimelineAdapter() TimelineAdapter {
	return &SimpleTimelineAdapter{impl: adapter.Impl}
}

// ğŸ†• DirectTimelineQuery å®ç°æ¥å£æ–¹æ³•ï¼Œç›´æ¥æ—¶é—´çº¿æŸ¥è¯¢
func (adapter *MultiDimensionalRetrieverAdapter) DirectTimelineQuery(ctx context.Context, req *models.TimelineSearchRequest) ([]*models.TimelineEvent, error) {
	log.Printf("ğŸ” [é€‚é…å™¨] è°ƒç”¨åº•å±‚DirectTimelineQuery")
	return adapter.Impl.DirectTimelineQuery(ctx, req)
}

// ParallelRetrieve å®ç°æ¥å£æ–¹æ³•
func (adapter *MultiDimensionalRetrieverAdapter) ParallelRetrieve(ctx context.Context, queries *RetrievalQueries) (*RetrievalResults, error) {
	// ä»ä¸Šä¸‹æ–‡æå–ç”¨æˆ·ä¸å·¥ä½œç©ºé—´ä¿¡æ¯ï¼Œç§»é™¤ç¡¬ç¼–ç 
	userID, _ := ctx.Value("user_id").(string)
	workspaceID, _ := ctx.Value("workspacePath").(string)

	// ğŸ”¥ ä¿®å¤ï¼šå¡«å……ç”¨æˆ·ã€å·¥ä½œç©ºé—´å’ŒLLMåˆ†æä¿¡æ¯
	queries.UserID = userID
	queries.WorkspaceID = workspaceID
	// TODO: å¡«å……KeyConceptså­—æ®µä»ä¸Šå±‚LLMåˆ†æç»“æœ

	// è°ƒç”¨å®é™…å®ç°
	engineResults, err := adapter.Impl.ParallelRetrieve(ctx, queries)
	if err != nil {
		return nil, err
	}

	// è½¬æ¢ç»“æœæ ¼å¼
	results := &RetrievalResults{
		Results: make([]interface{}, 0),
		Sources: []string{},
	}

	// æ·»åŠ æ—¶é—´çº¿ç»“æœ
	for _, result := range engineResults.TimelineResults {
		results.Results = append(results.Results, result)
		results.Sources = append(results.Sources, "timeline")
	}

	// æ·»åŠ çŸ¥è¯†å›¾è°±ç»“æœ
	for _, result := range engineResults.KnowledgeResults {
		results.Results = append(results.Results, result)
		results.Sources = append(results.Sources, "knowledge")
	}

	// æ·»åŠ å‘é‡ç»“æœ
	for _, result := range engineResults.VectorResults {
		results.Results = append(results.Results, result)
		results.Sources = append(results.Sources, "vector")
	}

	return results, nil
}

// ContentSynthesisEngineAdapter å†…å®¹åˆæˆå¼•æ“é€‚é…å™¨
type ContentSynthesisEngineAdapter struct {
	impl *engines.ContentSynthesisEngineImpl
}

// SynthesizeResponse å®ç°æ¥å£æ–¹æ³•
func (adapter *ContentSynthesisEngineAdapter) SynthesizeResponse(ctx context.Context, query string, analysis *engines.SemanticAnalysisResult, retrieval *RetrievalResults) (models.ContextResponse, error) {
	// è½¬æ¢æ£€ç´¢ç»“æœæ ¼å¼
	engineRetrieval := &engines.RetrievalResults{
		TimelineResults:  []*models.TimelineEvent{},
		KnowledgeResults: []*models.KnowledgeNode{},
		VectorResults:    []*models.VectorMatch{},
		TimelineCount:    0,
		KnowledgeCount:   0,
		VectorCount:      0,
		TotalResults:     len(retrieval.Results),
		OverallQuality:   0.8,
		RetrievalTime:    0,
		Results:          retrieval.Results,
	}

	// ä»Resultsä¸­æå–å…·ä½“ç±»å‹çš„ç»“æœ
	for i, result := range retrieval.Results {
		source := ""
		if i < len(retrieval.Sources) {
			source = retrieval.Sources[i]
		}

		switch source {
		case "timeline":
			if event, ok := result.(*models.TimelineEvent); ok {
				engineRetrieval.TimelineResults = append(engineRetrieval.TimelineResults, event)
				engineRetrieval.TimelineCount++
			}
		case "knowledge":
			if node, ok := result.(*models.KnowledgeNode); ok {
				engineRetrieval.KnowledgeResults = append(engineRetrieval.KnowledgeResults, node)
				engineRetrieval.KnowledgeCount++
			}
		case "vector":
			if match, ok := result.(*models.VectorMatch); ok {
				engineRetrieval.VectorResults = append(engineRetrieval.VectorResults, match)
				engineRetrieval.VectorCount++
			}
		}
	}

	// è°ƒç”¨å®é™…å®ç°
	return adapter.impl.SynthesizeResponse(ctx, query, analysis, engineRetrieval)
}

// NewLLMDrivenContextServiceWithEngines åˆ›å»ºå¸¦å­˜å‚¨å¼•æ“çš„LLMé©±åŠ¨ä¸Šä¸‹æ–‡æœåŠ¡
func NewLLMDrivenContextServiceWithEngines(contextService *ContextService, storageEngines map[string]interface{}) *LLMDrivenContextService {
	cfg := loadLLMDrivenConfig()

	service := &LLMDrivenContextService{
		contextService: contextService,
		config:         cfg,
		enabled:        cfg.Enabled,
		metrics: &LLMDrivenMetrics{
			LastUpdated: time.Now(),
		},
	}

	// åˆå§‹åŒ–LLMé©±åŠ¨ç»„ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
	if cfg.Enabled {
		service.initializeLLMComponentsWithEngines(storageEngines)
	}

	log.Printf("ğŸš€ [LLMé©±åŠ¨æœåŠ¡] åˆå§‹åŒ–å®Œæˆï¼ˆå¸¦å­˜å‚¨å¼•æ“ï¼‰ï¼ŒçŠ¶æ€: %v", cfg.Enabled)
	return service
}

// loadLLMDrivenConfig åŠ è½½LLMé©±åŠ¨é…ç½®
// ç»Ÿä¸€ä½¿ç”¨ç¯å¢ƒå˜é‡ä½œä¸ºå”¯ä¸€é…ç½®æºï¼Œç®€åŒ–å¼€å…³é€»è¾‘
func loadLLMDrivenConfig() *LLMDrivenConfig {
	log.Printf("ğŸ”§ [é…ç½®åŠ è½½] å¼€å§‹åŠ è½½LLMé©±åŠ¨é…ç½®ï¼Œä»…ä»ç¯å¢ƒå˜é‡è¯»å–")

	// è®¾ç½®é»˜è®¤å€¼
	cfg := &LLMDrivenConfig{
		// ğŸ”¥ ä¸»å¼€å…³ï¼šé»˜è®¤å¯ç”¨ï¼Œç”±ç¯å¢ƒå˜é‡æ§åˆ¶
		Enabled: getEnvAsBool("LLM_DRIVEN_ENABLED", true),

		// åŠŸèƒ½å¼€å…³ï¼šé»˜è®¤å¯ç”¨å­åŠŸèƒ½
		SemanticAnalysis:   getEnvAsBool("LLM_DRIVEN_SEMANTIC_ANALYSIS", true),
		MultiDimensional:   getEnvAsBool("LLM_DRIVEN_MULTI_DIMENSIONAL", true),
		ContentSynthesis:   getEnvAsBool("LLM_DRIVEN_CONTENT_SYNTHESIS", true),
		ShortTermMemoryLLM: getEnvAsBool("LLM_DRIVEN_SHORT_TERM_MEMORY", false),

		// å®¹é”™è®¾ç½®
		AutoFallback:      getEnvAsBool("LLM_DRIVEN_AUTO_FALLBACK", true),
		FallbackThreshold: getEnvAsInt("LLM_DRIVEN_FALLBACK_THRESHOLD", 3),
	}

	// LLMé…ç½®
	cfg.LLM.Provider = getEnv("LLM_PROVIDER", "deepseek")
	cfg.LLM.Model = getEnv("LLM_MODEL", "deepseek-chat")
	cfg.LLM.MaxTokens = getEnvAsInt("LLM_MAX_TOKENS", 4000)
	cfg.LLM.Temperature = getEnvAsFloat("LLM_TEMPERATURE", 0.3)

	log.Printf("ğŸ¯ [é…ç½®åŠ è½½] LLMé©±åŠ¨é…ç½®åŠ è½½å®Œæˆ")
	log.Printf("   ğŸ”‘ ä¸»å¼€å…³: enabled=%v", cfg.Enabled)
	log.Printf("   ğŸ§  è¯­æ–™åˆ†æ: %v", cfg.SemanticAnalysis)
	log.Printf("   ğŸ“Š å¤šç»´æ£€ç´¢: %v", cfg.MultiDimensional)
	log.Printf("   âœ¨ å†…å®¹åˆæˆ: %v", cfg.ContentSynthesis)
	log.Printf("   ğŸ¤– LLMæä¾›å•†: %s/%s", cfg.LLM.Provider, cfg.LLM.Model)

	return cfg
}

// ä»ç¯å¢ƒå˜é‡è·å–å­—ç¬¦ä¸²å€¼
func getEnv(key, defaultValue string) string {
	if value, exists := os.LookupEnv(key); exists {
		return value
	}
	return defaultValue
}

// ä»ç¯å¢ƒå˜é‡è·å–æ•´æ•°å€¼
func getEnvAsInt(key string, defaultValue int) int {
	strValue := getEnv(key, "")
	if value, err := strconv.Atoi(strValue); err == nil {
		return value
	}
	return defaultValue
}

// ä»ç¯å¢ƒå˜é‡è·å–å¸ƒå°”å€¼
func getEnvAsBool(key string, defaultValue bool) bool {
	strValue := getEnv(key, "")
	if value, err := strconv.ParseBool(strValue); err == nil {
		return value
	}
	return defaultValue
}

// ä»ç¯å¢ƒå˜é‡è·å–æµ®ç‚¹å€¼
func getEnvAsFloat(key string, defaultValue float64) float64 {
	strValue := getEnv(key, "")
	if value, err := strconv.ParseFloat(strValue, 64); err == nil {
		return value
	}
	return defaultValue
}

// initializeLLMComponentsWithEngines åˆå§‹åŒ–LLMç»„ä»¶ï¼ˆå¸¦å­˜å‚¨å¼•æ“ï¼‰
func (lds *LLMDrivenContextService) initializeLLMComponentsWithEngines(storageEngines map[string]interface{}) {
	log.Printf("ğŸ§  [LLMé©±åŠ¨æœåŠ¡] åˆå§‹åŒ–LLMç»„ä»¶ï¼ˆå¸¦å­˜å‚¨å¼•æ“ï¼‰...")

	// åˆ›å»ºLLMå®¢æˆ·ç«¯
	llmClient, err := lds.createLLMClient()
	if err != nil {
		log.Printf("âŒ [LLMé©±åŠ¨æœåŠ¡] LLMå®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: %v", err)
		return
	}
	log.Printf("âœ… [LLMé©±åŠ¨æœåŠ¡] LLMå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸï¼Œæä¾›å•†: %s, æ¨¡å‹: %s", lds.config.LLM.Provider, lds.config.LLM.Model)

	// è¯­æ–™åˆ†æå¼•æ“
	if lds.config.SemanticAnalysis {
		semanticConfig := &engines.SemanticAnalysisConfig{
			Enabled:              true,
			Provider:             lds.config.LLM.Provider,
			Model:                lds.config.LLM.Model,
			MaxTokens:            lds.config.LLM.MaxTokens,
			Temperature:          lds.config.LLM.Temperature,
			TimeoutSeconds:       30,
			EnableIntentCache:    true,
			EnableQueryExpansion: true,
		}
		lds.semanticAnalyzer = engines.NewSemanticAnalysisEngine(semanticConfig, llmClient)
		log.Printf("âœ… [LLMé©±åŠ¨æœåŠ¡] è¯­æ–™åˆ†æå¼•æ“å·²åˆå§‹åŒ–")
	}

	// å¤šç»´åº¦æ£€ç´¢å¼•æ“ï¼ˆä»storageEnginesä¸­è·å–å·²åˆ›å»ºçš„å®ä¾‹ï¼‰
	if lds.config.MultiDimensional {
		if multiRetriever, exists := storageEngines["multi_retriever"]; exists && multiRetriever != nil {
			lds.multiRetriever = multiRetriever.(MultiDimensionalRetriever)
			log.Printf("âœ… [LLMé©±åŠ¨æœåŠ¡] å¤šç»´åº¦æ£€ç´¢å¼•æ“å·²è¿æ¥: %T", multiRetriever)

			// ğŸ”¥ å»¶è¿Ÿèµ‹å€¼ï¼šç›´æ¥åŸºäºMultiDimensionalRetrieverçš„vectorAdapterè¿›è¡Œèµ‹å€¼
			if adapter, ok := lds.multiRetriever.(*MultiDimensionalRetrieverAdapter); ok {
				if vectorStore := lds.contextService.GetVectorStore(); vectorStore != nil {
					adapter.Impl.SetVectorStoreEngine(vectorStore)
					log.Printf("âœ… [å»¶è¿Ÿèµ‹å€¼] æˆåŠŸè®¾ç½®MultiDimensionalRetrieverçš„vectorAdapter.Engine")
				} else {
					log.Printf("âš ï¸ [å»¶è¿Ÿèµ‹å€¼] contextService.GetVectorStore()ä¸ºnil")
				}
			}
		} else {
			log.Printf("âš ï¸ [LLMé©±åŠ¨æœåŠ¡] å¤šç»´åº¦æ£€ç´¢å¼•æ“æœªæ‰¾åˆ°ï¼Œå¤šç»´åº¦æ£€ç´¢åŠŸèƒ½å°†ä¸å¯ç”¨")
		}
	}

	// å†…å®¹åˆæˆå¼•æ“
	if lds.config.ContentSynthesis {
		// åˆå§‹åŒ–å†…å®¹åˆæˆå¼•æ“
		contentSynthesizerImpl := engines.NewContentSynthesisEngine(llmClient)
		// åˆ›å»ºé€‚é…å™¨
		lds.contentSynthesizer = &ContentSynthesisEngineAdapter{impl: contentSynthesizerImpl}
		log.Printf("âœ… [LLMé©±åŠ¨æœåŠ¡] å†…å®¹åˆæˆå¼•æ“å·²åˆå§‹åŒ–")
	}

	log.Printf("ğŸ¯ [LLMé©±åŠ¨æœåŠ¡] LLMç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼ˆå¸¦å­˜å‚¨å¼•æ“ï¼‰")
}

// ReinitializeVectorEngine é‡æ–°åˆå§‹åŒ–å‘é‡å¼•æ“ï¼ˆç”¨äºå»¶è¿Ÿèµ‹å€¼ï¼‰
func (lds *LLMDrivenContextService) ReinitializeVectorEngine() {
	log.Printf("ğŸ”§ [LLMé©±åŠ¨æœåŠ¡] å¼€å§‹é‡æ–°åˆå§‹åŒ–å‘é‡å¼•æ“...")

	// æ£€æŸ¥LLMé©±åŠ¨æ˜¯å¦å¯ç”¨
	if !lds.enabled {
		log.Printf("ğŸ“ [å‘é‡å¼•æ“é‡åˆå§‹åŒ–] LLMé©±åŠ¨åŠŸèƒ½å·²ç¦ç”¨ï¼Œæ— éœ€åˆå§‹åŒ–å‘é‡å¼•æ“")
		return
	}

	// æ£€æŸ¥å¤šç»´åº¦æ£€ç´¢å™¨æ˜¯å¦å­˜åœ¨
	if lds.multiRetriever == nil {
		log.Printf("âš ï¸ [å‘é‡å¼•æ“é‡åˆå§‹åŒ–] å¤šç»´åº¦æ£€ç´¢å™¨ä¸ºnilï¼Œè·³è¿‡")
		return
	}

	// ğŸ”¥ é‡æ–°æ‰§è¡Œå»¶è¿Ÿèµ‹å€¼é€»è¾‘
	if adapter, ok := lds.multiRetriever.(*MultiDimensionalRetrieverAdapter); ok {
		if vectorStore := lds.contextService.GetVectorStore(); vectorStore != nil {
			adapter.Impl.SetVectorStoreEngine(vectorStore)
			log.Printf("âœ… [å‘é‡å¼•æ“é‡åˆå§‹åŒ–] æˆåŠŸé‡æ–°è®¾ç½®MultiDimensionalRetrieverçš„vectorAdapter.Engine")
		} else {
			log.Printf("âŒ [å‘é‡å¼•æ“é‡åˆå§‹åŒ–] contextService.GetVectorStore()ä»ç„¶ä¸ºnil")
		}
	} else {
		log.Printf("âš ï¸ [å‘é‡å¼•æ“é‡åˆå§‹åŒ–] å¤šç»´åº¦æ£€ç´¢å™¨ç±»å‹æ–­è¨€å¤±è´¥: %T", lds.multiRetriever)
	}

	log.Printf("ğŸ¯ [LLMé©±åŠ¨æœåŠ¡] å‘é‡å¼•æ“é‡æ–°åˆå§‹åŒ–å®Œæˆ")
}

// createLLMClient åˆ›å»ºLLMå®¢æˆ·ç«¯
func (lds *LLMDrivenContextService) createLLMClient() (llm.LLMClient, error) {
	// æ ¹æ®Providerè·å–å¯¹åº”çš„APIå¯†é’¥
	var apiKey string
	switch lds.config.LLM.Provider {
	case "deepseek":
		apiKey = getEnv("DEEPSEEK_API_KEY", "")
	case "openai":
		apiKey = getEnv("OPENAI_API_KEY", "")
	case "claude":
		apiKey = getEnv("CLAUDE_API_KEY", "")
	case "qianwen":
		apiKey = getEnv("QIANWEN_API_KEY", "")
	case "ollama_local":
		// ğŸ†• æœ¬åœ°æ¨¡å‹ä¸éœ€è¦APIå¯†é’¥
		apiKey = ""
	default:
		return nil, fmt.Errorf("ä¸æ”¯æŒçš„LLMæä¾›å•†: %s", lds.config.LLM.Provider)
	}

	// ğŸ”¥ ä¿®å¤ï¼šæœ¬åœ°æ¨¡å‹ä¸éœ€è¦APIå¯†é’¥æ£€æŸ¥
	if apiKey == "" && lds.config.LLM.Provider != "ollama_local" {
		return nil, fmt.Errorf("LLM APIå¯†é’¥æœªé…ç½®ï¼Œæä¾›å•†: %s", lds.config.LLM.Provider)
	}

	// è®¾ç½®LLMé…ç½®ï¼ˆåŸºç¡€é…ç½®ï¼‰
	config := &llm.LLMConfig{
		Provider:   llm.LLMProvider(lds.config.LLM.Provider),
		APIKey:     apiKey,
		Model:      lds.config.LLM.Model,
		MaxRetries: 3,
		Timeout:    120 * time.Second, // å¢åŠ åˆ°120ç§’ï¼Œé€‚åº”å¤æ‚LLMåˆ†æ
		RateLimit:  60,                // æ¯åˆ†é’Ÿ60æ¬¡è¯·æ±‚
	}

	// ğŸ†• è®¾ç½®æœ¬åœ°æ¨¡å‹çš„BaseURL
	if lds.config.LLM.Provider == "ollama_local" {
		config.BaseURL = "http://localhost:11434"
		config.RateLimit = 0              // æœ¬åœ°æ¨¡å‹æ— é™æµé™åˆ¶
		config.Timeout = 60 * time.Second // æœ¬åœ°æ¨¡å‹æ›´å¿«
	}

	// è®¾ç½®å…¨å±€é…ç½®
	llm.SetGlobalConfig(llm.LLMProvider(lds.config.LLM.Provider), config)

	// ä½¿ç”¨å·¥å‚åˆ›å»ºå®¢æˆ·ç«¯
	client, err := llm.CreateGlobalClient(llm.LLMProvider(lds.config.LLM.Provider))
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºLLMå®¢æˆ·ç«¯å¤±è´¥: %w", err)
	}

	log.Printf("âœ… [LLMé©±åŠ¨æœåŠ¡] LLMå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸï¼Œæä¾›å•†: %s, æ¨¡å‹: %s",
		lds.config.LLM.Provider, lds.config.LLM.Model)

	// ğŸ”¥ æ‰§è¡Œå¥åº·æ£€æŸ¥éªŒè¯æ¨¡å‹å¯ç”¨æ€§
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	if err := client.HealthCheck(ctx); err != nil {
		log.Printf("âš ï¸ [LLMé©±åŠ¨æœåŠ¡] æ¨¡å‹å¥åº·æ£€æŸ¥å¤±è´¥: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œå…è®¸æœåŠ¡å¯åŠ¨ä½†è®°å½•è­¦å‘Š
	} else {
		log.Printf("âœ… [LLMé©±åŠ¨æœåŠ¡] æ¨¡å‹å¥åº·æ£€æŸ¥é€šè¿‡")
	}

	return client, nil
}

// RetrieveContext å®ç°ContextServiceInterfaceæ¥å£ - æ ¸å¿ƒæ–¹æ³•
func (lds *LLMDrivenContextService) RetrieveContext(ctx context.Context, req models.RetrieveContextRequest) (models.ContextResponse, error) {
	lds.metrics.TotalRequests++
	lds.metrics.LastUpdated = time.Now()

	// ğŸ”¥ å…³é”®å¼€å…³ï¼šLLMé©±åŠ¨ vs åŸºç¡€æœåŠ¡
	if !lds.enabled {
		log.Printf("ğŸ”„ [LLMé©±åŠ¨æœåŠ¡] LLMé©±åŠ¨åŠŸèƒ½å·²ç¦ç”¨ï¼Œä½¿ç”¨åŸºç¡€ContextService")
		lds.metrics.FallbackRequests++
		return lds.contextService.RetrieveContext(ctx, req)
	}

	log.Printf("ğŸš€ [LLMé©±åŠ¨æœåŠ¡] å¯ç”¨LLMé©±åŠ¨æ™ºèƒ½åŒ–æµç¨‹ï¼ŒæŸ¥è¯¢: %s", req.Query)
	lds.metrics.LLMDrivenRequests++

	startTime := time.Now()

	// æ‰§è¡ŒLLMé©±åŠ¨çš„æ™ºèƒ½åŒ–æµç¨‹
	response, err := lds.executeLLMDrivenFlow(ctx, req)
	if err != nil {
		lds.metrics.ErrorCount++

		// è‡ªåŠ¨é™çº§åˆ°åŸºç¡€æœåŠ¡
		if lds.config.AutoFallback {
			log.Printf("âš ï¸ [LLMé©±åŠ¨æœåŠ¡] LLMé©±åŠ¨æµç¨‹å¤±è´¥ï¼Œè‡ªåŠ¨é™çº§åˆ°åŸºç¡€ContextService: %v", err)
			lds.metrics.FallbackRequests++
			return lds.contextService.RetrieveContext(ctx, req)
		}

		return models.ContextResponse{}, fmt.Errorf("LLMé©±åŠ¨æµç¨‹å¤±è´¥: %w", err)
	}

	// æ›´æ–°æ€§èƒ½æŒ‡æ ‡
	latency := time.Since(startTime)
	lds.updateMetrics(latency, true)

	log.Printf("âœ… [LLMé©±åŠ¨æœåŠ¡] LLMé©±åŠ¨æµç¨‹å®Œæˆï¼Œè€—æ—¶: %v", latency)
	return response, nil
}

// åŸºäºllmé©±åŠ¨çš„ã€å®½å¬å›+ç²¾æ’åºã€‘
func (lds *LLMDrivenContextService) executeLLMDrivenFlow(ctx context.Context, req models.RetrieveContextRequest) (models.ContextResponse, error) {
	// Phase 1: ç¬¬ä¸€æ¬¡LLMè°ƒç”¨ - è¯­æ–™åˆ†æ
	if lds.config.SemanticAnalysis && lds.semanticAnalyzer != nil {
		log.Printf("ğŸ¯ [LLMé©±åŠ¨æœåŠ¡] æ‰§è¡Œè¯­æ–™åˆ†æ...")
		analysisResult, err := lds.semanticAnalyzer.AnalyzeQuery(ctx, req.Query, req.SessionID)
		if err != nil {
			return models.ContextResponse{}, fmt.Errorf("è¯­æ–™åˆ†æå¤±è´¥: %w", err)
		}
		log.Printf("âœ… [LLMé©±åŠ¨æœåŠ¡] è¯­æ–™åˆ†æå®Œæˆï¼Œè¯†åˆ«æ„å›¾: %s", analysisResult.Intent)

		// ğŸ†• Phase 1.5: æ£€æŸ¥æ˜¯å¦ä¸ºæ—¶é—´å›å¿†æŸ¥è¯¢ - ä¼˜å…ˆå¤„ç†
		if lds.checkTimelineRecallQuery(analysisResult) {
			log.Printf("ğŸ•’ [æ—¶é—´å›å¿†æ¨¡å¼] æ£€æµ‹åˆ°æ—¶é—´èŒƒå›´æŸ¥è¯¢ï¼Œä½¿ç”¨ä¸“ç”¨æ—¶é—´çº¿æ£€ç´¢")
			return lds.handleTimelineRecallQuery(ctx, req, analysisResult)
		}

		// ğŸ†• å·¥ç¨‹æ„ŸçŸ¥é›†æˆï¼šå¦‚æœæä¾›äº†ProjectAnalysisï¼Œèåˆåˆ°æ£€ç´¢è¯·æ±‚ä¸­  TODO å¾…å®šè¿™ä¸ªé€»è¾‘
		if req.ProjectAnalysis != "" {
			log.Printf("ğŸ”§ [å·¥ç¨‹æ„ŸçŸ¥] æ£€æµ‹åˆ°é¡¹ç›®åˆ†æä¿¡æ¯ï¼Œé•¿åº¦: %då­—ç¬¦", len(req.ProjectAnalysis))
			// å°†å·¥ç¨‹æ„ŸçŸ¥ä¿¡æ¯æ·»åŠ åˆ°æ£€ç´¢æŸ¥è¯¢ä¸­ï¼Œå¢å¼ºä¸Šä¸‹æ–‡ç†è§£
			analysisResult.Queries.ContextQueries = append(analysisResult.Queries.ContextQueries,
				"é¡¹ç›®ä¸Šä¸‹æ–‡: "+req.ProjectAnalysis)
			log.Printf("ğŸ”§ [å·¥ç¨‹æ„ŸçŸ¥] å·²å°†é¡¹ç›®åˆ†æèåˆåˆ°ä¸Šä¸‹æ–‡æ£€ç´¢ä¸­")
		}

		// Phase 2: å¤šç»´åº¦å¹¶è¡Œæ£€ç´¢
		if lds.config.MultiDimensional && lds.multiRetriever != nil {
			log.Printf("ğŸ” [LLMé©±åŠ¨æœåŠ¡] æ‰§è¡Œå¤šç»´åº¦æ£€ç´¢...")

			// ğŸ”¥ å…³é”®ä¿®å¤ï¼šä»LLMåˆ†æç»“æœä¸­æå–å…³é”®æ¦‚å¿µ
			if analysisResult.Keywords != nil {
				analysisResult.Queries.KeyConcepts = analysisResult.Keywords
				log.Printf("ğŸ”¥ [LLMé©±åŠ¨æœåŠ¡] å·²è®¾ç½®å…³é”®æ¦‚å¿µ: %v", analysisResult.Keywords)
			}

			retrievalResults, err := lds.multiRetriever.ParallelRetrieve(ctx, analysisResult.Queries)
			if err != nil {
				return models.ContextResponse{}, fmt.Errorf("å¤šç»´åº¦æ£€ç´¢å¤±è´¥: %w", err)
			}
			log.Printf("âœ… [LLMé©±åŠ¨æœåŠ¡] å¤šç»´åº¦æ£€ç´¢å®Œæˆï¼Œè·å¾— %d ä¸ªç»“æœ", len(retrievalResults.Results))

			// Phase 3: ç¬¬äºŒæ¬¡LLMè°ƒç”¨ - å†…å®¹åˆæˆ
			if lds.config.ContentSynthesis && lds.contentSynthesizer != nil {
				log.Printf("ğŸ§  [LLMé©±åŠ¨æœåŠ¡] æ‰§è¡Œå†…å®¹åˆæˆ...")

				// ğŸ†• ä¼ é€’å·¥ç¨‹æ„ŸçŸ¥ä¿¡æ¯åˆ°åˆæˆå¼•æ“
				enrichedCtx := ctx
				if req.ProjectAnalysis != "" {
					enrichedCtx = context.WithValue(ctx, "project_analysis", req.ProjectAnalysis)
					log.Printf("ğŸ”§ [å·¥ç¨‹æ„ŸçŸ¥] å°†é¡¹ç›®åˆ†æä¿¡æ¯ä¼ é€’ç»™å†…å®¹åˆæˆå¼•æ“")
				}

				response, err := lds.contentSynthesizer.SynthesizeResponse(enrichedCtx, req.Query, analysisResult, retrievalResults)
				if err != nil {
					return models.ContextResponse{}, fmt.Errorf("å†…å®¹åˆæˆå¤±è´¥: %w", err)
				}
				log.Printf("âœ… [LLMé©±åŠ¨æœåŠ¡] å†…å®¹åˆæˆå®Œæˆ")
				return response, nil
			}
		}
	}

	// å¦‚æœæŸäº›ç»„ä»¶æœªå¯ç”¨ï¼Œé™çº§åˆ°åŸºç¡€æœåŠ¡
	log.Printf("âš ï¸ [LLMé©±åŠ¨æœåŠ¡] LLMé©±åŠ¨ç»„ä»¶æœªå®Œå…¨å¯ç”¨ï¼Œé™çº§åˆ°åŸºç¡€æœåŠ¡")
	return lds.contextService.RetrieveContext(ctx, req)
}

// StoreContext ä»£ç†åˆ°åŸºç¡€ContextService
func (lds *LLMDrivenContextService) StoreContext(ctx context.Context, req models.StoreContextRequest) (string, error) {
	return lds.contextService.StoreContext(ctx, req)
}

// RetrieveConversation ä»£ç†åˆ°åŸºç¡€ContextService
func (lds *LLMDrivenContextService) RetrieveConversation(ctx context.Context, req models.RetrieveConversationRequest) (*models.ConversationResponse, error) {
	return lds.contextService.RetrieveConversation(ctx, req)
}

// GetProgrammingContext ä»£ç†åˆ°åŸºç¡€ContextService
func (lds *LLMDrivenContextService) GetProgrammingContext(ctx context.Context, sessionID string, query string) (*models.ProgrammingContext, error) {
	return lds.contextService.GetProgrammingContext(ctx, sessionID, query)
}

// GetContextService è·å–åŸºç¡€ContextServiceï¼ˆç”¨äºMCPå·¥å…·ç­‰éœ€è¦ç›´æ¥è®¿é—®åŸºç¡€æœåŠ¡çš„åœºæ™¯ï¼‰
func (lds *LLMDrivenContextService) GetContextService() *ContextService {
	return lds.contextService
}

// SetContextManager è®¾ç½®ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
func (lds *LLMDrivenContextService) SetContextManager(manager *UnifiedContextManager) {
	lds.contextManager = manager
}

// ============================================================================
// ğŸ”„ ä»£ç†æ–¹æ³• - å®Œå…¨å…¼å®¹AgenticContextServiceæ¥å£
// ============================================================================

// SummarizeContext æ€»ç»“ä¸Šä¸‹æ–‡
func (lds *LLMDrivenContextService) SummarizeContext(ctx context.Context, req models.SummarizeContextRequest) (string, error) {
	return lds.contextService.SummarizeContext(ctx, req)
}

// StoreSessionMessages å­˜å‚¨ä¼šè¯æ¶ˆæ¯ - LLMé©±åŠ¨çš„æ™ºèƒ½å­˜å‚¨
func (lds *LLMDrivenContextService) StoreSessionMessages(ctx context.Context, req models.StoreMessagesRequest) (*models.StoreMessagesResponse, error) {
	// ğŸ”¥ æ£€æŸ¥çŸ­æœŸè®°å¿†LLMé©±åŠ¨å¼€å…³ï¼ˆç‹¬ç«‹æ§åˆ¶ï¼‰
	if !lds.enabled || !lds.config.ShortTermMemoryLLM {
		log.Printf("ğŸ”„ [çŸ­æœŸè®°å¿†å­˜å‚¨] LLMé©±åŠ¨åŠŸèƒ½æœªå¯ç”¨æˆ–çŸ­æœŸè®°å¿†LLMå¼€å…³å…³é—­ï¼Œä½¿ç”¨åŸæœ‰æœ¬åœ°å­˜å‚¨é€»è¾‘")
		return lds.contextService.StoreSessionMessages(ctx, req)
	}

	log.Printf("ğŸ§  [LLMé©±åŠ¨å­˜å‚¨] å¼€å§‹æ™ºèƒ½å­˜å‚¨åˆ†æ: ä¼šè¯=%s, æ¶ˆæ¯æ•°=%d", req.SessionID, len(req.Messages))

	// å¯¹æ¯æ¡æ¶ˆæ¯è¿›è¡Œæ™ºèƒ½åˆ†æå’Œå­˜å‚¨
	var allMessageIDs []string
	var smartAnalysisResults []map[string]interface{}

	for i, msgReq := range req.Messages {
		log.Printf("ğŸ” [LLMé©±åŠ¨å­˜å‚¨] åˆ†ææ¶ˆæ¯ %d/%d: %s", i+1, len(req.Messages), msgReq.Content[:min(50, len(msgReq.Content))])

		// æ‰§è¡Œæ™ºèƒ½å­˜å‚¨å†³ç­–
		result, err := lds.executeSmartStorage(ctx, req.SessionID, msgReq.Content, msgReq.Priority)
		if err != nil {
			log.Printf("âŒ [LLMé©±åŠ¨å­˜å‚¨] æ™ºèƒ½å­˜å‚¨å¤±è´¥: %v", err)
			// é™çº§åˆ°åŸºç¡€å­˜å‚¨
			return lds.contextService.StoreSessionMessages(ctx, req)
		}

		// æ”¶é›†ç»“æœ
		if result.MessageIDs != nil {
			allMessageIDs = append(allMessageIDs, result.MessageIDs...)
		}

		// æ”¶é›†æ™ºèƒ½åˆ†æç»“æœ
		smartAnalysisResults = append(smartAnalysisResults, map[string]interface{}{
			"messageIndex":    i,
			"content":         msgReq.Content,
			"confidence":      result.Confidence,
			"storageStrategy": result.StorageStrategy,
			"intentAnalysis":  result.IntentAnalysis,
			"qualityScore":    result.QualityScore,
		})
	}

	// æ„å»ºå¢å¼ºçš„å“åº”
	response := &models.StoreMessagesResponse{
		MessageIDs: allMessageIDs,
		Status:     "success",
		Metadata: map[string]interface{}{
			"llm_driven":         true,
			"smart_analysis":     smartAnalysisResults,
			"total_messages":     len(req.Messages),
			"analysis_timestamp": time.Now().Unix(),
		},
	}

	log.Printf("âœ… [LLMé©±åŠ¨å­˜å‚¨] æ™ºèƒ½å­˜å‚¨å®Œæˆ: æ¶ˆæ¯æ•°=%d, æ€»IDæ•°=%d", len(req.Messages), len(allMessageIDs))
	return response, nil
}

// executeSmartStorage æ‰§è¡Œæ™ºèƒ½å­˜å‚¨å†³ç­–ï¼ˆé€‚é…ç‰ˆæœ¬ï¼‰
func (lds *LLMDrivenContextService) executeSmartStorage(ctx context.Context, sessionID, content, priority string) (*SmartStorageResult, error) {
	log.Printf("ğŸ§  [æ™ºèƒ½å­˜å‚¨å†³ç­–] å¼€å§‹åˆ†æå†…å®¹: %s", content[:min(50, len(content))])

	// ğŸ”¥ ç›´æ¥è°ƒç”¨åŸºç¡€æœåŠ¡çš„æ™ºèƒ½å­˜å‚¨é€»è¾‘ï¼ˆåŒ…å«LLMåˆ†æï¼‰
	req := models.StoreContextRequest{
		SessionID: sessionID,
		Content:   content,
		Priority:  priority,
		Metadata: map[string]interface{}{
			"source":    "llm_driven_storage",
			"timestamp": time.Now().Unix(),
		},
	}

	// ğŸ”¥ ä½¿ç”¨æ–°çš„æ‰©å±•æ¥å£è·å–å®Œæ•´åˆ†æç»“æœ
	response, err := lds.contextService.StoreContextWithAnalysis(ctx, req)
	if err != nil {
		log.Printf("âŒ [æ™ºèƒ½å­˜å‚¨å†³ç­–] å­˜å‚¨å¤±è´¥: %v", err)
		return nil, fmt.Errorf("æ™ºèƒ½å­˜å‚¨æ‰§è¡Œå¤±è´¥: %w", err)
	}

	// æ„å»ºæ™ºèƒ½å­˜å‚¨ç»“æœ
	result := &SmartStorageResult{
		MessageIDs:      []string{response.MemoryID},
		Confidence:      response.Confidence,
		StorageStrategy: response.StorageStrategy,
		IntentAnalysis:  content,
		QualityScore:    response.Confidence,
		AnalysisResult:  response.AnalysisResult, // åŒ…å«å®Œæ•´çš„åˆ†æç»“æœ
	}

	log.Printf("âœ… [æ™ºèƒ½å­˜å‚¨å†³ç­–] å®Œæˆï¼Œè®°å¿†ID: %s, ç½®ä¿¡åº¦: %.2f", response.MemoryID, result.Confidence)
	return result, nil
}

// SmartStorageResult æ™ºèƒ½å­˜å‚¨ç»“æœ
type SmartStorageResult struct {
	MessageIDs      []string                    `json:"messageIds"`
	Confidence      float64                     `json:"confidence"`
	StorageStrategy string                      `json:"storageStrategy"`
	IntentAnalysis  string                      `json:"intentAnalysis"`
	QualityScore    float64                     `json:"qualityScore"`
	AnalysisResult  *models.SmartAnalysisResult `json:"analysisResult,omitempty"` // å®Œæ•´çš„åˆ†æç»“æœ
}

// GetSessionState è·å–ä¼šè¯çŠ¶æ€
func (lds *LLMDrivenContextService) GetSessionState(ctx context.Context, sessionID string) (*models.MCPSessionResponse, error) {
	return lds.contextService.GetSessionState(ctx, sessionID)
}

// IsMultiDimensionalEnabled æ£€æŸ¥å¤šç»´åº¦å­˜å‚¨æ˜¯å¦å¯ç”¨
func (lds *LLMDrivenContextService) IsMultiDimensionalEnabled() bool {
	return lds.enabled && lds.multiRetriever != nil
}

// GetMultiDimensionalEngine è·å–å¤šç»´åº¦æ£€ç´¢å¼•æ“ï¼ˆç”¨äºMCPå·¥å…·ï¼‰
func (lds *LLMDrivenContextService) GetMultiDimensionalEngine() interface{} {
	if lds.multiRetriever != nil {
		return lds.multiRetriever
	}
	return nil
}

// SearchContext æœç´¢ä¸Šä¸‹æ–‡
func (lds *LLMDrivenContextService) SearchContext(ctx context.Context, sessionID, query string) ([]string, error) {
	return lds.contextService.SearchContext(ctx, sessionID, query)
}

// AssociateFile å…³è”æ–‡ä»¶
func (lds *LLMDrivenContextService) AssociateFile(ctx context.Context, req models.AssociateFileRequest) error {
	return lds.contextService.AssociateFile(ctx, req)
}

// RecordEdit è®°å½•ç¼–è¾‘
func (lds *LLMDrivenContextService) RecordEdit(ctx context.Context, req models.RecordEditRequest) error {
	return lds.contextService.RecordEdit(ctx, req)
}

// GetUserIDFromSessionID ä»ä¼šè¯IDè·å–ç”¨æˆ·ID
func (lds *LLMDrivenContextService) GetUserIDFromSessionID(sessionID string) (string, error) {
	return lds.contextService.GetUserIDFromSessionID(sessionID)
}

// ============================================================================
// ğŸ”§ å­˜å‚¨å¼•æ“é€‚é…å™¨ - å¿«é€Ÿä¿®å¤æ£€ç´¢é“¾è·¯
// ============================================================================

// TimelineStoreAdapter æ—¶é—´çº¿å­˜å‚¨é€‚é…å™¨
type TimelineStoreAdapter struct {
	Engine interface{}
}

func (adapter *TimelineStoreAdapter) SearchByQuery(ctx context.Context, req *models.TimelineSearchRequest) ([]*models.TimelineEvent, error) {
	// ğŸ”¥ ä¼˜å…ˆä½¿ç”¨è¯·æ±‚å¯¹è±¡ä¸­çš„å­—æ®µï¼ŒContextä½œä¸ºå¤‡ç”¨
	userID := req.UserID
	if userID == "" {
		userID, _ = ctx.Value("user_id").(string)
	}

	workspaceID := req.WorkspaceID
	if workspaceID == "" {
		workspaceID, _ = ctx.Value("workspacePath").(string)
	}

	log.Printf("ğŸ” [æ—¶é—´çº¿é€‚é…å™¨] æ‰§è¡ŒæŸ¥è¯¢: %s, ç”¨æˆ·: %s, é™åˆ¶: %d", req.Query, userID, req.Limit)
	log.Printf("ğŸ” [æ—¶é—´çº¿é€‚é…å™¨] LLMå…³é”®æ¦‚å¿µ: %v", req.KeyConcepts)
	log.Printf("ğŸ” [æ—¶é—´çº¿é€‚é…å™¨] å¼•æ“çŠ¶æ€: %T", adapter.Engine)

	// å¿«é€Ÿå®ç°ï¼šè¿”å›ç©ºç»“æœä½†è®°å½•è¯¦ç»†ä¿¡æ¯ï¼Œé¿å…nil panic
	if adapter.Engine == nil {
		log.Printf("âš ï¸ [æ—¶é—´çº¿é€‚é…å™¨] å¼•æ“ä¸ºnilï¼Œè¿”å›ç©ºç»“æœ")
		return []*models.TimelineEvent{}, nil
	}

	// ğŸ”¥ ä¿®å¤ï¼šå®ç°çœŸå®çš„TimescaleDBæŸ¥è¯¢é€‚é…
	// ä½¿ç”¨æ­£ç¡®çš„å¼•æ“æ¥å£è¿›è¡Œç±»å‹æ–­è¨€
	if timelineEngine, ok := adapter.Engine.(*timeline.TimescaleDBEngine); ok {
		log.Printf("ğŸ”§ [æ—¶é—´çº¿é€‚é…å™¨] æ£€æµ‹åˆ°TimescaleDBå¼•æ“ï¼Œæ„å»ºæŸ¥è¯¢å‚æ•°")

		// ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„TimelineQueryç»“æ„
		timelineQuery := &timeline.TimelineQuery{
			UserID:      userID,
			SearchText:  req.Query,
			Keywords:    req.KeyConcepts, // ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨LLMåˆ†æçš„å…³é”®æ¦‚å¿µ
			Limit:       req.Limit,
			WorkspaceID: utils.ExtractWorkspaceNameFromPath(workspaceID), // ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨å…¬å…±å·¥å…·å‡½æ•°
			OrderBy:     "timestamp",
			// è®¾ç½®æœ€å°ç›¸å…³æ€§è¿‡æ»¤
			MinRelevance: 0.1,
		}

		// ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ­£ç¡®å¤„ç†æ—¶é—´èŒƒå›´å‚æ•°
		if req.StartTime != nil && req.EndTime != nil {
			timelineQuery.StartTime = *req.StartTime
			timelineQuery.EndTime = *req.EndTime
			log.Printf("ğŸ•’ [æ—¶é—´çº¿é€‚é…å™¨] ä½¿ç”¨ç›´æ¥æ—¶é—´èŒƒå›´: %s - %s",
				req.StartTime.Format("2006-01-02 15:04:05"),
				req.EndTime.Format("2006-01-02 15:04:05"))
		} else {
			// æ²¡æœ‰æŒ‡å®šæ—¶é—´èŒƒå›´æ—¶æ‰ä½¿ç”¨é»˜è®¤çš„30å¤©çª—å£
			timelineQuery.TimeWindow = "30 days"
			log.Printf("â° [æ—¶é—´çº¿é€‚é…å™¨] ä½¿ç”¨é»˜è®¤æ—¶é—´çª—å£: 30 days")
		}

		log.Printf("ğŸ“¥ [æ—¶é—´çº¿é€‚é…å™¨] æŸ¥è¯¢å‚æ•°: %+v", timelineQuery)

		// ğŸ”¥ ä½¿ç”¨æ­£ç¡®çš„å¼•æ“æ¥å£è°ƒç”¨
		result, err := timelineEngine.RetrieveEvents(ctx, timelineQuery)
		if err != nil {
			log.Printf("âŒ [æ—¶é—´çº¿é€‚é…å™¨] æŸ¥è¯¢å¤±è´¥: %v", err)
			return []*models.TimelineEvent{}, nil // è¿”å›ç©ºç»“æœè€Œä¸æ˜¯é”™è¯¯ï¼Œä¿æŒæ£€ç´¢é“¾è·¯ç¨³å®š
		}

		// ğŸ”¥ ä¿®å¤ï¼šè½¬æ¢TimelineResultåˆ°models.TimelineEvent
		events := convertTimelineResultToEvents(result)
		log.Printf("âœ… [æ—¶é—´çº¿é€‚é…å™¨] æŸ¥è¯¢æˆåŠŸï¼Œè·å¾—%dä¸ªç»“æœ", len(events))
		return events, nil

	} else {
		log.Printf("âš ï¸ [æ—¶é—´çº¿é€‚é…å™¨] å¼•æ“ç±»å‹ä¸åŒ¹é…: %Tï¼Œè¿”å›ç©ºç»“æœ", adapter.Engine)
		return []*models.TimelineEvent{}, nil
	}
}

// ğŸ†• checkTimelineRecallQuery æ£€æŸ¥æ˜¯å¦ä¸ºæ—¶é—´å›å¿†æŸ¥è¯¢
func (lds *LLMDrivenContextService) checkTimelineRecallQuery(analysisResult *engines.SemanticAnalysisResult) bool {
	// æ£€æŸ¥è¯­æ–™åˆ†æç»“æœä¸­æ˜¯å¦åŒ…å«TimelineRecallå­—æ®µ
	if analysisResult != nil && analysisResult.SmartAnalysis != nil && analysisResult.SmartAnalysis.TimelineRecall != nil {
		startTime := analysisResult.SmartAnalysis.TimelineRecall.StartTime
		endTime := analysisResult.SmartAnalysis.TimelineRecall.EndTime
		if startTime != "" && endTime != "" {
			log.Printf("âœ… [æ—¶é—´å›å¿†æ£€æµ‹] å‘ç°æ—¶é—´å›å¿†æŸ¥è¯¢: %s - %s", startTime, endTime)
			return true
		}
	}
	return false
}

// ğŸ†• handleTimelineRecallQuery å¤„ç†æ—¶é—´å›å¿†æŸ¥è¯¢
func (lds *LLMDrivenContextService) handleTimelineRecallQuery(ctx context.Context, req models.RetrieveContextRequest, analysisResult *engines.SemanticAnalysisResult) (models.ContextResponse, error) {
	timelineRecall := analysisResult.SmartAnalysis.TimelineRecall

	// è§£ææ—¶é—´èŒƒå›´
	startTime, err := time.Parse("2006-01-02 15:04:05", timelineRecall.StartTime)
	if err != nil {
		log.Printf("âŒ [æ—¶é—´å›å¿†] æ—¶é—´è§£æå¤±è´¥ StartTime: %s, error: %v", timelineRecall.StartTime, err)
		return models.ContextResponse{}, fmt.Errorf("æ—¶é—´è§£æå¤±è´¥: %w", err)
	}

	endTime, err := time.Parse("2006-01-02 15:04:05", timelineRecall.EndTime)
	if err != nil {
		log.Printf("âŒ [æ—¶é—´å›å¿†] æ—¶é—´è§£æå¤±è´¥ EndTime: %s, error: %v", timelineRecall.EndTime, err)
		return models.ContextResponse{}, fmt.Errorf("æ—¶é—´è§£æå¤±è´¥: %w", err)
	}

	log.Printf("ğŸ” [æ—¶é—´å›å¿†] æŸ¥è¯¢æ—¶é—´èŒƒå›´: %s åˆ° %s", startTime.Format("2006-01-02 15:04:05"), endTime.Format("2006-01-02 15:04:05"))

	// ğŸ”¥ ä»ç»Ÿä¸€æ‹¦æˆªå™¨æ³¨å…¥çš„contextä¸­ç›´æ¥è·å–ç”¨æˆ·IDå’Œå·¥ä½œç©ºé—´ID
	userID, ok := ctx.Value("user_id").(string)
	if !ok || userID == "" {
		log.Printf("âŒ [æ—¶é—´å›å¿†] ä»contextè·å–ç”¨æˆ·IDå¤±è´¥ï¼Œç»Ÿä¸€æ‹¦æˆªå™¨å¯èƒ½æœªç”Ÿæ•ˆ")
		return models.ContextResponse{}, fmt.Errorf("è·å–ç”¨æˆ·IDå¤±è´¥ï¼šcontextä¸­ç¼ºå°‘user_id")
	}
	log.Printf("âœ… [æ—¶é—´å›å¿†] ä»contextè·å–ç”¨æˆ·ID: %s", userID)

	workspacePath, ok := ctx.Value("workspacePath").(string)
	if !ok || workspacePath == "" {
		log.Printf("âŒ [æ—¶é—´å›å¿†] ä»contextè·å–å·¥ä½œç©ºé—´è·¯å¾„å¤±è´¥ï¼Œç»Ÿä¸€æ‹¦æˆªå™¨å¯èƒ½æœªç”Ÿæ•ˆ")
		return models.ContextResponse{}, fmt.Errorf("è·å–å·¥ä½œç©ºé—´å¤±è´¥ï¼šcontextä¸­ç¼ºå°‘workspacePath")
	}

	// ä»å·¥ä½œç©ºé—´è·¯å¾„æå–workspaceåç§°
	workspaceID := utils.ExtractWorkspaceNameFromPath(workspacePath)
	log.Printf("âœ… [æ—¶é—´å›å¿†] ä»contextè·å–å·¥ä½œç©ºé—´: path=%s, id=%s", workspacePath, workspaceID)

	// ğŸ”¥ çº¯æ—¶é—´çº¿æŸ¥è¯¢ï¼šç”¨æˆ·ID + å·¥ä½œç©ºé—´ + æ—¶é—´èŒƒå›´ï¼Œä¸ä½¿ç”¨å…³é”®è¯è¿‡æ»¤
	timelineQuery := &timeline.TimelineQuery{
		UserID:      userID,      // ğŸ”¥ ä»ä¸Šä¸‹æ–‡æ­£ç¡®è·å–ç”¨æˆ·ID
		WorkspaceID: workspaceID, // ğŸ”¥ æ­£ç¡®æå–çš„workspace ID
		StartTime:   startTime,
		EndTime:     endTime,
		OrderBy:     "timestamp DESC, importance_score DESC",
		Limit:       20,
		// ğŸ”¥ å…³é”®ï¼šä¸è®¾ç½®Keywordså’ŒSearchTextï¼Œçº¯æ—¶é—´èŒƒå›´æŸ¥è¯¢
	}

	// ç›´æ¥æŸ¥è¯¢æ—¶é—´çº¿å¼•æ“
	if lds.multiRetriever != nil {
		events, err := lds.queryTimelineDirectly(ctx, timelineQuery)
		if err != nil {
			log.Printf("âŒ [æ—¶é—´å›å¿†] æ—¶é—´çº¿æŸ¥è¯¢å¤±è´¥: %v", err)
			return models.ContextResponse{}, fmt.Errorf("æ—¶é—´çº¿æŸ¥è¯¢å¤±è´¥: %w", err)
		}

		log.Printf("âœ… [æ—¶é—´å›å¿†] æŸ¥è¯¢æˆåŠŸï¼Œè·å¾— %d ä¸ªæ—¶é—´çº¿äº‹ä»¶", len(events))

		// ğŸ”¥ æ ¼å¼åŒ–æ—¶é—´çº¿æ•°æ®ä¸ºç²¾ç®€çš„JSONæ ¼å¼ï¼ŒåªåŒ…å«å¿…è¦å­—æ®µ
		var timelineData []map[string]interface{}
		for _, event := range events {
			// åªè¿”å›å¿…è¦çš„å­—æ®µï¼štitle, content, summary, related_files, related_concepts,
			// parent_event_id, intent, keywords, relevance_score, created_at
			eventData := map[string]interface{}{
				"title":            event.Title,
				"content":          event.Content,
				"summary":          event.Summary,
				"related_files":    event.RelatedFiles,
				"related_concepts": event.RelatedConcepts,
				"parent_event_id":  event.ParentEventID,
				"intent":           event.Intent,
				"keywords":         event.Keywords,
				"relevance_score":  event.RelevanceScore,
				"created_at":       event.CreatedAt,
			}
			timelineData = append(timelineData, eventData)
		}

		// å°†æ—¶é—´çº¿æ•°æ®åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²
		timelineJSON, err := json.MarshalIndent(timelineData, "", "  ")
		if err != nil {
			log.Printf("âŒ [æ—¶é—´å›å¿†] JSONåºåˆ—åŒ–å¤±è´¥: %v", err)
			return models.ContextResponse{}, fmt.Errorf("æ•°æ®æ ¼å¼åŒ–å¤±è´¥: %w", err)
		}

		log.Printf("âœ… [æ—¶é—´å›å¿†] æ—¶é—´çº¿æ•°æ®å·²æ ¼å¼åŒ–ä¸ºJSONï¼Œå…±%dæ¡è®°å½•", len(timelineData))

		// ğŸ”¥ ä½¿ç”¨åŸæœ‰çš„ContextResponseç»“æ„ï¼Œå°†æ—¶é—´çº¿æ•°æ®å¡«å……åˆ°LongTermMemoryå­—æ®µ
		return models.ContextResponse{
			SessionState:      "",
			ShortTermMemory:   "æš‚æ— ",
			LongTermMemory:    string(timelineJSON), // ğŸ”¥ å…³é”®ï¼šæ—¶é—´çº¿æ•°æ®å¡«å……åˆ°LongTermMemory
			RelevantKnowledge: "æš‚æ— ",
		}, nil
	}

	return models.ContextResponse{}, fmt.Errorf("æ—¶é—´çº¿é€‚é…å™¨ä¸å¯ç”¨")
}

// ğŸ†• queryTimelineDirectly ç›´æ¥æŸ¥è¯¢æ—¶é—´çº¿ï¼ˆä¸“ç”¨äºæ—¶é—´å›å¿†ï¼‰
func (lds *LLMDrivenContextService) queryTimelineDirectly(ctx context.Context, query *timeline.TimelineQuery) ([]*models.TimelineEvent, error) {
	log.Printf("ğŸ“¥ [æ—¶é—´å›å¿†ç›´æŸ¥] æŸ¥è¯¢å‚æ•°: UserID=%s, WorkspaceID=%s, æ—¶é—´èŒƒå›´=%såˆ°%s",
		query.UserID, query.WorkspaceID,
		query.StartTime.Format("2006-01-02 15:04:05"),
		query.EndTime.Format("2006-01-02 15:04:05"))

	// ğŸ”¥ ç›´æ¥è°ƒç”¨å¤šç»´æ£€ç´¢å™¨çš„DirectTimelineQueryæ–¹æ³•
	events, err := lds.multiRetriever.DirectTimelineQuery(ctx, &models.TimelineSearchRequest{
		UserID:      query.UserID,
		WorkspaceID: query.WorkspaceID,
		Query:       "", // ğŸ”¥ ç©ºæŸ¥è¯¢ï¼Œçº¯æ—¶é—´èŒƒå›´è¿‡æ»¤
		Limit:       query.Limit,
		StartTime:   &query.StartTime, // ğŸ”¥ å…³é”®ï¼šä¼ é€’æ—¶é—´èŒƒå›´
		EndTime:     &query.EndTime,   // ğŸ”¥ å…³é”®ï¼šä¼ é€’æ—¶é—´èŒƒå›´
	})

	if err != nil {
		log.Printf("âŒ [æ—¶é—´å›å¿†ç›´æŸ¥] ç›´æ¥æŸ¥è¯¢å¤±è´¥: %v", err)
		return nil, err
	}

	log.Printf("âœ… [æ—¶é—´å›å¿†ç›´æŸ¥] æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› %d ä¸ªäº‹ä»¶", len(events))
	return events, nil
}

// extractWorkspaceFromQuery ä»æŸ¥è¯¢ä¸­æå–å·¥ä½œç©ºé—´ä¿¡æ¯
func extractWorkspaceFromQuery(query string) string {
	// ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ é¡¹ç›®ä¸Šä¸‹æ–‡è¯†åˆ«
	if containsKeywords(query, []string{"context-keeper", "Context-Keeper", "ä¸Šä¸‹æ–‡", "è®°å¿†", "æ£€ç´¢"}) {
		return "context-keeper" // è¿”å›é¡¹ç›®åç§°ä½œä¸ºå·¥ä½œç©ºé—´ID
	}
	return "default"
}

// extractTimeWindowFromQuery ä»æŸ¥è¯¢ä¸­æå–æ—¶é—´çª—å£
func extractTimeWindowFromQuery(query string) string {
	// ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ æ—¶é—´ç»´åº¦è¯†åˆ«
	if containsKeywords(query, []string{"æ˜¨å¤©", "yesterday"}) {
		return "1 day"
	}
	if containsKeywords(query, []string{"ä¸Šå‘¨", "last week"}) {
		return "1 week"
	}
	if containsKeywords(query, []string{"æœ€è¿‘", "recent"}) {
		return "3 days"
	}
	return "" // ä¸é™åˆ¶æ—¶é—´çª—å£
}

// containsKeywords æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦åŒ…å«å…³é”®è¯
func containsKeywords(query string, keywords []string) bool {
	for _, keyword := range keywords {
		if strings.Contains(strings.ToLower(query), strings.ToLower(keyword)) {
			return true
		}
	}
	return false
}

// ğŸ”¥ æ–°å¢ï¼šæ­£ç¡®çš„ç»“æœè½¬æ¢æ–¹æ³•
func convertTimelineResultToEvents(result *timeline.TimelineResult) []*models.TimelineEvent {
	if result == nil || len(result.Events) == 0 {
		log.Printf("âš ï¸ [æ—¶é—´çº¿è½¬æ¢] æ— ç»“æœæ•°æ®")
		return []*models.TimelineEvent{}
	}

	events := make([]*models.TimelineEvent, len(result.Events))
	for i, event := range result.Events {
		events[i] = &models.TimelineEvent{
			ID:          event.ID,
			UserID:      event.UserID,
			SessionID:   event.SessionID,
			WorkspaceID: event.WorkspaceID,
			Timestamp:   event.Timestamp,
			EventType:   event.EventType,
			Title:       event.Title,
			Content:     event.Content,
			Summary:     event.Summary,
			// è½¬æ¢ç›¸å…³æ–‡ä»¶å’Œæ¦‚å¿µ
			RelatedFiles:    convertStringArray(event.RelatedFiles),
			RelatedConcepts: convertStringArray(event.RelatedConcepts),
			// å…¶ä»–å­—æ®µ
			Intent:          event.Intent,
			Keywords:        convertStringArray(event.Keywords),
			Entities:        convertToEntityArray(event.Entities),
			Categories:      convertStringArray(event.Categories),
			ImportanceScore: event.ImportanceScore,
			RelevanceScore:  event.RelevanceScore,
			CreatedAt:       event.CreatedAt,
			UpdatedAt:       event.UpdatedAt,
		}
	}

	log.Printf("âœ… [æ—¶é—´çº¿è½¬æ¢] æˆåŠŸè½¬æ¢ %d ä¸ªäº‹ä»¶", len(events))
	return events
}

// è¾…åŠ©æ–¹æ³•ï¼šè½¬æ¢å­—ç¬¦ä¸²æ•°ç»„
func convertStringArray(pqArray interface{}) []string {
	if pqArray == nil {
		return []string{}
	}

	// å¤„ç†pq.StringArrayç±»å‹
	if arr, ok := pqArray.([]string); ok {
		return arr
	}

	// å¤„ç†å…¶ä»–å¯èƒ½çš„ç±»å‹
	return []string{}
}

// è¾…åŠ©æ–¹æ³•ï¼šè½¬æ¢å®ä½“æ•°ç»„
func convertToEntityArray(entities interface{}) models.EntityArray {
	if entities == nil {
		return models.EntityArray{}
	}

	// å¦‚æœå·²ç»æ˜¯models.EntityArrayç±»å‹
	if arr, ok := entities.(models.EntityArray); ok {
		return arr
	}

	// å¦‚æœæ˜¯timeline.EntityArrayç±»å‹ï¼Œéœ€è¦è½¬æ¢
	if timelineEntities, ok := entities.(timeline.EntityArray); ok {
		result := make(models.EntityArray, len(timelineEntities))
		for i, entity := range timelineEntities {
			result[i] = models.Entity{
				Text:       entity.Text,
				Type:       entity.Type,
				Confidence: entity.Confidence,
			}
		}
		return result
	}

	// å¤„ç†å…¶ä»–å¯èƒ½çš„ç±»å‹
	return models.EntityArray{}
}

// ğŸ”¥ æ–°å¢ï¼šè½¬æ¢çŸ¥è¯†å›¾è°±ç»“æœåˆ°æ¨¡å‹èŠ‚ç‚¹
func convertKnowledgeResultToNodes(result *knowledge.KnowledgeResult) []*models.KnowledgeNode {
	if result == nil || len(result.Nodes) == 0 {
		log.Printf("âš ï¸ [çŸ¥è¯†å›¾è°±è½¬æ¢] æ— ç»“æœæ•°æ®")
		return []*models.KnowledgeNode{}
	}

	nodes := make([]*models.KnowledgeNode, len(result.Nodes))
	for i, node := range result.Nodes {
		nodes[i] = &models.KnowledgeNode{
			ID:          node.ID,
			Name:        node.Name,
			Labels:      node.Labels,
			Category:    node.Category,
			Description: node.Description,
			Keywords:    node.Keywords,
			Score:       node.Score,
			// è½¬æ¢å±æ€§
			Properties: convertPropertiesToMap(node.Properties),
		}
	}

	log.Printf("âœ… [çŸ¥è¯†å›¾è°±è½¬æ¢] æˆåŠŸè½¬æ¢ %d ä¸ªèŠ‚ç‚¹", len(nodes))
	return nodes
}

// è¾…åŠ©æ–¹æ³•ï¼šè½¬æ¢å±æ€§
func convertPropertiesToMap(properties interface{}) map[string]interface{} {
	if properties == nil {
		return map[string]interface{}{}
	}

	// å¦‚æœå·²ç»æ˜¯mapç±»å‹
	if propMap, ok := properties.(map[string]interface{}); ok {
		return propMap
	}

	// å¤„ç†å…¶ä»–å¯èƒ½çš„ç±»å‹
	return map[string]interface{}{}
}

// ğŸ”¥ å®Œå–„ï¼šè½¬æ¢çŸ¥è¯†å›¾è°±å…³ç³»ä¸ºæ ‡å‡†æ ¼å¼
func convertRelationshipsToModels(relationships []knowledge.KnowledgeRelationship, nodeID string) []map[string]interface{} {
	var result []map[string]interface{}

	for _, rel := range relationships {
		// åªåŒ…å«ä¸å½“å‰èŠ‚ç‚¹ç›¸å…³çš„å…³ç³»
		if rel.StartNodeID == nodeID || rel.EndNodeID == nodeID {
			relationship := map[string]interface{}{
				"id":            rel.ID,
				"type":          rel.Type,
				"start_node_id": rel.StartNodeID,
				"end_node_id":   rel.EndNodeID,
				"strength":      rel.Strength,
				"description":   rel.Description,
				"properties":    convertPropertiesToMap(rel.Properties),
				// æ·»åŠ å…³ç³»æ–¹å‘æŒ‡ç¤º
				"direction": getRelationshipDirection(rel, nodeID),
				// æ·»åŠ å…³ç³»æƒé‡è¯„ä¼°
				"weight_category": categorizeRelationshipWeight(rel.Strength),
			}
			result = append(result, relationship)
		}
	}

	log.Printf("ğŸ”— [å…³ç³»è½¬æ¢] ä¸ºèŠ‚ç‚¹ %s è½¬æ¢äº† %d ä¸ªå…³ç³»", nodeID, len(result))
	return result
}

// è·å–å…³ç³»æ–¹å‘
func getRelationshipDirection(rel knowledge.KnowledgeRelationship, nodeID string) string {
	if rel.StartNodeID == nodeID {
		return "outgoing" // å‡ºåº¦å…³ç³»
	} else if rel.EndNodeID == nodeID {
		return "incoming" // å…¥åº¦å…³ç³»
	}
	return "unknown"
}

// åˆ†ç±»å…³ç³»æƒé‡
func categorizeRelationshipWeight(strength float64) string {
	switch {
	case strength >= 0.8:
		return "strong"
	case strength >= 0.5:
		return "medium"
	case strength >= 0.2:
		return "weak"
	default:
		return "minimal"
	}
}

// ä»æŸ¥è¯¢ä¸­æå–åˆ†ç±»
func extractCategoriesFromQuery(query string) []string {
	// ç®€å•çš„åˆ†ç±»æå–é€»è¾‘ï¼Œå¯ä»¥åç»­ä¼˜åŒ–
	categories := []string{}

	// æŠ€æœ¯ç›¸å…³å…³é”®è¯
	techKeywords := []string{"ä»£ç ", "ç¼–ç¨‹", "å¼€å‘", "æ¶æ„", "è®¾è®¡", "ç®—æ³•", "æ•°æ®åº“", "API", "æ¡†æ¶"}
	for _, keyword := range techKeywords {
		if strings.Contains(query, keyword) {
			categories = append(categories, "technology")
			break
		}
	}

	// ä¸šåŠ¡ç›¸å…³å…³é”®è¯
	businessKeywords := []string{"éœ€æ±‚", "ä¸šåŠ¡", "æµç¨‹", "ç®¡ç†", "äº§å“", "ç”¨æˆ·"}
	for _, keyword := range businessKeywords {
		if strings.Contains(query, keyword) {
			categories = append(categories, "business")
			break
		}
	}

	// é»˜è®¤åˆ†ç±»
	if len(categories) == 0 {
		categories = append(categories, "general")
	}

	return categories
}

// ä»æŸ¥è¯¢ä¸­æå–å…³é”®è¯
func extractKeywordsFromQuery(query string) []string {
	// ç®€å•çš„å…³é”®è¯æå–ï¼ŒæŒ‰ç©ºæ ¼åˆ†å‰²å¹¶è¿‡æ»¤åœç”¨è¯
	words := strings.Fields(query)
	keywords := []string{}

	// åœç”¨è¯åˆ—è¡¨
	stopWords := map[string]bool{
		"çš„": true, "æ˜¯": true, "å’Œ": true, "åœ¨": true, "æœ‰": true, "è¿™": true, "é‚£": true,
		"a": true, "an": true, "the": true, "and": true, "or": true, "but": true,
	}

	for _, word := range words {
		word = strings.TrimSpace(word)
		if len(word) > 1 && !stopWords[strings.ToLower(word)] {
			keywords = append(keywords, word)
		}
	}

	return keywords
}

// ğŸ”¥ æ–°å¢ï¼šæŸ¥è¯¢å»é‡å’Œä¼˜åŒ–ï¼ŒåŒºåˆ†ä¸åŒæ•°æ®æºçš„æŸ¥è¯¢ç‰¹ç‚¹
func deduplicateAndOptimizeQueries(queries []string, queryType string) []string {
	if len(queries) == 0 {
		return queries
	}

	log.Printf("ğŸ”„ [æŸ¥è¯¢ä¼˜åŒ–] å¤„ç† %s ç±»å‹æŸ¥è¯¢ï¼ŒåŸå§‹æ•°é‡: %d", queryType, len(queries))

	// ç¬¬ä¸€æ­¥ï¼šåŸºç¡€å»é‡
	seenQueries := make(map[string]bool)
	uniqueQueries := make([]string, 0)

	for _, query := range queries {
		normalizedQuery := strings.TrimSpace(strings.ToLower(query))
		if normalizedQuery != "" && !seenQueries[normalizedQuery] {
			seenQueries[normalizedQuery] = true
			uniqueQueries = append(uniqueQueries, query)
		}
	}

	// ç¬¬äºŒæ­¥ï¼šæ ¹æ®æŸ¥è¯¢ç±»å‹è¿›è¡Œç‰¹åŒ–ä¼˜åŒ–
	optimizedQueries := optimizeQueriesByType(uniqueQueries, queryType)

	// ç¬¬ä¸‰æ­¥ï¼šè¯­ä¹‰å»é‡ï¼ˆç§»é™¤è¿‡äºç›¸ä¼¼çš„æŸ¥è¯¢ï¼‰
	finalQueries := semanticDeduplication(optimizedQueries)

	log.Printf("âœ… [æŸ¥è¯¢ä¼˜åŒ–] %s ç±»å‹æŸ¥è¯¢ä¼˜åŒ–å®Œæˆ: %d -> %d", queryType, len(queries), len(finalQueries))
	return finalQueries
}

// æ ¹æ®æŸ¥è¯¢ç±»å‹è¿›è¡Œç‰¹åŒ–ä¼˜åŒ–
func optimizeQueriesByType(queries []string, queryType string) []string {
	optimized := make([]string, 0)

	for _, query := range queries {
		optimizedQuery := ""

		switch queryType {
		case "context":
			// ä¸Šä¸‹æ–‡æŸ¥è¯¢ï¼šå…³æ³¨å½“å‰ä¼šè¯å’Œè¿‘æœŸæ´»åŠ¨
			optimizedQuery = enhanceContextQuery(query)

		case "timeline":
			// æ—¶é—´çº¿æŸ¥è¯¢ï¼šå¢åŠ æ—¶é—´ç»´åº¦å’Œé¡ºåºæ€§
			optimizedQuery = enhanceTimelineQuery(query)

		case "knowledge":
			// çŸ¥è¯†å›¾è°±æŸ¥è¯¢ï¼šå…³æ³¨æ¦‚å¿µå’Œå…³ç³»
			optimizedQuery = enhanceKnowledgeQuery(query)

		case "vector":
			// å‘é‡æŸ¥è¯¢ï¼šä¿æŒåŸå§‹è¯­ä¹‰
			optimizedQuery = enhanceVectorQuery(query)

		default:
			optimizedQuery = query
		}

		if optimizedQuery != "" && optimizedQuery != query {
			log.Printf("ğŸ”§ [æŸ¥è¯¢ç‰¹åŒ–] %s: %s -> %s", queryType, query, optimizedQuery)
		}

		optimized = append(optimized, optimizedQuery)
	}

	return optimized
}

// å¢å¼ºä¸Šä¸‹æ–‡æŸ¥è¯¢
func enhanceContextQuery(query string) string {
	// ä¸Šä¸‹æ–‡æŸ¥è¯¢å…³æ³¨å½“å‰ä¼šè¯çŠ¶æ€å’Œç”¨æˆ·æ„å›¾
	if !strings.Contains(query, "å½“å‰") && !strings.Contains(query, "current") {
		return "å½“å‰ä¼šè¯ " + query
	}
	return query
}

// å¢å¼ºæ—¶é—´çº¿æŸ¥è¯¢
func enhanceTimelineQuery(query string) string {
	// ğŸ”§ ä¿®å¤ï¼šä¸å†æ·»åŠ "å†å²æ´»åŠ¨"å‰ç¼€ï¼Œç›´æ¥è¿”å›åŸæŸ¥è¯¢
	// åŸå› ï¼šæ·»åŠ å‰ç¼€å¯¼è‡´åŒ…å«ä¸å­˜åœ¨è¯æ±‡ï¼ŒPostgreSQL ANDé€»è¾‘æŸ¥è¯¢å¤±è´¥
	return query
}

// å¢å¼ºçŸ¥è¯†å›¾è°±æŸ¥è¯¢
func enhanceKnowledgeQuery(query string) string {
	// çŸ¥è¯†å›¾è°±æŸ¥è¯¢å…³æ³¨æ¦‚å¿µå’Œå…³ç³»
	if !containsConceptKeywords(query) {
		return "ç›¸å…³æ¦‚å¿µ " + query
	}
	return query
}

// å¢å¼ºå‘é‡æŸ¥è¯¢
func enhanceVectorQuery(query string) string {
	// å‘é‡æŸ¥è¯¢ä¿æŒåŸå§‹è¯­ä¹‰ï¼Œç”¨äºè¯­ä¹‰ç›¸ä¼¼æ€§åŒ¹é…
	return query
}

// æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¶é—´å…³é”®è¯
func containsTimeKeywords(query string) bool {
	timeKeywords := []string{"æœ€è¿‘", "å†å²", "ä¹‹å‰", "æ—¶é—´", "å½“æ—¶", "è¿‡å»", "earlier", "recent", "history", "time"}
	queryLower := strings.ToLower(query)
	for _, keyword := range timeKeywords {
		if strings.Contains(queryLower, keyword) {
			return true
		}
	}
	return false
}

// æ£€æŸ¥æ˜¯å¦åŒ…å«æ¦‚å¿µå…³é”®è¯
func containsConceptKeywords(query string) bool {
	conceptKeywords := []string{"æ¦‚å¿µ", "å…³ç³»", "ç›¸å…³", "ç±»ä¼¼", "å…³è”", "concept", "related", "similar", "connection"}
	queryLower := strings.ToLower(query)
	for _, keyword := range conceptKeywords {
		if strings.Contains(queryLower, keyword) {
			return true
		}
	}
	return false
}

// è¯­ä¹‰å»é‡ï¼šç§»é™¤è¿‡äºç›¸ä¼¼çš„æŸ¥è¯¢
func semanticDeduplication(queries []string) []string {
	if len(queries) <= 1 {
		return queries
	}

	deduplicated := make([]string, 0)

	for i, query1 := range queries {
		isDuplicate := false

		for j := 0; j < i; j++ {
			query2 := queries[j]
			// ç®€å•çš„è¯­ä¹‰ç›¸ä¼¼æ€§æ£€æŸ¥ï¼šè®¡ç®—è¯æ±‡é‡å åº¦
			similarity := calculateQuerySimilarity(query1, query2)
			if similarity > 0.8 { // ç›¸ä¼¼åº¦é˜ˆå€¼
				log.Printf("ğŸ” [è¯­ä¹‰å»é‡] ç§»é™¤ç›¸ä¼¼æŸ¥è¯¢: '%s' (ä¸ '%s' ç›¸ä¼¼åº¦: %.2f)", query1, query2, similarity)
				isDuplicate = true
				break
			}
		}

		if !isDuplicate {
			deduplicated = append(deduplicated, query1)
		}
	}

	return deduplicated
}

// è®¡ç®—æŸ¥è¯¢ç›¸ä¼¼æ€§
func calculateQuerySimilarity(query1, query2 string) float64 {
	words1 := extractKeywordsFromQuery(query1)
	words2 := extractKeywordsFromQuery(query2)

	if len(words1) == 0 && len(words2) == 0 {
		return 1.0
	}
	if len(words1) == 0 || len(words2) == 0 {
		return 0.0
	}

	// è®¡ç®—è¯æ±‡äº¤é›†
	intersection := 0
	word2Set := make(map[string]bool)
	for _, word := range words2 {
		word2Set[strings.ToLower(word)] = true
	}

	for _, word := range words1 {
		if word2Set[strings.ToLower(word)] {
			intersection++
		}
	}

	// è®¡ç®—Jaccardç›¸ä¼¼æ€§
	union := len(words1) + len(words2) - intersection
	if union == 0 {
		return 0.0
	}

	return float64(intersection) / float64(union)
}

// KnowledgeStoreAdapter çŸ¥è¯†å›¾è°±å­˜å‚¨é€‚é…å™¨
type KnowledgeStoreAdapter struct {
	Engine interface{}
}

func (adapter *KnowledgeStoreAdapter) SearchByQuery(ctx context.Context, query string, limit int) ([]*models.KnowledgeNode, error) {
	// ğŸ”¥ ä»Contextè·å–åŸºç¡€ä¿¡æ¯ï¼Œè€Œéå‚æ•°ä¼ é€’
	userID, _ := ctx.Value("user_id").(string)

	log.Printf("ğŸ” [çŸ¥è¯†å›¾è°±é€‚é…å™¨] æ‰§è¡ŒæŸ¥è¯¢: %s, ç”¨æˆ·: %s, é™åˆ¶: %d", query, userID, limit)
	log.Printf("ğŸ” [çŸ¥è¯†å›¾è°±é€‚é…å™¨] å¼•æ“çŠ¶æ€: %T", adapter.Engine)

	// å¿«é€Ÿå®ç°ï¼šè¿”å›ç©ºç»“æœä½†è®°å½•è¯¦ç»†ä¿¡æ¯ï¼Œé¿å…nil panic
	if adapter.Engine == nil {
		log.Printf("âš ï¸ [çŸ¥è¯†å›¾è°±é€‚é…å™¨] å¼•æ“ä¸ºnilï¼Œè¿”å›ç©ºç»“æœ")
		return []*models.KnowledgeNode{}, nil
	}

	// ğŸ”¥ ä¿®å¤ï¼šå®ç°çœŸå®çš„Neo4jæŸ¥è¯¢é€‚é…
	if knowledgeEngine, ok := adapter.Engine.(*knowledge.Neo4jEngine); ok {
		log.Printf("ğŸ”§ [çŸ¥è¯†å›¾è°±é€‚é…å™¨] æ£€æµ‹åˆ°Neo4jå¼•æ“ï¼Œæ„å»ºæŸ¥è¯¢å‚æ•°")

		// ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„KnowledgeQueryç»“æ„
		knowledgeQuery := &knowledge.KnowledgeQuery{
			UserID:     userID,
			SearchText: query,
			Limit:      limit,
			// è®¾ç½®æŸ¥è¯¢ç±»å‹å’ŒèŒƒå›´
			QueryType:   "search", // æœç´¢æŸ¥è¯¢
			Categories:  extractCategoriesFromQuery(query),
			Keywords:    extractKeywordsFromQuery(query),
			MaxDepth:    3,   // æœ€å¤§æ·±åº¦3å±‚
			MinStrength: 0.1, // æœ€å°å…³ç³»å¼ºåº¦
		}

		log.Printf("ğŸ“¥ [çŸ¥è¯†å›¾è°±é€‚é…å™¨] æŸ¥è¯¢å‚æ•°: %+v", knowledgeQuery)

		// ğŸ”¥ ä½¿ç”¨æ­£ç¡®çš„å¼•æ“æ¥å£è°ƒç”¨
		result, err := knowledgeEngine.ExpandKnowledge(ctx, knowledgeQuery)
		if err != nil {
			log.Printf("âŒ [çŸ¥è¯†å›¾è°±é€‚é…å™¨] æŸ¥è¯¢å¤±è´¥: %v", err)
			return []*models.KnowledgeNode{}, nil // è¿”å›ç©ºç»“æœè€Œä¸æ˜¯é”™è¯¯ï¼Œä¿æŒæ£€ç´¢é“¾è·¯ç¨³å®š
		}

		// ğŸ”¥ ä¿®å¤ï¼šè½¬æ¢KnowledgeResultåˆ°models.KnowledgeNode
		nodes := convertKnowledgeResultToNodes(result)
		log.Printf("âœ… [çŸ¥è¯†å›¾è°±é€‚é…å™¨] æŸ¥è¯¢æˆåŠŸï¼Œè·å¾—%dä¸ªç»“æœ", len(nodes))
		return nodes, nil

	} else {
		log.Printf("âš ï¸ [çŸ¥è¯†å›¾è°±é€‚é…å™¨] å¼•æ“ç±»å‹ä¸åŒ¹é…: %Tï¼Œè¿”å›ç©ºç»“æœ", adapter.Engine)
		return []*models.KnowledgeNode{}, nil
	}
}

// VectorStoreAdapter å‘é‡å­˜å‚¨é€‚é…å™¨
type VectorStoreAdapter struct {
	Engine interface{}
}

func (adapter *VectorStoreAdapter) SearchByQuery(ctx context.Context, query string, limit int) ([]*models.VectorMatch, error) {
	// ğŸ”¥ ä»Contextè·å–åŸºç¡€ä¿¡æ¯ï¼Œè€Œéå‚æ•°ä¼ é€’
	userID, _ := ctx.Value("user_id").(string)

	log.Printf("ğŸ” [å‘é‡é€‚é…å™¨] æ‰§è¡ŒæŸ¥è¯¢: %s, ç”¨æˆ·: %s, é™åˆ¶: %d", query, userID, limit)
	log.Printf("ğŸ” [å‘é‡é€‚é…å™¨] å¼•æ“çŠ¶æ€: %T", adapter.Engine)

	// å¿«é€Ÿå®ç°ï¼šè¿”å›ç©ºç»“æœä½†è®°å½•è¯¦ç»†ä¿¡æ¯ï¼Œé¿å…nil panic
	if adapter.Engine == nil {
		log.Printf("âš ï¸ [å‘é‡é€‚é…å™¨] å¼•æ“ä¸ºnilï¼Œè¿”å›ç©ºç»“æœ")
		return []*models.VectorMatch{}, nil
	}

	// ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„ç±»å‹æ–­è¨€æ¨¡å¼
	if vectorStore, ok := adapter.Engine.(models.VectorStore); ok {
		log.Printf("ğŸ”§ [å‘é‡é€‚é…å™¨] æ£€æµ‹åˆ°VectorStoreå¼•æ“ï¼Œæ„å»ºæŸ¥è¯¢å‚æ•°")

		// æ„å»ºSearchOptions
		options := &models.SearchOptions{
			Limit:  limit,
			UserID: userID,
		}

		log.Printf("ğŸ“¥ [å‘é‡é€‚é…å™¨] æŸ¥è¯¢å‚æ•°: %+v", options)

		// ğŸ”¥ ä½¿ç”¨æ­£ç¡®çš„æ¥å£è°ƒç”¨vectorStore.SearchByText
		results, err := vectorStore.SearchByText(ctx, query, options)
		if err != nil {
			log.Printf("âŒ [å‘é‡é€‚é…å™¨] æŸ¥è¯¢å¤±è´¥: %v", err)
			return []*models.VectorMatch{}, nil // è¿”å›ç©ºç»“æœè€Œä¸æ˜¯é”™è¯¯ï¼Œä¿æŒæ£€ç´¢é“¾è·¯ç¨³å®š
		}

		// ğŸ”¥ è½¬æ¢SearchResult[]åˆ°VectorMatch[]
		matches := convertSearchResultsToVectorMatches(results)
		log.Printf("âœ… [å‘é‡é€‚é…å™¨] æŸ¥è¯¢æˆåŠŸï¼Œè·å¾—%dä¸ªç»“æœ", len(matches))
		return matches, nil

	} else {
		log.Printf("âš ï¸ [å‘é‡é€‚é…å™¨] å¼•æ“ç±»å‹ä¸åŒ¹é…: %Tï¼Œè¿”å›ç©ºç»“æœ", adapter.Engine)
		return []*models.VectorMatch{}, nil
	}
}

// SetEngine è®¾ç½®å‘é‡å­˜å‚¨çš„Engineï¼ˆç”¨äºå»¶è¿Ÿèµ‹å€¼ï¼‰
func (adapter *VectorStoreAdapter) SetEngine(engine interface{}) {
	adapter.Engine = engine
	log.Printf("âœ… [å‘é‡é€‚é…å™¨] Engineå·²è®¾ç½®: %T", engine)
}

// convertSearchResultsToVectorMatches è½¬æ¢SearchResultåˆ°VectorMatch
func convertSearchResultsToVectorMatches(results []models.SearchResult) []*models.VectorMatch {
	matches := make([]*models.VectorMatch, 0, len(results))

	for _, result := range results {
		match := &models.VectorMatch{
			ID:    result.ID,
			Score: result.Score,
		}

		// ä»Fieldsä¸­æå–Contentå’ŒMetadata
		if result.Fields != nil {
			if content, ok := result.Fields["content"].(string); ok {
				match.Content = content
			}
			if title, ok := result.Fields["title"].(string); ok {
				match.Title = title
			}
			// å…¶ä»–å­—æ®µä½œä¸ºMetadata
			match.Metadata = make(map[string]interface{})
			for k, v := range result.Fields {
				if k != "content" && k != "title" {
					match.Metadata[k] = v
				}
			}
		}

		matches = append(matches, match)
	}

	log.Printf("ğŸ”„ [ç»“æœè½¬æ¢] è½¬æ¢äº† %d ä¸ªSearchResultåˆ°VectorMatch", len(matches))
	return matches
}

// buildEnhancedQuery æ„å»ºåŒ…å«é¡¹ç›®ä¸Šä¸‹æ–‡çš„å¢å¼ºæŸ¥è¯¢
func buildEnhancedQuery(originalQuery, userID string) string {
	// ğŸ”¥ å…³é”®ä¿®å¤ï¼šåœ¨æŸ¥è¯¢ä¸­æ·»åŠ é¡¹ç›®ä¸Šä¸‹æ–‡ä¿¡æ¯
	projectContext := "context-keeperé¡¹ç›® "

	// å¦‚æœæŸ¥è¯¢ä¸­å·²ç»åŒ…å«é¡¹ç›®ä¿¡æ¯ï¼Œåˆ™ä¸é‡å¤æ·»åŠ 
	if containsKeywords(originalQuery, []string{"context-keeper", "Context-Keeper"}) {
		return originalQuery
	}

	// æ·»åŠ é¡¹ç›®ä¸Šä¸‹æ–‡
	return projectContext + originalQuery
}

// buildProjectContextFilter æ„å»ºé¡¹ç›®ä¸Šä¸‹æ–‡è¿‡æ»¤å™¨
func buildProjectContextFilter(userID, query string) string {
	// ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ„å»ºåŒ…å«ç”¨æˆ·å’Œé¡¹ç›®ä¿¡æ¯çš„è¿‡æ»¤å™¨
	var filterParts []string

	// ç”¨æˆ·è¿‡æ»¤ï¼ˆå¿…é¡»ï¼‰
	if userID != "" {
		filterParts = append(filterParts, fmt.Sprintf(`userId="%s"`, userID))
	}

	// é¡¹ç›®ä¸Šä¸‹æ–‡è¿‡æ»¤ï¼ˆå¦‚æœæŸ¥è¯¢æ¶‰åŠç‰¹å®šé¡¹ç›®ï¼‰
	if containsKeywords(query, []string{"context-keeper", "Context-Keeper", "ä¸Šä¸‹æ–‡", "è®°å¿†"}) {
		// å¯ä»¥æ·»åŠ é¡¹ç›®ç›¸å…³çš„è¿‡æ»¤æ¡ä»¶ï¼Œæ¯”å¦‚workspace_idæˆ–project_name
		// filterParts = append(filterParts, `project="context-keeper"`)
	}

	if len(filterParts) > 0 {
		return strings.Join(filterParts, " AND ")
	}

	return ""
}

// convertToVectorMatches è½¬æ¢æœç´¢ç»“æœä¸ºå‘é‡åŒ¹é…æ ¼å¼
func convertToVectorMatches(results []models.SearchResult) []*models.VectorMatch {
	var matches []*models.VectorMatch

	for _, result := range results {
		// ğŸ”¥ ä¿®å¤ï¼šä»Fieldsä¸­æå–å†…å®¹ï¼Œå› ä¸ºSearchResultçš„å†…å®¹åœ¨Fieldsä¸­
		content := ""
		title := ""
		if result.Fields != nil {
			if c, ok := result.Fields["content"].(string); ok {
				content = c
			}
			if t, ok := result.Fields["title"].(string); ok {
				title = t
			}
		}

		match := &models.VectorMatch{
			ID:      result.ID,
			Content: content,
			Title:   title,
			Score:   result.Score,
			// å¯ä»¥æ·»åŠ æ›´å¤šå­—æ®µæ˜ å°„
			Metadata: result.Fields, // ä¿ç•™åŸå§‹å­—æ®µä¿¡æ¯
		}
		matches = append(matches, match)
	}

	log.Printf("ğŸ”„ [å‘é‡é€‚é…å™¨] è½¬æ¢äº†%dä¸ªæœç´¢ç»“æœä¸ºå‘é‡åŒ¹é…", len(matches))
	return matches
}

// GetUserSessionStore è·å–ç”¨æˆ·ä¼šè¯å­˜å‚¨
func (lds *LLMDrivenContextService) GetUserSessionStore(userID string) (*store.SessionStore, error) {
	return lds.contextService.GetUserSessionStore(userID)
}

// SessionStore è¿”å›ä¼šè¯å­˜å‚¨å®ä¾‹
func (lds *LLMDrivenContextService) SessionStore() *store.SessionStore {
	return lds.contextService.SessionStore()
}

// SummarizeToLongTermMemory æ€»ç»“åˆ°é•¿æœŸè®°å¿†
func (lds *LLMDrivenContextService) SummarizeToLongTermMemory(ctx context.Context, req models.SummarizeToLongTermRequest) (string, error) {
	return lds.contextService.SummarizeToLongTermMemory(ctx, req)
}

// RetrieveTodos è·å–å¾…åŠäº‹é¡¹
func (lds *LLMDrivenContextService) RetrieveTodos(ctx context.Context, req models.RetrieveTodosRequest) (*models.RetrieveTodosResponse, error) {
	return lds.contextService.RetrieveTodos(ctx, req)
}

// StartSessionCleanupTask å¯åŠ¨ä¼šè¯æ¸…ç†ä»»åŠ¡ï¼ˆä»£ç†åˆ°åº•å±‚ContextServiceï¼‰
func (lds *LLMDrivenContextService) StartSessionCleanupTask(ctx context.Context, timeout time.Duration, interval time.Duration) {
	lds.contextService.StartSessionCleanupTask(ctx, timeout, interval)
}

// è¿è¡Œæ—¶æ§åˆ¶æ¥å£
func (lds *LLMDrivenContextService) EnableLLMDriven(enabled bool) {
	lds.enabled = enabled
	if enabled {
		log.Printf("âœ… [LLMé©±åŠ¨æœåŠ¡] LLMé©±åŠ¨åŠŸèƒ½å·²å¯ç”¨")
	} else {
		log.Printf("âšª [LLMé©±åŠ¨æœåŠ¡] LLMé©±åŠ¨åŠŸèƒ½å·²ç¦ç”¨ï¼Œå°†ä½¿ç”¨åŸºç¡€ContextService")
	}
}

// GetMetrics è·å–ç›‘æ§æŒ‡æ ‡
func (lds *LLMDrivenContextService) GetMetrics() *LLMDrivenMetrics {
	return lds.metrics
}

// GetStatus è·å–æœåŠ¡çŠ¶æ€
func (lds *LLMDrivenContextService) GetStatus() map[string]interface{} {
	return map[string]interface{}{
		"enabled":             lds.enabled,
		"semantic_analysis":   lds.config.SemanticAnalysis,
		"multi_dimensional":   lds.config.MultiDimensional,
		"content_synthesis":   lds.config.ContentSynthesis,
		"total_requests":      lds.metrics.TotalRequests,
		"llm_driven_requests": lds.metrics.LLMDrivenRequests,
		"fallback_requests":   lds.metrics.FallbackRequests,
		"success_rate":        lds.metrics.SuccessRate,
		"error_count":         lds.metrics.ErrorCount,
		"last_updated":        lds.metrics.LastUpdated,
	}
}

// updateMetrics æ›´æ–°æ€§èƒ½æŒ‡æ ‡
func (lds *LLMDrivenContextService) updateMetrics(latency time.Duration, success bool) {
	// æ›´æ–°å¹³å‡å»¶è¿Ÿ
	if lds.metrics.LLMDrivenRequests > 0 {
		lds.metrics.AverageLatency = (lds.metrics.AverageLatency*time.Duration(lds.metrics.LLMDrivenRequests-1) + latency) / time.Duration(lds.metrics.LLMDrivenRequests)
	} else {
		lds.metrics.AverageLatency = latency
	}

	// æ›´æ–°æˆåŠŸç‡
	if success && lds.metrics.LLMDrivenRequests > 0 {
		lds.metrics.SuccessRate = float64(lds.metrics.LLMDrivenRequests-lds.metrics.ErrorCount) / float64(lds.metrics.LLMDrivenRequests)
	}

	lds.metrics.LastUpdated = time.Now()
}
