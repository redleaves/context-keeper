package services

import (
	"context"
	"fmt"
	"log"
	"sync"
	"time"

	"github.com/contextkeeper/service/internal/models"
	// TODO: åˆ›å»ºè¿™äº›åŒ…çš„æ¥å£
	// "github.com/contextkeeper/service/internal/services/llm"
	// "github.com/contextkeeper/service/internal/storage"
)

// WideRecallService å®½å¬å›æœåŠ¡
type WideRecallService struct {
	// === å­˜å‚¨å¼•æ“ ===
	timelineStore  TimelineStore  // æ—¶é—´çº¿å­˜å‚¨
	knowledgeStore KnowledgeStore // çŸ¥è¯†å›¾è°±å­˜å‚¨
	vectorStore    VectorStore    // å‘é‡å­˜å‚¨

	// === LLMæœåŠ¡ ===
	llmService LLMService // LLMæœåŠ¡

	// === é…ç½® ===
	config *WideRecallConfig // é…ç½®

	// === å¹¶å‘æ§åˆ¶ ===
	mu sync.RWMutex // è¯»å†™é”
}

// WideRecallConfig å®½å¬å›é…ç½®
type WideRecallConfig struct {
	// === è¶…æ—¶é…ç½® ===
	LLMTimeout       int `json:"llm_timeout"`       // LLMè¶…æ—¶æ—¶é—´(ç§’)
	TimelineTimeout  int `json:"timeline_timeout"`  // æ—¶é—´çº¿æ£€ç´¢è¶…æ—¶(ç§’)
	KnowledgeTimeout int `json:"knowledge_timeout"` // çŸ¥è¯†å›¾è°±æ£€ç´¢è¶…æ—¶(ç§’)
	VectorTimeout    int `json:"vector_timeout"`    // å‘é‡æ£€ç´¢è¶…æ—¶(ç§’)

	// === ç»“æœæ•°é‡é™åˆ¶ ===
	TimelineMaxResults  int `json:"timeline_max_results"`  // æ—¶é—´çº¿æœ€å¤§ç»“æœæ•°
	KnowledgeMaxResults int `json:"knowledge_max_results"` // çŸ¥è¯†å›¾è°±æœ€å¤§ç»“æœæ•°
	VectorMaxResults    int `json:"vector_max_results"`    // å‘é‡æœ€å¤§ç»“æœæ•°

	// === è´¨é‡é˜ˆå€¼ ===
	MinSimilarityScore   float64 `json:"min_similarity_score"`  // æœ€å°ç›¸ä¼¼åº¦åˆ†æ•°
	MinRelevanceScore    float64 `json:"min_relevance_score"`   // æœ€å°ç›¸å…³æ€§åˆ†æ•°
	ConfidenceThreshold  float64 `json:"confidence_threshold"`  // ç½®ä¿¡åº¦é˜ˆå€¼
	UpdateThreshold      float64 `json:"update_threshold"`      // æ›´æ–°é˜ˆå€¼
	PersistenceThreshold float64 `json:"persistence_threshold"` // æŒä¹…åŒ–é˜ˆå€¼

	// === é‡è¯•é…ç½® ===
	MaxRetries    int `json:"max_retries"`    // æœ€å¤§é‡è¯•æ¬¡æ•°
	RetryInterval int `json:"retry_interval"` // é‡è¯•é—´éš”(ç§’)
}

// NewWideRecallService åˆ›å»ºå®½å¬å›æœåŠ¡
func NewWideRecallService(
	timelineStore TimelineStore,
	knowledgeStore KnowledgeStore,
	vectorStore VectorStore,
	llmService LLMService,
	config *WideRecallConfig,
) *WideRecallService {
	if config == nil {
		config = getDefaultWideRecallConfig()
	}

	return &WideRecallService{
		timelineStore:  timelineStore,
		knowledgeStore: knowledgeStore,
		vectorStore:    vectorStore,
		llmService:     llmService,
		config:         config,
	}
}

// ExecuteWideRecall æ‰§è¡Œå®½å¬å›æ£€ç´¢
func (s *WideRecallService) ExecuteWideRecall(ctx context.Context, req *models.WideRecallRequest) (*models.WideRecallResponse, error) {
	startTime := time.Now()

	// === é˜¶æ®µ1: LLMæ„å›¾åˆ†æå’ŒæŸ¥è¯¢æ‹†è§£ ===
	intentAnalysis, err := s.analyzeUserIntent(ctx, req.UserQuery)
	if err != nil {
		return nil, fmt.Errorf("æ„å›¾åˆ†æå¤±è´¥: %w", err)
	}

	// === é˜¶æ®µ2: å¹¶è¡Œå®½å¬å›æ£€ç´¢ ===
	retrievalResults, err := s.executeParallelRetrieval(ctx, intentAnalysis, req)
	if err != nil {
		return nil, fmt.Errorf("å¹¶è¡Œæ£€ç´¢å¤±è´¥: %w", err)
	}

	// === æ„å»ºå“åº” ===
	response := &models.WideRecallResponse{
		Success:          true,
		Message:          "å®½å¬å›æ£€ç´¢æˆåŠŸ",
		RequestID:        generateWideRecallRequestID(),
		ProcessTime:      time.Since(startTime).Milliseconds(),
		RetrievalResults: retrievalResults,
		ResponseTime:     time.Now(),
	}

	return response, nil
}

// ExecuteContextSynthesis æ‰§è¡Œä¸Šä¸‹æ–‡åˆæˆ
func (s *WideRecallService) ExecuteContextSynthesis(ctx context.Context, req *models.ContextSynthesisRequest) (*models.ContextSynthesisResponse, error) {
	startTime := time.Now()

	// === é˜¶æ®µ3: LLMè¯„ä¼°èåˆå’Œä¸Šä¸‹æ–‡åˆæˆ ===
	synthesisResult, err := s.synthesizeAndEvaluateContext(ctx, req)
	if err != nil {
		return nil, fmt.Errorf("ä¸Šä¸‹æ–‡åˆæˆå¤±è´¥: %w", err)
	}

	// === æ„å»ºå“åº” ===
	response := &models.ContextSynthesisResponse{
		Success:            true,
		Message:            "ä¸Šä¸‹æ–‡åˆæˆæˆåŠŸ",
		RequestID:          generateWideRecallRequestID(),
		ProcessTime:        time.Since(startTime).Milliseconds(),
		EvaluationResult:   synthesisResult.EvaluationResult,
		SynthesizedContext: synthesisResult.SynthesizedContext,
		SynthesisMetadata:  synthesisResult.SynthesisMetadata,
		ResponseTime:       time.Now(),
	}

	return response, nil
}

// analyzeUserIntent åˆ†æç”¨æˆ·æ„å›¾
func (s *WideRecallService) analyzeUserIntent(ctx context.Context, userQuery string) (*models.WideRecallIntentAnalysis, error) {
	// åˆ›å»ºå¸¦è¶…æ—¶çš„ä¸Šä¸‹æ–‡
	timeoutCtx, cancel := context.WithTimeout(ctx, time.Duration(s.config.LLMTimeout)*time.Second)
	defer cancel()

	// æ„å»ºæ„å›¾åˆ†æPrompt
	prompt := s.buildIntentAnalysisPrompt(userQuery)

	// è°ƒç”¨LLMè¿›è¡Œæ„å›¾åˆ†æ
	llmRequest := &GenerateRequest{
		Prompt:      prompt,
		MaxTokens:   4000, // å¢åŠ tokené™åˆ¶
		Temperature: 0.1,  // é™ä½æ¸©åº¦æé«˜ä¸€è‡´æ€§
		Format:      "json",
	}

	log.Printf("ğŸ¤– [æ–¹æ¡ˆ1-R1æ¨¡å‹] æ„å›¾åˆ†æLLMè¯·æ±‚")
	log.Printf("ğŸ“¤ [æ„å›¾åˆ†æè¯·æ±‚] Prompté•¿åº¦: %då­—ç¬¦", len(llmRequest.Prompt))
	log.Printf("ğŸ“¤ [æ„å›¾åˆ†æè¯·æ±‚] MaxTokens: %d, Temperature: %.1f", llmRequest.MaxTokens, llmRequest.Temperature)
	log.Printf("ğŸ“¤ [æ„å›¾åˆ†æè¯·æ±‚] Promptå‰300å­—ç¬¦:\n%s", llmRequest.Prompt[:min(300, len(llmRequest.Prompt))])

	response, err := s.llmService.GenerateResponse(timeoutCtx, llmRequest)
	if err != nil {
		log.Printf("âŒ [æ„å›¾åˆ†æå“åº”] LLMè°ƒç”¨å¤±è´¥: %v", err)
		return nil, fmt.Errorf("LLMæ„å›¾åˆ†æå¤±è´¥: %w", err)
	}

	log.Printf("ğŸ“¥ [æ„å›¾åˆ†æå“åº”] å“åº”é•¿åº¦: %då­—ç¬¦", len(response.Content))
	log.Printf("ğŸ“¥ [æ„å›¾åˆ†æå“åº”] Tokenä½¿ç”¨: Prompt=%d, Completion=%d, Total=%d",
		response.Usage.PromptTokens, response.Usage.CompletionTokens, response.Usage.TotalTokens)
	log.Printf("ğŸ“¥ [æ„å›¾åˆ†æå“åº”] å†…å®¹å‰800å­—ç¬¦:\n%s", response.Content[:min(800, len(response.Content))])

	// è§£æLLMå“åº”
	intentAnalysis, err := s.parseIntentAnalysisResponse(response.Content)
	if err != nil {
		return nil, fmt.Errorf("è§£ææ„å›¾åˆ†æç»“æœå¤±è´¥: %w", err)
	}

	return intentAnalysis, nil
}

// executeParallelRetrieval æ‰§è¡Œå¹¶è¡Œæ£€ç´¢
func (s *WideRecallService) executeParallelRetrieval(ctx context.Context, intentAnalysis *models.WideRecallIntentAnalysis, req *models.WideRecallRequest) (*models.RetrievalResults, error) {
	// åˆ›å»ºç»“æœé€šé“
	timelineResultChan := make(chan *TimelineRetrievalResult, 1)
	knowledgeResultChan := make(chan *KnowledgeRetrievalResult, 1)
	vectorResultChan := make(chan *VectorRetrievalResult, 1)

	// å¯åŠ¨å¹¶è¡Œæ£€ç´¢
	var wg sync.WaitGroup

	// æ—¶é—´çº¿æ£€ç´¢
	wg.Add(1)
	go func() {
		defer wg.Done()
		result := s.executeTimelineRetrieval(ctx, intentAnalysis.RetrievalStrategy.TimelineQueries, req)
		timelineResultChan <- result
	}()

	// çŸ¥è¯†å›¾è°±æ£€ç´¢
	wg.Add(1)
	go func() {
		defer wg.Done()
		result := s.executeKnowledgeRetrieval(ctx, intentAnalysis.RetrievalStrategy.KnowledgeQueries, req)
		knowledgeResultChan <- result
	}()

	// å‘é‡æ£€ç´¢
	wg.Add(1)
	go func() {
		defer wg.Done()
		result := s.executeVectorRetrieval(ctx, intentAnalysis.RetrievalStrategy.VectorQueries, req)
		vectorResultChan <- result
	}()

	// ç­‰å¾…æ‰€æœ‰æ£€ç´¢å®Œæˆ
	wg.Wait()
	close(timelineResultChan)
	close(knowledgeResultChan)
	close(vectorResultChan)

	// æ”¶é›†ç»“æœ
	timelineResult := <-timelineResultChan
	knowledgeResult := <-knowledgeResultChan
	vectorResult := <-vectorResultChan

	// æ„å»ºæ±‡æ€»ç»“æœ
	retrievalResults := &models.RetrievalResults{
		TimelineResults:  timelineResult.Results,
		TimelineCount:    len(timelineResult.Results),
		TimelineStatus:   timelineResult.Status,
		KnowledgeResults: knowledgeResult.Results,
		KnowledgeCount:   len(knowledgeResult.Results),
		KnowledgeStatus:  knowledgeResult.Status,
		VectorResults:    vectorResult.Results,
		VectorCount:      len(vectorResult.Results),
		VectorStatus:     vectorResult.Status,
		TotalResults:     len(timelineResult.Results) + len(knowledgeResult.Results) + len(vectorResult.Results),
		OverallQuality:   s.calculateOverallQuality(timelineResult, knowledgeResult, vectorResult),
		RetrievalTime:    timelineResult.Duration + knowledgeResult.Duration + vectorResult.Duration,
		SuccessfulDims:   s.countSuccessfulDimensions(timelineResult, knowledgeResult, vectorResult),
	}

	return retrievalResults, nil
}

// synthesizeAndEvaluateContext åˆæˆå’Œè¯„ä¼°ä¸Šä¸‹æ–‡
func (s *WideRecallService) synthesizeAndEvaluateContext(ctx context.Context, req *models.ContextSynthesisRequest) (*ContextSynthesisResult, error) {
	// åˆ›å»ºå¸¦è¶…æ—¶çš„ä¸Šä¸‹æ–‡
	timeoutCtx, cancel := context.WithTimeout(ctx, time.Duration(s.config.LLMTimeout)*time.Second)
	defer cancel()

	// æ„å»ºä¸Šä¸‹æ–‡åˆæˆPrompt
	prompt := s.buildContextSynthesisPrompt(req)

	// è°ƒç”¨LLMè¿›è¡Œä¸Šä¸‹æ–‡åˆæˆ
	llmRequest := &GenerateRequest{
		Prompt:      prompt,
		MaxTokens:   8000, // å¤§å¹…å¢åŠ tokené™åˆ¶ä»¥æ”¯æŒå¤æ‚çš„UnifiedContextModel
		Temperature: 0.1,  // é™ä½æ¸©åº¦æé«˜ä¸€è‡´æ€§
		Format:      "json",
	}

	log.Printf("ğŸ¤– [æ–¹æ¡ˆ1-R1æ¨¡å‹] ä¸Šä¸‹æ–‡åˆæˆLLMè¯·æ±‚")
	log.Printf("ğŸ“¤ [ä¸Šä¸‹æ–‡åˆæˆè¯·æ±‚] Prompté•¿åº¦: %då­—ç¬¦", len(llmRequest.Prompt))
	log.Printf("ğŸ“¤ [ä¸Šä¸‹æ–‡åˆæˆè¯·æ±‚] MaxTokens: %d, Temperature: %.1f", llmRequest.MaxTokens, llmRequest.Temperature)
	log.Printf("ğŸ“¤ [ä¸Šä¸‹æ–‡åˆæˆè¯·æ±‚] Promptå‰500å­—ç¬¦:\n%s", llmRequest.Prompt[:min(500, len(llmRequest.Prompt))])

	response, err := s.llmService.GenerateResponse(timeoutCtx, llmRequest)
	if err != nil {
		log.Printf("âŒ [ä¸Šä¸‹æ–‡åˆæˆå“åº”] LLMè°ƒç”¨å¤±è´¥: %v", err)
		return nil, fmt.Errorf("LLMä¸Šä¸‹æ–‡åˆæˆå¤±è´¥: %w", err)
	}

	log.Printf("ğŸ“¥ [ä¸Šä¸‹æ–‡åˆæˆå“åº”] å“åº”é•¿åº¦: %då­—ç¬¦", len(response.Content))
	log.Printf("ğŸ“¥ [ä¸Šä¸‹æ–‡åˆæˆå“åº”] Tokenä½¿ç”¨: Prompt=%d, Completion=%d, Total=%d",
		response.Usage.PromptTokens, response.Usage.CompletionTokens, response.Usage.TotalTokens)
	log.Printf("ğŸ“¥ [ä¸Šä¸‹æ–‡åˆæˆå“åº”] å†…å®¹å‰1000å­—ç¬¦:\n%s", response.Content[:min(1000, len(response.Content))])

	// è§£æLLMå“åº”
	synthesisResult, err := s.parseContextSynthesisResponse(response.Content)
	if err != nil {
		return nil, fmt.Errorf("è§£æä¸Šä¸‹æ–‡åˆæˆç»“æœå¤±è´¥: %w", err)
	}

	return synthesisResult, nil
}

// å†…éƒ¨ç»“æœç»“æ„
type TimelineRetrievalResult struct {
	Results  []models.TimelineResult `json:"results"`
	Status   string                  `json:"status"`
	Duration int64                   `json:"duration"`
	Error    error                   `json:"error,omitempty"`
}

type KnowledgeRetrievalResult struct {
	Results  []models.KnowledgeResult `json:"results"`
	Status   string                   `json:"status"`
	Duration int64                    `json:"duration"`
	Error    error                    `json:"error,omitempty"`
}

type VectorRetrievalResult struct {
	Results  []models.VectorResult `json:"results"`
	Status   string                `json:"status"`
	Duration int64                 `json:"duration"`
	Error    error                 `json:"error,omitempty"`
}

type ContextSynthesisResult struct {
	EvaluationResult   *models.EvaluationResult    `json:"evaluation_result"`
	SynthesizedContext *models.UnifiedContextModel `json:"synthesized_context"`
	SynthesisMetadata  *models.SynthesisMetadata   `json:"synthesis_metadata"`
}

// getDefaultWideRecallConfig è·å–é»˜è®¤é…ç½®
func getDefaultWideRecallConfig() *WideRecallConfig {
	return &WideRecallConfig{
		LLMTimeout:           40, // 40ç§’
		TimelineTimeout:      5,  // 5ç§’
		KnowledgeTimeout:     5,  // 5ç§’
		VectorTimeout:        5,  // 5ç§’
		TimelineMaxResults:   20,
		KnowledgeMaxResults:  15,
		VectorMaxResults:     25,
		MinSimilarityScore:   0.6,
		MinRelevanceScore:    0.5,
		ConfidenceThreshold:  0.7,
		UpdateThreshold:      0.4,
		PersistenceThreshold: 0.7,
		MaxRetries:           1,
		RetryInterval:        2,
	}
}

// generateWideRecallRequestID ç”Ÿæˆå®½å¬å›è¯·æ±‚ID
func generateWideRecallRequestID() string {
	return fmt.Sprintf("wr_%d", time.Now().UnixNano())
}

// executeTimelineRetrieval æ‰§è¡Œæ—¶é—´çº¿æ£€ç´¢
func (s *WideRecallService) executeTimelineRetrieval(ctx context.Context, queries []models.TimelineQuery, req *models.WideRecallRequest) *TimelineRetrievalResult {
	startTime := time.Now()

	// åˆ›å»ºå¸¦è¶…æ—¶çš„ä¸Šä¸‹æ–‡
	timeoutCtx, cancel := context.WithTimeout(ctx, time.Duration(s.config.TimelineTimeout)*time.Second)
	defer cancel()

	var allResults []models.TimelineResult
	status := "success"

	// æ‰§è¡Œæ¯ä¸ªæ—¶é—´çº¿æŸ¥è¯¢
	for _, query := range queries {
		results, err := s.timelineStore.SearchEvents(timeoutCtx, &TimelineSearchRequest{
			UserID:      req.UserID,
			WorkspaceID: req.WorkspaceID,
			Query:       query.QueryText,
			TimeRange:   query.TimeRange,
			EventTypes:  query.EventTypes,
			MaxResults:  s.config.TimelineMaxResults,
		})

		if err != nil {
			status = "partial_failure"
			continue
		}

		// è½¬æ¢ç»“æœæ ¼å¼
		for _, result := range results {
			timelineResult := models.TimelineResult{
				EventID:         result.EventID,
				EventType:       result.EventType,
				Title:           result.Title,
				Content:         result.Content,
				Timestamp:       result.Timestamp,
				Source:          result.Source,
				ImportanceScore: result.ImportanceScore,
				RelevanceScore:  result.RelevanceScore,
				Tags:            result.Tags,
				Metadata:        result.Metadata,
			}
			allResults = append(allResults, timelineResult)
		}
	}

	// å¦‚æœæ²¡æœ‰ä»»ä½•ç»“æœä¸”å‘ç”Ÿé”™è¯¯ï¼Œæ ‡è®°ä¸ºå¤±è´¥
	if len(allResults) == 0 && status == "partial_failure" {
		status = "failure"
	}

	return &TimelineRetrievalResult{
		Results:  allResults,
		Status:   status,
		Duration: time.Since(startTime).Milliseconds(),
	}
}

// executeKnowledgeRetrieval æ‰§è¡ŒçŸ¥è¯†å›¾è°±æ£€ç´¢
func (s *WideRecallService) executeKnowledgeRetrieval(ctx context.Context, queries []models.KnowledgeQuery, req *models.WideRecallRequest) *KnowledgeRetrievalResult {
	startTime := time.Now()

	// åˆ›å»ºå¸¦è¶…æ—¶çš„ä¸Šä¸‹æ–‡
	timeoutCtx, cancel := context.WithTimeout(ctx, time.Duration(s.config.KnowledgeTimeout)*time.Second)
	defer cancel()

	var allResults []models.KnowledgeResult
	status := "success"

	// æ‰§è¡Œæ¯ä¸ªçŸ¥è¯†å›¾è°±æŸ¥è¯¢
	for _, query := range queries {
		results, err := s.knowledgeStore.SearchConcepts(timeoutCtx, &KnowledgeSearchRequest{
			UserID:        req.UserID,
			WorkspaceID:   req.WorkspaceID,
			Query:         query.QueryText,
			ConceptTypes:  query.ConceptTypes,
			RelationTypes: query.RelationTypes,
			MaxResults:    s.config.KnowledgeMaxResults,
		})

		if err != nil {
			status = "partial_failure"
			continue
		}

		// è½¬æ¢ç»“æœæ ¼å¼
		for _, result := range results {
			knowledgeResult := models.KnowledgeResult{
				ConceptID:       result.ConceptID,
				ConceptName:     result.ConceptName,
				ConceptType:     result.ConceptType,
				Description:     result.Description,
				RelatedConcepts: convertRelatedConcepts(result.RelatedConcepts),
				Properties:      result.Properties,
				RelevanceScore:  result.RelevanceScore,
				ConfidenceScore: result.ConfidenceScore,
				Source:          result.Source,
				LastUpdated:     result.LastUpdated,
			}
			allResults = append(allResults, knowledgeResult)
		}
	}

	// å¦‚æœæ²¡æœ‰ä»»ä½•ç»“æœä¸”å‘ç”Ÿé”™è¯¯ï¼Œæ ‡è®°ä¸ºå¤±è´¥
	if len(allResults) == 0 && status == "partial_failure" {
		status = "failure"
	}

	return &KnowledgeRetrievalResult{
		Results:  allResults,
		Status:   status,
		Duration: time.Since(startTime).Milliseconds(),
	}
}

// executeVectorRetrieval æ‰§è¡Œå‘é‡æ£€ç´¢
func (s *WideRecallService) executeVectorRetrieval(ctx context.Context, queries []models.VectorQuery, req *models.WideRecallRequest) *VectorRetrievalResult {
	startTime := time.Now()

	// åˆ›å»ºå¸¦è¶…æ—¶çš„ä¸Šä¸‹æ–‡
	timeoutCtx, cancel := context.WithTimeout(ctx, time.Duration(s.config.VectorTimeout)*time.Second)
	defer cancel()

	var allResults []models.VectorResult
	status := "success"

	// æ‰§è¡Œæ¯ä¸ªå‘é‡æŸ¥è¯¢
	for _, query := range queries {
		results, err := s.vectorStore.SearchSimilar(timeoutCtx, &VectorSearchRequest{
			UserID:              req.UserID,
			WorkspaceID:         req.WorkspaceID,
			Query:               query.QueryText,
			SimilarityThreshold: query.SimilarityThreshold,
			MaxResults:          s.config.VectorMaxResults,
		})

		if err != nil {
			status = "partial_failure"
			continue
		}

		// è½¬æ¢ç»“æœæ ¼å¼
		for _, result := range results {
			vectorResult := models.VectorResult{
				DocumentID:      result.DocumentID,
				Content:         result.Content,
				ContentType:     result.ContentType,
				Source:          result.Source,
				Similarity:      result.Similarity,
				RelevanceScore:  result.RelevanceScore,
				Timestamp:       result.Timestamp,
				Tags:            result.Tags,
				Metadata:        result.Metadata,
				MatchedSegments: convertMatchedSegments(result.MatchedSegments),
			}
			allResults = append(allResults, vectorResult)
		}
	}

	// å¦‚æœæ²¡æœ‰ä»»ä½•ç»“æœä¸”å‘ç”Ÿé”™è¯¯ï¼Œæ ‡è®°ä¸ºå¤±è´¥
	if len(allResults) == 0 && status == "partial_failure" {
		status = "failure"
	}

	return &VectorRetrievalResult{
		Results:  allResults,
		Status:   status,
		Duration: time.Since(startTime).Milliseconds(),
	}
}

// è¾…åŠ©å‡½æ•°
func convertRelatedConcepts(storageRelated []RelatedConcept) []models.RelatedConcept {
	var result []models.RelatedConcept
	for _, related := range storageRelated {
		result = append(result, models.RelatedConcept{
			ConceptName:    related.ConceptName,
			RelationType:   related.RelationType,
			RelationWeight: related.RelationWeight,
		})
	}
	return result
}

func convertMatchedSegments(storageSegments []MatchedSegment) []models.MatchedSegment {
	var result []models.MatchedSegment
	for _, segment := range storageSegments {
		result = append(result, models.MatchedSegment{
			SegmentText: segment.SegmentText,
			StartPos:    segment.StartPos,
			EndPos:      segment.EndPos,
			Similarity:  segment.Similarity,
		})
	}
	return result
}

// calculateOverallQuality è®¡ç®—æ€»ä½“è´¨é‡
func (s *WideRecallService) calculateOverallQuality(timeline *TimelineRetrievalResult, knowledge *KnowledgeRetrievalResult, vector *VectorRetrievalResult) float64 {
	var totalScore float64
	var totalWeight float64

	// æ—¶é—´çº¿è´¨é‡è¯„åˆ†
	if timeline.Status == "success" && len(timeline.Results) > 0 {
		timelineScore := 0.0
		for _, result := range timeline.Results {
			timelineScore += (result.ImportanceScore + result.RelevanceScore) / 2
		}
		timelineScore /= float64(len(timeline.Results))
		totalScore += timelineScore * 0.3 // 30%æƒé‡
		totalWeight += 0.3
	}

	// çŸ¥è¯†å›¾è°±è´¨é‡è¯„åˆ†
	if knowledge.Status == "success" && len(knowledge.Results) > 0 {
		knowledgeScore := 0.0
		for _, result := range knowledge.Results {
			knowledgeScore += (result.RelevanceScore + result.ConfidenceScore) / 2
		}
		knowledgeScore /= float64(len(knowledge.Results))
		totalScore += knowledgeScore * 0.3 // 30%æƒé‡
		totalWeight += 0.3
	}

	// å‘é‡æ£€ç´¢è´¨é‡è¯„åˆ†
	if vector.Status == "success" && len(vector.Results) > 0 {
		vectorScore := 0.0
		for _, result := range vector.Results {
			vectorScore += (result.Similarity + result.RelevanceScore) / 2
		}
		vectorScore /= float64(len(vector.Results))
		totalScore += vectorScore * 0.4 // 40%æƒé‡
		totalWeight += 0.4
	}

	if totalWeight == 0 {
		return 0.0
	}

	return totalScore / totalWeight
}

// countSuccessfulDimensions ç»Ÿè®¡æˆåŠŸçš„ç»´åº¦æ•°é‡
func (s *WideRecallService) countSuccessfulDimensions(timeline *TimelineRetrievalResult, knowledge *KnowledgeRetrievalResult, vector *VectorRetrievalResult) int {
	count := 0
	if timeline.Status == "success" {
		count++
	}
	if knowledge.Status == "success" {
		count++
	}
	if vector.Status == "success" {
		count++
	}
	return count
}
