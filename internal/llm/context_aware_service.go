package llm

import (
	"context"
	"fmt"
	"time"
)

// min è¿”å›ä¸¤ä¸ªæ•´æ•°ä¸­çš„è¾ƒå°å€¼
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// =============================================================================
// ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„LLMæœåŠ¡
// =============================================================================

// ContextAwareLLMService ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„LLMæœåŠ¡
type ContextAwareLLMService struct {
	factory       *LLMFactory
	promptManager *PromptManager
	cacheManager  *CacheManager
	config        *ContextAwareLLMConfig
}

// ContextAwareLLMConfig ä¸Šä¸‹æ–‡æ„ŸçŸ¥LLMé…ç½®
type ContextAwareLLMConfig struct {
	PrimaryProvider  LLMProvider   `json:"primary_provider"`
	FallbackProvider LLMProvider   `json:"fallback_provider"`
	CacheEnabled     bool          `json:"cache_enabled"`
	CacheTTL         time.Duration `json:"cache_ttl"`
	MaxRetries       int           `json:"max_retries"`
	TimeoutSeconds   int           `json:"timeout_seconds"`
	EnableRouting    bool          `json:"enable_routing"`
}

// LLMTask LLMä»»åŠ¡
type LLMTask struct {
	Type           string                 `json:"type"`
	Prompt         *Prompt                `json:"prompt"`
	ExpectedFormat string                 `json:"expected_format"`
	MaxTokens      int                    `json:"max_tokens"`
	Temperature    float64                `json:"temperature"`
	Metadata       map[string]interface{} `json:"metadata"`
}

// NewContextAwareLLMService åˆ›å»ºä¸Šä¸‹æ–‡æ„ŸçŸ¥LLMæœåŠ¡
func NewContextAwareLLMService(config *ContextAwareLLMConfig) *ContextAwareLLMService {
	if config == nil {
		config = &ContextAwareLLMConfig{
			PrimaryProvider:  ProviderOpenAI,
			FallbackProvider: ProviderClaude,
			CacheEnabled:     true,
			CacheTTL:         30 * time.Minute,
			MaxRetries:       3,
			TimeoutSeconds:   30,
			EnableRouting:    true,
		}
	}

	return &ContextAwareLLMService{
		factory:       GetGlobalFactory(),
		promptManager: NewPromptManager(nil),
		cacheManager:  NewCacheManager(),
		config:        config,
	}
}

// AnalyzeThreeElementsWithLLM ä½¿ç”¨LLMåˆ†æä¸‰è¦ç´ 
func (cas *ContextAwareLLMService) AnalyzeThreeElementsWithLLM(
	ctx context.Context,
	sessionHistory []Message,
	workspaceContext *WorkspaceContext,
) (*ThreeElementsModel, error) {

	fmt.Printf("\nğŸ” [ä¸‰è¦ç´ åˆ†æ] å¼€å§‹åˆ†æ...\n")
	fmt.Printf("ğŸ“ è¾“å…¥å‚æ•°:\n")
	fmt.Printf("  - ä¼šè¯å†å²æ¡æ•°: %d\n", len(sessionHistory))
	for i, msg := range sessionHistory {
		fmt.Printf("    [%d] %s: %s\n", i+1, msg.Role, msg.Content)
	}
	if workspaceContext != nil {
		fmt.Printf("  - å·¥ä½œç©ºé—´: %s (%s)\n", workspaceContext.ProjectName, workspaceContext.ProjectType)
		fmt.Printf("  - æŠ€æœ¯æ ˆ: %v\n", workspaceContext.TechStack)
		fmt.Printf("  - ç¯å¢ƒ: %s\n", workspaceContext.Environment)
	}

	// 1. æ„å»ºä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„Prompt
	fmt.Printf("ğŸ› ï¸  [æ­¥éª¤1] æ„å»ºPrompt...\n")
	prompt, err := cas.promptManager.BuildPrompt("three_elements_analysis", &PromptContext{
		SessionHistory:   sessionHistory,
		WorkspaceContext: workspaceContext,
		AnalysisType:     "three_elements",
	})
	if err != nil {
		fmt.Printf("âŒ æ„å»ºPromptå¤±è´¥: %v\n", err)
		return nil, fmt.Errorf("æ„å»ºPromptå¤±è´¥: %w", err)
	}

	fmt.Printf("âœ… Promptæ„å»ºæˆåŠŸ\n")
	fmt.Printf("ğŸ“‹ ç³»ç»Ÿæç¤ºè¯: %s\n", prompt.SystemPrompt[:min(200, len(prompt.SystemPrompt))]+"...")
	fmt.Printf("ğŸ“‹ ç”¨æˆ·æç¤ºè¯: %s\n", prompt.Content[:min(300, len(prompt.Content))]+"...")

	// 2. æ£€æŸ¥ç¼“å­˜
	fmt.Printf("ğŸ—„ï¸  [æ­¥éª¤2] æ£€æŸ¥ç¼“å­˜...\n")
	if cas.config.CacheEnabled {
		if cached := cas.cacheManager.GetThreeElements(prompt.Hash()); cached != nil {
			fmt.Printf("âœ… ç¼“å­˜å‘½ä¸­ï¼Œç›´æ¥è¿”å›ç»“æœ\n")
			return cached, nil
		}
		fmt.Printf("âšª ç¼“å­˜æœªå‘½ä¸­ï¼Œç»§ç»­LLMè°ƒç”¨\n")
	} else {
		fmt.Printf("âšª ç¼“å­˜å·²ç¦ç”¨\n")
	}

	// 3. è°ƒç”¨LLM
	fmt.Printf("ğŸ¤– [æ­¥éª¤3] è°ƒç”¨LLM...\n")
	task := &LLMTask{
		Type:           "three_elements_analysis",
		Prompt:         prompt,
		ExpectedFormat: "json",
		MaxTokens:      500,
		Temperature:    0.1, // ä½æ¸©åº¦ç¡®ä¿ä¸€è‡´æ€§
	}
	fmt.Printf("ğŸ“Š ä»»åŠ¡å‚æ•°: Type=%s, MaxTokens=%d, Temperature=%.1f\n",
		task.Type, task.MaxTokens, task.Temperature)

	result, err := cas.callLLMWithFallback(ctx, task)
	if err != nil {
		fmt.Printf("âŒ LLMè°ƒç”¨å¤±è´¥: %v\n", err)
		return nil, fmt.Errorf("LLMåˆ†æå¤±è´¥: %w", err)
	}

	fmt.Printf("âœ… LLMè°ƒç”¨æˆåŠŸ\n")
	fmt.Printf("ğŸ“ˆ å“åº”ç»Ÿè®¡: Provider=%s, TokensUsed=%d, Duration=%v\n",
		result.Provider, result.TokensUsed, result.Duration)
	fmt.Printf("ğŸ“„ åŸå§‹å“åº”å†…å®¹:\n%s\n", result.Content)

	// 4. è§£æç»“æœ
	fmt.Printf("ğŸ”§ [æ­¥éª¤4] è§£æJSONå“åº”...\n")
	var threeElements ThreeElementsModel
	if err := parseJSONResponse(result.Content, &threeElements); err != nil {
		fmt.Printf("âŒ JSONè§£æå¤±è´¥: %v\n", err)
		fmt.Printf("ğŸ“„ åŸå§‹å†…å®¹: %s\n", result.Content)
		return nil, fmt.Errorf("è§£æLLMç»“æœå¤±è´¥: %w, åŸå§‹å†…å®¹: %s", err, result.Content)
	}

	fmt.Printf("âœ… JSONè§£ææˆåŠŸ\n")
	fmt.Printf("ğŸ‘¤ ç”¨æˆ·è¦ç´ : TechStack=%v, Level=%s, Role=%s, Domain=%s\n",
		threeElements.User.TechStack, threeElements.User.ExperienceLevel,
		threeElements.User.Role, threeElements.User.Domain)
	fmt.Printf("ğŸ¢ æƒ…æ™¯è¦ç´ : ProjectType=%s, BusinessContext=%s\n",
		threeElements.Situation.ProjectType, threeElements.Situation.BusinessContext)
	fmt.Printf("â“ é—®é¢˜è¦ç´ : Intent=%s, ExplicitProblem=%s, ImplicitNeeds=%v\n",
		threeElements.Problem.Intent, threeElements.Problem.ExplicitProblem,
		threeElements.Problem.ImplicitNeeds)

	// 5. ç¼“å­˜ç»“æœ
	fmt.Printf("ğŸ’¾ [æ­¥éª¤5] ç¼“å­˜ç»“æœ...\n")
	if cas.config.CacheEnabled {
		cas.cacheManager.SetThreeElements(prompt.Hash(), &threeElements, cas.config.CacheTTL)
		fmt.Printf("âœ… ç»“æœå·²ç¼“å­˜ï¼ŒTTL=%v\n", cas.config.CacheTTL)
	} else {
		fmt.Printf("âšª ç¼“å­˜å·²ç¦ç”¨\n")
	}

	fmt.Printf("ğŸ‰ [ä¸‰è¦ç´ åˆ†æ] å®Œæˆï¼\n\n")
	return &threeElements, nil
}

// RewriteQueryWithLLM ä½¿ç”¨LLMè¿›è¡ŒæŸ¥è¯¢æ”¹å†™
func (cas *ContextAwareLLMService) RewriteQueryWithLLM(
	ctx context.Context,
	originalQuery string,
	threeElements *ThreeElementsModel,
	retrievalContext *RetrievalContext,
) (*QueryRewriteResult, error) {

	fmt.Printf("\nâœï¸  [æŸ¥è¯¢æ”¹å†™] å¼€å§‹æ”¹å†™...\n")
	fmt.Printf("ğŸ“ è¾“å…¥å‚æ•°:\n")
	fmt.Printf("  - åŸå§‹æŸ¥è¯¢: %s\n", originalQuery)
	if threeElements != nil {
		fmt.Printf("  - ç”¨æˆ·æŠ€æœ¯æ ˆ: %v\n", threeElements.User.TechStack)
		fmt.Printf("  - ç”¨æˆ·è§’è‰²: %s\n", threeElements.User.Role)
		fmt.Printf("  - é¡¹ç›®ç±»å‹: %s\n", threeElements.Situation.ProjectType)
		fmt.Printf("  - é—®é¢˜æ„å›¾: %s\n", threeElements.Problem.Intent)
	}
	if retrievalContext != nil {
		fmt.Printf("  - æ£€ç´¢ç­–ç•¥: %s\n", retrievalContext.Strategy)
		fmt.Printf("  - TopK: %d\n", retrievalContext.TopK)
		fmt.Printf("  - é˜ˆå€¼: %.2f\n", retrievalContext.Threshold)
	}

	// 1. æ„å»ºæŸ¥è¯¢æ”¹å†™çš„Prompt
	fmt.Printf("ğŸ› ï¸  [æ­¥éª¤1] æ„å»ºæŸ¥è¯¢æ”¹å†™Prompt...\n")
	prompt, err := cas.promptManager.BuildPrompt("query_rewrite", &PromptContext{
		OriginalQuery:    originalQuery,
		ThreeElements:    threeElements,
		RetrievalContext: retrievalContext,
		AnalysisType:     "query_rewrite",
	})
	if err != nil {
		fmt.Printf("âŒ æ„å»ºPromptå¤±è´¥: %v\n", err)
		return nil, fmt.Errorf("æ„å»ºæŸ¥è¯¢æ”¹å†™Promptå¤±è´¥: %w", err)
	}

	fmt.Printf("âœ… Promptæ„å»ºæˆåŠŸ\n")
	fmt.Printf("ğŸ“‹ ç³»ç»Ÿæç¤ºè¯: %s\n", prompt.SystemPrompt[:min(200, len(prompt.SystemPrompt))]+"...")
	fmt.Printf("ğŸ“‹ ç”¨æˆ·æç¤ºè¯: %s\n", prompt.Content[:min(300, len(prompt.Content))]+"...")

	// 2. è°ƒç”¨LLM
	fmt.Printf("ğŸ¤– [æ­¥éª¤2] è°ƒç”¨LLMè¿›è¡ŒæŸ¥è¯¢æ”¹å†™...\n")
	task := &LLMTask{
		Type:           "query_rewrite",
		Prompt:         prompt,
		ExpectedFormat: "json",
		MaxTokens:      300,
		Temperature:    0.2, // ç¨é«˜æ¸©åº¦å¢åŠ åˆ›é€ æ€§
	}
	fmt.Printf("ğŸ“Š ä»»åŠ¡å‚æ•°: Type=%s, MaxTokens=%d, Temperature=%.1f\n",
		task.Type, task.MaxTokens, task.Temperature)

	result, err := cas.callLLMWithFallback(ctx, task)
	if err != nil {
		fmt.Printf("âŒ LLMè°ƒç”¨å¤±è´¥: %v\n", err)
		return nil, fmt.Errorf("LLMæŸ¥è¯¢æ”¹å†™å¤±è´¥: %w", err)
	}

	fmt.Printf("âœ… LLMè°ƒç”¨æˆåŠŸ\n")
	fmt.Printf("ğŸ“ˆ å“åº”ç»Ÿè®¡: Provider=%s, TokensUsed=%d, Duration=%v\n",
		result.Provider, result.TokensUsed, result.Duration)
	fmt.Printf("ğŸ“„ åŸå§‹å“åº”å†…å®¹:\n%s\n", result.Content)

	// 3. è§£æå’ŒéªŒè¯ç»“æœ
	fmt.Printf("ğŸ”§ [æ­¥éª¤3] è§£æJSONå“åº”...\n")
	var rewriteResult QueryRewriteResult
	if err := parseJSONResponse(result.Content, &rewriteResult); err != nil {
		fmt.Printf("âŒ JSONè§£æå¤±è´¥: %v\n", err)
		fmt.Printf("ğŸ“„ åŸå§‹å†…å®¹: %s\n", result.Content)
		return nil, fmt.Errorf("è§£ææŸ¥è¯¢æ”¹å†™ç»“æœå¤±è´¥: %w", err)
	}

	// 4. è®¾ç½®åŸå§‹æŸ¥è¯¢
	rewriteResult.OriginalQuery = originalQuery

	fmt.Printf("âœ… JSONè§£ææˆåŠŸ\n")
	fmt.Printf("ğŸ“ æ”¹å†™ç»“æœ:\n")
	fmt.Printf("  - åŸå§‹æŸ¥è¯¢: %s\n", rewriteResult.OriginalQuery)
	fmt.Printf("  - æ”¹å†™æŸ¥è¯¢: %s\n", rewriteResult.RewrittenQuery)
	fmt.Printf("  - æ‰©å±•è¯æ±‡: %v\n", rewriteResult.Expansions)
	fmt.Printf("  - è´¨é‡åˆ†æ•°: %.2f\n", rewriteResult.QualityScore)
	fmt.Printf("  - æ”¹å†™ç†ç”±: %v\n", rewriteResult.Reasoning)

	fmt.Printf("ğŸ‰ [æŸ¥è¯¢æ”¹å†™] å®Œæˆï¼\n\n")
	return &rewriteResult, nil
}

// QueryRewriteResult æŸ¥è¯¢æ”¹å†™ç»“æœ
type QueryRewriteResult struct {
	OriginalQuery   string   `json:"original_query"`
	RewrittenQuery  string   `json:"rewritten_query"`
	Expansions      []string `json:"expansions"`
	QualityScore    float64  `json:"quality_score"`
	Reasoning       []string `json:"reasoning"`
	RewriteStrategy string   `json:"rewrite_strategy"`
}

// callLLMWithFallback å¸¦é™çº§çš„LLMè°ƒç”¨
func (cas *ContextAwareLLMService) callLLMWithFallback(
	ctx context.Context,
	task *LLMTask,
) (*LLMResponse, error) {

	fmt.Printf("ğŸ”„ [LLMè°ƒç”¨] å¼€å§‹å¸¦é™çº§çš„LLMè°ƒç”¨...\n")

	// 1. é€‰æ‹©æä¾›å•†
	fmt.Printf("ğŸ¯ [æ­¥éª¤1] é€‰æ‹©æä¾›å•†...\n")
	provider := cas.selectProvider(task)
	fmt.Printf("âœ… é€‰æ‹©çš„æä¾›å•†: %s (ä»»åŠ¡ç±»å‹: %s)\n", provider, task.Type)

	// 2. å°è¯•ä¸»è¦æä¾›å•†
	fmt.Printf("ğŸš€ [æ­¥éª¤2] å°è¯•ä¸»è¦æä¾›å•†: %s\n", provider)
	if result, err := cas.callLLMWithRetry(ctx, provider, task); err == nil {
		fmt.Printf("âœ… ä¸»è¦æä¾›å•†è°ƒç”¨æˆåŠŸ\n")
		return result, nil
	} else {
		fmt.Printf("âŒ ä¸»è¦æä¾›å•†è°ƒç”¨å¤±è´¥: %v\n", err)
	}

	// 3. é™çº§åˆ°å¤‡ç”¨æä¾›å•†
	if cas.config.FallbackProvider != "" && cas.config.FallbackProvider != provider {
		fmt.Printf("ğŸ”„ [æ­¥éª¤3] é™çº§åˆ°å¤‡ç”¨æä¾›å•†: %s\n", cas.config.FallbackProvider)
		if result, err := cas.callLLMWithRetry(ctx, cas.config.FallbackProvider, task); err == nil {
			fmt.Printf("âœ… å¤‡ç”¨æä¾›å•†è°ƒç”¨æˆåŠŸ\n")
			return result, nil
		} else {
			fmt.Printf("âŒ å¤‡ç”¨æä¾›å•†è°ƒç”¨å¤±è´¥: %v\n", err)
		}
	} else {
		fmt.Printf("âšª æ— å¤‡ç”¨æä¾›å•†æˆ–ä¸ä¸»è¦æä¾›å•†ç›¸åŒ\n")
	}

	fmt.Printf("ğŸ’¥ æ‰€æœ‰LLMæä¾›å•†éƒ½ä¸å¯ç”¨\n")
	return nil, fmt.Errorf("æ‰€æœ‰LLMæä¾›å•†éƒ½ä¸å¯ç”¨")
}

// selectProvider é€‰æ‹©æä¾›å•†
func (cas *ContextAwareLLMService) selectProvider(task *LLMTask) LLMProvider {
	if !cas.config.EnableRouting {
		return cas.config.PrimaryProvider
	}

	// æ£€æŸ¥é¦–é€‰æä¾›å•†æ˜¯å¦å¯ç”¨
	checkProvider := func(provider LLMProvider) bool {
		_, err := cas.factory.CreateClient(provider)
		return err == nil
	}

	// æ ¹æ®ä»»åŠ¡ç±»å‹æ™ºèƒ½é€‰æ‹©æä¾›å•†
	var preferredProvider LLMProvider
	switch task.Type {
	case "three_elements_analysis":
		// Claudeæ›´é€‚åˆåˆ†æä»»åŠ¡ï¼Œä½†å¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨DeepSeek
		if checkProvider(ProviderClaude) {
			preferredProvider = ProviderClaude
		} else if checkProvider(ProviderDeepSeek) {
			preferredProvider = ProviderDeepSeek
		} else {
			preferredProvider = cas.config.PrimaryProvider
		}
	case "query_rewrite":
		// åƒé—®é€Ÿåº¦æ›´å¿«ï¼Œä½†å¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨DeepSeek
		if checkProvider(ProviderQianwen) {
			preferredProvider = ProviderQianwen
		} else if checkProvider(ProviderDeepSeek) {
			preferredProvider = ProviderDeepSeek
		} else {
			preferredProvider = cas.config.PrimaryProvider
		}
	case "code_analysis":
		// DeepSeekæ›´é€‚åˆä»£ç åˆ†æ
		preferredProvider = ProviderDeepSeek
	default:
		preferredProvider = cas.config.PrimaryProvider
	}

	// ç¡®ä¿é€‰æ‹©çš„æä¾›å•†å¯ç”¨
	if checkProvider(preferredProvider) {
		return preferredProvider
	}

	// å¦‚æœé¦–é€‰ä¸å¯ç”¨ï¼Œè¿”å›ä¸»è¦æä¾›å•†
	return cas.config.PrimaryProvider
}

// callLLMWithRetry å¸¦é‡è¯•çš„LLMè°ƒç”¨
func (cas *ContextAwareLLMService) callLLMWithRetry(
	ctx context.Context,
	provider LLMProvider,
	task *LLMTask,
) (*LLMResponse, error) {

	fmt.Printf("ğŸ” [é‡è¯•è°ƒç”¨] å¼€å§‹é‡è¯•è°ƒç”¨ %s...\n", provider)

	client, err := cas.factory.CreateClient(provider)
	if err != nil {
		fmt.Printf("âŒ åˆ›å»ºå®¢æˆ·ç«¯å¤±è´¥: %v\n", err)
		return nil, fmt.Errorf("åˆ›å»ºLLMå®¢æˆ·ç«¯å¤±è´¥: %w", err)
	}

	fmt.Printf("âœ… å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: %s\n", provider)

	var lastErr error

	for attempt := 0; attempt < cas.config.MaxRetries; attempt++ {
		fmt.Printf("ğŸ¯ [å°è¯• %d/%d] è°ƒç”¨ %s...\n", attempt+1, cas.config.MaxRetries, provider)

		// è®¾ç½®è¶…æ—¶
		timeoutCtx, cancel := context.WithTimeout(ctx,
			time.Duration(cas.config.TimeoutSeconds)*time.Second)

		// æ„å»ºè¯·æ±‚
		req := &LLMRequest{
			Prompt:       task.Prompt.Content,
			SystemPrompt: task.Prompt.SystemPrompt,
			MaxTokens:    task.MaxTokens,
			Temperature:  task.Temperature,
			Format:       task.ExpectedFormat,
		}

		fmt.Printf("ğŸ“¤ å‘é€è¯·æ±‚: MaxTokens=%d, Temperature=%.1f, Timeout=%ds\n",
			req.MaxTokens, req.Temperature, cas.config.TimeoutSeconds)

		// è°ƒç”¨LLM
		startTime := time.Now()
		result, err := client.Complete(timeoutCtx, req)
		duration := time.Since(startTime)
		cancel()

		if err == nil {
			fmt.Printf("âœ… è°ƒç”¨æˆåŠŸ! è€—æ—¶: %v\n", duration)
			return result, nil
		}

		fmt.Printf("âŒ è°ƒç”¨å¤±è´¥: %v (è€—æ—¶: %v)\n", err, duration)
		lastErr = err

		// æŒ‡æ•°é€€é¿
		if attempt < cas.config.MaxRetries-1 {
			backoff := time.Duration(1<<attempt) * time.Second
			fmt.Printf("â³ ç­‰å¾… %v åé‡è¯•...\n", backoff)
			select {
			case <-time.After(backoff):
				continue
			case <-ctx.Done():
				fmt.Printf("âŒ ä¸Šä¸‹æ–‡å–æ¶ˆ\n")
				return nil, ctx.Err()
			}
		}
	}

	fmt.Printf("ğŸ’¥ é‡è¯•%dæ¬¡åä»ç„¶å¤±è´¥: %v\n", cas.config.MaxRetries, lastErr)
	return nil, fmt.Errorf("é‡è¯•%dæ¬¡åä»ç„¶å¤±è´¥: %w", cas.config.MaxRetries, lastErr)
}

// SetConfig è®¾ç½®é…ç½®
func (cas *ContextAwareLLMService) SetConfig(config *ContextAwareLLMConfig) {
	cas.config = config
}

// GetConfig è·å–é…ç½®
func (cas *ContextAwareLLMService) GetConfig() *ContextAwareLLMConfig {
	return cas.config
}

// Close å…³é—­æœåŠ¡
func (cas *ContextAwareLLMService) Close() error {
	return cas.factory.Close()
}

// =============================================================================
// ç®€å•çš„LLMå®¢æˆ·ç«¯æ¥å£ - ä¾›å¤–éƒ¨è°ƒç”¨
// =============================================================================

// SimpleLLMClient ç®€å•çš„LLMå®¢æˆ·ç«¯æ¥å£
type SimpleLLMClient struct {
	service *ContextAwareLLMService
}

// NewSimpleLLMClient åˆ›å»ºç®€å•LLMå®¢æˆ·ç«¯
func NewSimpleLLMClient(provider LLMProvider, apiKey string) *SimpleLLMClient {
	// è®¾ç½®é…ç½®
	config := &LLMConfig{
		Provider:   provider,
		APIKey:     apiKey,
		MaxRetries: 3,
		Timeout:    30 * time.Second,
		RateLimit:  60,
	}

	SetGlobalConfig(provider, config)

	// åˆ›å»ºæœåŠ¡
	service := NewContextAwareLLMService(&ContextAwareLLMConfig{
		PrimaryProvider: provider,
	})

	return &SimpleLLMClient{
		service: service,
	}
}

// Chat ç®€å•å¯¹è¯æ¥å£
func (slc *SimpleLLMClient) Chat(ctx context.Context, message string) (string, error) {
	client, err := slc.service.factory.CreateClient(slc.service.config.PrimaryProvider)
	if err != nil {
		return "", err
	}

	req := &LLMRequest{
		Prompt:      message,
		MaxTokens:   1000,
		Temperature: 0.7,
	}

	resp, err := client.Complete(ctx, req)
	if err != nil {
		return "", err
	}

	return resp.Content, nil
}
