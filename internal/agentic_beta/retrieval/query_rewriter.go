package retrieval

import (
	"context"
	"fmt"
	"reflect"
	"regexp"
	"strings"
	"time"
)

// QueryRewriter æŸ¥è¯¢æ”¹å†™å™¨ - æ ¸å¿ƒæŸ¥è¯¢å¢å¼ºç»„ä»¶
type QueryRewriter struct {
	config        *QueryRewriterConfig
	enabled       bool
	rewriteChains []RewriteChain
}

// QueryRewriterConfig æŸ¥è¯¢æ”¹å†™å™¨é…ç½®
type QueryRewriterConfig struct {
	// å…³é”®è¯æå–
	KeywordExtraction KeywordExtractionConfig `json:"keyword_extraction"`
	// å™ªå£°å»é™¤
	NoiseReduction NoiseReductionConfig `json:"noise_reduction"`
	// ä¸Šä¸‹æ–‡ä¸°å¯Œ
	ContextEnrichment ContextEnrichmentConfig `json:"context_enrichment"`
	// è¿­ä»£è®¾ç½®
	MaxIterations    int     `json:"max_iterations"`
	QualityThreshold float64 `json:"quality_threshold"`
}

// ğŸ”¥ å…³é”®è¯æå–é…ç½®
type KeywordExtractionConfig struct {
	Enabled     bool     `json:"enabled"`
	Methods     []string `json:"methods"`    // ["tfidf", "keyword_density", "named_entity", "technical_terms"]
	MinWeight   float64  `json:"min_weight"` // æœ€å°æƒé‡é˜ˆå€¼
	MaxKeywords int      `json:"max_keywords"`
}

// ğŸ”¥ å™ªå£°å»é™¤é…ç½®
type NoiseReductionConfig struct {
	Enabled       bool     `json:"enabled"`
	StopWords     []string `json:"stop_words"`     // åœç”¨è¯
	FillerPhrases []string `json:"filler_phrases"` // å¡«å……çŸ­è¯­
	MinLength     int      `json:"min_length"`     // æœ€å°æŸ¥è¯¢é•¿åº¦
}

// ğŸ”¥ ä¸Šä¸‹æ–‡ä¸°å¯Œé…ç½®
type ContextEnrichmentConfig struct {
	Enabled          bool     `json:"enabled"`
	DomainTerms      []string `json:"domain_terms"`      // é¢†åŸŸæœ¯è¯­
	SynonymExpansion bool     `json:"synonym_expansion"` // åŒä¹‰è¯æ‰©å±•
	RelatedConcepts  bool     `json:"related_concepts"`  // ç›¸å…³æ¦‚å¿µ
}

// RewriteChain æ”¹å†™é“¾æ¥å£
type RewriteChain interface {
	Name() string
	Process(ctx context.Context, query string, metadata map[string]interface{}) (*RewriteResult, error)
	Priority() int
}

// RewriteResult æ”¹å†™ç»“æœ
type RewriteResult struct {
	OriginalQuery     string                 `json:"original_query"`
	RewrittenQuery    string                 `json:"rewritten_query"`
	ExtractedKeywords []KeywordInfo          `json:"extracted_keywords"`
	RemovedNoise      []string               `json:"removed_noise"`
	AddedContext      []string               `json:"added_context"`
	QualityScore      float64                `json:"quality_score"`
	ProcessingTime    time.Duration          `json:"processing_time"`
	Metadata          map[string]interface{} `json:"metadata"`
}

// KeywordInfo å…³é”®è¯ä¿¡æ¯
type KeywordInfo struct {
	Term     string  `json:"term"`
	Weight   float64 `json:"weight"`
	Category string  `json:"category"` // "technical", "domain", "general"
}

// NewQueryRewriter åˆ›å»ºæŸ¥è¯¢æ”¹å†™å™¨
func NewQueryRewriter(config *QueryRewriterConfig) *QueryRewriter {
	rewriter := &QueryRewriter{
		config:        config,
		enabled:       true,
		rewriteChains: make([]RewriteChain, 0),
	}

	// ğŸ”¥ åˆå§‹åŒ–æ”¹å†™é“¾ - æŒ‰ä¼˜å…ˆçº§æ’åº
	if config.KeywordExtraction.Enabled {
		rewriter.AddChain(&KeywordExtractionChain{config: &config.KeywordExtraction})
	}

	if config.NoiseReduction.Enabled {
		rewriter.AddChain(&NoiseReductionChain{config: &config.NoiseReduction})
	}

	if config.ContextEnrichment.Enabled {
		rewriter.AddChain(&ContextEnrichmentChain{config: &config.ContextEnrichment})
	}

	return rewriter
}

// AddChain æ·»åŠ æ”¹å†™é“¾
func (qr *QueryRewriter) AddChain(chain RewriteChain) {
	qr.rewriteChains = append(qr.rewriteChains, chain)
	// æŒ‰ä¼˜å…ˆçº§æ’åº
	for i := len(qr.rewriteChains) - 1; i > 0; i-- {
		if qr.rewriteChains[i].Priority() > qr.rewriteChains[i-1].Priority() {
			qr.rewriteChains[i], qr.rewriteChains[i-1] = qr.rewriteChains[i-1], qr.rewriteChains[i]
		}
	}
}

// ProcessQuery å¤„ç†æŸ¥è¯¢ - æ ¸å¿ƒå…¥å£æ–¹æ³•
func (qr *QueryRewriter) ProcessQuery(ctx context.Context, originalQuery string) (*RewriteResult, error) {
	if !qr.enabled {
		return &RewriteResult{
			OriginalQuery:  originalQuery,
			RewrittenQuery: originalQuery,
			QualityScore:   1.0,
		}, nil
	}

	startTime := time.Now()

	result := &RewriteResult{
		OriginalQuery:     originalQuery,
		RewrittenQuery:    originalQuery,
		ExtractedKeywords: make([]KeywordInfo, 0),
		RemovedNoise:      make([]string, 0),
		AddedContext:      make([]string, 0),
		QualityScore:      0.0,
		Metadata:          make(map[string]interface{}),
	}

	currentQuery := originalQuery

	// ğŸ”¥ å¤šè½®è¿­ä»£æ”¹å†™
	for iteration := 0; iteration < qr.config.MaxIterations; iteration++ {
		iterationImproved := false

		// æŒ‰ä¼˜å…ˆçº§æ‰§è¡Œæ”¹å†™é“¾
		for _, chain := range qr.rewriteChains {
			chainResult, err := chain.Process(ctx, currentQuery, result.Metadata)
			if err != nil {
				continue // é“¾æ‰§è¡Œå¤±è´¥æ—¶ç»§ç»­ä¸‹ä¸€ä¸ª
			}

			// åˆå¹¶ç»“æœ
			if chainResult.RewrittenQuery != currentQuery {
				currentQuery = chainResult.RewrittenQuery
				iterationImproved = true

				// åˆå¹¶å…³é”®è¯
				result.ExtractedKeywords = append(result.ExtractedKeywords, chainResult.ExtractedKeywords...)
				result.RemovedNoise = append(result.RemovedNoise, chainResult.RemovedNoise...)
				result.AddedContext = append(result.AddedContext, chainResult.AddedContext...)

				// æ›´æ–°è´¨é‡åˆ†æ•°ï¼ˆå–æœ€é«˜åˆ†ï¼‰
				if chainResult.QualityScore > result.QualityScore {
					result.QualityScore = chainResult.QualityScore
				}
			}
		}

		// ğŸ”¥ è´¨é‡è¯„ä¼° - è¾¾åˆ°é˜ˆå€¼åˆ™åœæ­¢è¿­ä»£
		if result.QualityScore >= qr.config.QualityThreshold {
			break
		}

		// æ— æ”¹è¿›åˆ™åœæ­¢
		if !iterationImproved {
			break
		}
	}

	result.RewrittenQuery = currentQuery
	result.ProcessingTime = time.Since(startTime)

	// ğŸ”¥ æœ€ç»ˆè´¨é‡æ£€æŸ¥
	if result.QualityScore == 0.0 {
		result.QualityScore = qr.calculateFinalQuality(originalQuery, currentQuery)
	}

	return result, nil
}

// ğŸ”¥ å…³é”®è¯æå–é“¾å®ç°
type KeywordExtractionChain struct {
	config *KeywordExtractionConfig
}

func (kec *KeywordExtractionChain) Name() string  { return "keyword_extraction" }
func (kec *KeywordExtractionChain) Priority() int { return 100 }

func (kec *KeywordExtractionChain) Process(ctx context.Context, query string, metadata map[string]interface{}) (*RewriteResult, error) {
	keywords := make([]KeywordInfo, 0)

	// ğŸ”¥ æŠ€æœ¯æœ¯è¯­æå–
	technicalTerms := kec.extractTechnicalTerms(query)
	for _, term := range technicalTerms {
		keywords = append(keywords, KeywordInfo{
			Term:     term,
			Weight:   0.9,
			Category: "technical",
		})
	}

	// ğŸ”¥ å‘½åå®ä½“æå–
	entities := kec.extractNamedEntities(query)
	for _, entity := range entities {
		keywords = append(keywords, KeywordInfo{
			Term:     entity,
			Weight:   0.8,
			Category: "entity",
		})
	}

	// ğŸ”¥ åŸºäºå¯†åº¦çš„å…³é”®è¯
	densityKeywords := kec.extractByDensity(query)
	for _, kw := range densityKeywords {
		keywords = append(keywords, kw)
	}

	// æ„å»ºå¢å¼ºæŸ¥è¯¢
	enhancedQuery := kec.buildEnhancedQuery(query, keywords)

	return &RewriteResult{
		OriginalQuery:     query,
		RewrittenQuery:    enhancedQuery,
		ExtractedKeywords: keywords,
		QualityScore:      kec.calculateKeywordQuality(keywords),
	}, nil
}

// ğŸ”¥ å™ªå£°å»é™¤é“¾å®ç°
type NoiseReductionChain struct {
	config *NoiseReductionConfig
}

func (nrc *NoiseReductionChain) Name() string  { return "noise_reduction" }
func (nrc *NoiseReductionChain) Priority() int { return 90 }

func (nrc *NoiseReductionChain) Process(ctx context.Context, query string, metadata map[string]interface{}) (*RewriteResult, error) {
	cleanedQuery := query
	removedNoise := make([]string, 0)

	// ğŸ”¥ ç§»é™¤åœç”¨è¯
	for _, stopWord := range nrc.config.StopWords {
		pattern := fmt.Sprintf(`\b%s\b`, regexp.QuoteMeta(stopWord))
		re := regexp.MustCompile(`(?i)` + pattern)
		if re.MatchString(cleanedQuery) {
			cleanedQuery = re.ReplaceAllString(cleanedQuery, " ")
			removedNoise = append(removedNoise, stopWord)
		}
	}

	// ğŸ”¥ ç§»é™¤å¡«å……çŸ­è¯­
	for _, filler := range nrc.config.FillerPhrases {
		if strings.Contains(strings.ToLower(cleanedQuery), strings.ToLower(filler)) {
			cleanedQuery = strings.ReplaceAll(cleanedQuery, filler, " ")
			removedNoise = append(removedNoise, filler)
		}
	}

	// ğŸ”¥ æ¸…ç†å¤šä½™ç©ºæ ¼
	cleanedQuery = regexp.MustCompile(`\s+`).ReplaceAllString(cleanedQuery, " ")
	cleanedQuery = strings.TrimSpace(cleanedQuery)

	// æ£€æŸ¥æœ€å°é•¿åº¦
	if len(cleanedQuery) < nrc.config.MinLength {
		cleanedQuery = query // æ¢å¤åŸæŸ¥è¯¢
	}

	return &RewriteResult{
		OriginalQuery:  query,
		RewrittenQuery: cleanedQuery,
		RemovedNoise:   removedNoise,
		QualityScore:   nrc.calculateCleaningQuality(query, cleanedQuery),
	}, nil
}

// ğŸ”¥ ä¸Šä¸‹æ–‡ä¸°å¯Œé“¾å®ç°
type ContextEnrichmentChain struct {
	config *ContextEnrichmentConfig
}

func (cec *ContextEnrichmentChain) Name() string  { return "context_enrichment" }
func (cec *ContextEnrichmentChain) Priority() int { return 80 }

func (cec *ContextEnrichmentChain) Process(ctx context.Context, query string, metadata map[string]interface{}) (*RewriteResult, error) {
	enrichedQuery := query
	addedContext := make([]string, 0)

	// ğŸ”¥ æ·»åŠ é¢†åŸŸæœ¯è¯­
	domainTerms := cec.findRelevantDomainTerms(query)
	for _, term := range domainTerms {
		if !strings.Contains(strings.ToLower(enrichedQuery), strings.ToLower(term)) {
			enrichedQuery += " " + term
			addedContext = append(addedContext, term)
		}
	}

	// ğŸ”¥ åŒä¹‰è¯æ‰©å±•
	if cec.config.SynonymExpansion {
		synonyms := cec.expandSynonyms(query)
		for _, synonym := range synonyms {
			enrichedQuery += " " + synonym
			addedContext = append(addedContext, synonym)
		}
	}

	// ğŸ”¥ ç›¸å…³æ¦‚å¿µè¡¥å……
	if cec.config.RelatedConcepts {
		concepts := cec.addRelatedConcepts(query)
		for _, concept := range concepts {
			enrichedQuery += " " + concept
			addedContext = append(addedContext, concept)
		}
	}

	return &RewriteResult{
		OriginalQuery:  query,
		RewrittenQuery: strings.TrimSpace(enrichedQuery),
		AddedContext:   addedContext,
		QualityScore:   cec.calculateEnrichmentQuality(query, enrichedQuery),
	}, nil
}

// ğŸ”¥ è¾…åŠ©æ–¹æ³•å®ç°

func (kec *KeywordExtractionChain) extractTechnicalTerms(query string) []string {
	// ç®€åŒ–å®ç°ï¼šåŸºäºå¸¸è§æŠ€æœ¯æœ¯è¯­æ¨¡å¼
	technicalPatterns := []string{
		`\b[A-Z]{2,}\b`,     // å¤§å†™ç¼©å†™ (API, HTTP, JSON)
		`\b\w+\(\)\b`,       // å‡½æ•°è°ƒç”¨æ¨¡å¼
		`\b\w+\.\w+\b`,      // å±æ€§è®¿é—®æ¨¡å¼
		`\b\w+Service\b`,    // æœåŠ¡æ¨¡å¼
		`\b\w+Controller\b`, // æ§åˆ¶å™¨æ¨¡å¼
	}

	terms := make([]string, 0)
	for _, pattern := range technicalPatterns {
		re := regexp.MustCompile(pattern)
		matches := re.FindAllString(query, -1)
		terms = append(terms, matches...)
	}
	return terms
}

func (kec *KeywordExtractionChain) extractNamedEntities(query string) []string {
	// ç®€åŒ–å®ç°ï¼šåŸºäºé¦–å­—æ¯å¤§å†™æ¨¡å¼
	re := regexp.MustCompile(`\b[A-Z][a-z]+\b`)
	return re.FindAllString(query, -1)
}

func (kec *KeywordExtractionChain) extractByDensity(query string) []KeywordInfo {
	words := strings.Fields(strings.ToLower(query))
	frequency := make(map[string]int)

	for _, word := range words {
		word = regexp.MustCompile(`[^a-zA-Z0-9]`).ReplaceAllString(word, "")
		if len(word) > 2 { // å¿½ç•¥è¿‡çŸ­çš„è¯
			frequency[word]++
		}
	}

	keywords := make([]KeywordInfo, 0)
	for word, freq := range frequency {
		if freq > 1 { // å‡ºç°å¤šæ¬¡çš„è¯
			keywords = append(keywords, KeywordInfo{
				Term:     word,
				Weight:   float64(freq) / float64(len(words)),
				Category: "density",
			})
		}
	}

	return keywords
}

func (kec *KeywordExtractionChain) buildEnhancedQuery(query string, keywords []KeywordInfo) string {
	// æ ¹æ®å…³é”®è¯æƒé‡é‡æ–°æ„å»ºæŸ¥è¯¢
	highValueKeywords := make([]string, 0)
	for _, kw := range keywords {
		if kw.Weight > 0.7 {
			highValueKeywords = append(highValueKeywords, kw.Term)
		}
	}

	if len(highValueKeywords) > 0 {
		return query + " " + strings.Join(highValueKeywords, " ")
	}
	return query
}

func (kec *KeywordExtractionChain) calculateKeywordQuality(keywords []KeywordInfo) float64 {
	if len(keywords) == 0 {
		return 0.5
	}

	totalWeight := 0.0
	for _, kw := range keywords {
		totalWeight += kw.Weight
	}

	avgWeight := totalWeight / float64(len(keywords))
	if avgWeight > 1.0 {
		return 1.0
	}
	return avgWeight
}

func (nrc *NoiseReductionChain) calculateCleaningQuality(original, cleaned string) float64 {
	originalLen := len(strings.Fields(original))
	cleanedLen := len(strings.Fields(cleaned))

	if originalLen == 0 {
		return 0.5
	}

	// è´¨é‡ = ä¿ç•™çš„æœ‰ç”¨è¯æ±‡æ¯”ä¾‹
	preservation := float64(cleanedLen) / float64(originalLen)

	// å»å™ªæ•ˆæœè¯„åˆ†
	if preservation > 0.7 && preservation < 1.0 {
		return 0.8 // é€‚åº¦å»å™ª
	} else if preservation == 1.0 {
		return 0.6 // æœªå»å™ª
	} else if preservation < 0.3 {
		return 0.3 // è¿‡åº¦å»å™ª
	}

	return preservation
}

func (cec *ContextEnrichmentChain) findRelevantDomainTerms(query string) []string {
	// ç®€åŒ–å®ç°ï¼šåŸºäºé…ç½®çš„é¢†åŸŸæœ¯è¯­åŒ¹é…
	relevant := make([]string, 0)
	queryLower := strings.ToLower(query)

	for _, term := range cec.config.DomainTerms {
		// å¦‚æœæŸ¥è¯¢ä¸é¢†åŸŸæœ¯è¯­æœ‰å…³è”ï¼Œæ·»åŠ ç›¸å…³æœ¯è¯­
		if strings.Contains(queryLower, strings.ToLower(term[:min(len(term), 3)])) {
			relevant = append(relevant, term)
		}
	}

	return relevant
}

func (cec *ContextEnrichmentChain) expandSynonyms(query string) []string {
	// ç®€åŒ–å®ç°ï¼šå¸¸è§åŒä¹‰è¯æ˜ å°„
	synonymMap := map[string][]string{
		"é—®é¢˜": {"issue", "bug", "æ•…éšœ"},
		"è§£å†³": {"fix", "resolve", "solve"},
		"ä¼˜åŒ–": {"optimize", "improve", "enhance"},
		"é…ç½®": {"config", "configuration", "setting"},
	}

	synonyms := make([]string, 0)
	for word, syns := range synonymMap {
		if strings.Contains(strings.ToLower(query), word) {
			synonyms = append(synonyms, syns...)
		}
	}

	return synonyms
}

func (cec *ContextEnrichmentChain) addRelatedConcepts(query string) []string {
	// ç®€åŒ–å®ç°ï¼šåŸºäºæŸ¥è¯¢å†…å®¹æ¨æ–­ç›¸å…³æ¦‚å¿µ
	concepts := make([]string, 0)
	queryLower := strings.ToLower(query)

	if strings.Contains(queryLower, "api") {
		concepts = append(concepts, "æ¥å£", "è¯·æ±‚", "å“åº”", "çŠ¶æ€ç ")
	}
	if strings.Contains(queryLower, "æ•°æ®åº“") {
		concepts = append(concepts, "SQL", "æŸ¥è¯¢", "ç´¢å¼•", "äº‹åŠ¡")
	}
	if strings.Contains(queryLower, "æ€§èƒ½") {
		concepts = append(concepts, "å»¶è¿Ÿ", "ååé‡", "å¹¶å‘", "ç¼“å­˜")
	}

	return concepts
}

func (cec *ContextEnrichmentChain) calculateEnrichmentQuality(original, enriched string) float64 {
	originalWords := len(strings.Fields(original))
	enrichedWords := len(strings.Fields(enriched))

	if originalWords == 0 {
		return 0.5
	}

	enrichmentRatio := float64(enrichedWords-originalWords) / float64(originalWords)

	// é€‚åº¦ä¸°å¯Œ (10%-50%) è·å¾—æœ€é«˜åˆ†
	if enrichmentRatio >= 0.1 && enrichmentRatio <= 0.5 {
		return 0.9
	} else if enrichmentRatio > 0.5 {
		return 0.7 // è¿‡åº¦ä¸°å¯Œ
	} else {
		return 0.6 // ä¸°å¯Œä¸è¶³
	}
}

func (qr *QueryRewriter) calculateFinalQuality(original, rewritten string) float64 {
	// ç»¼åˆè´¨é‡è¯„ä¼°
	if original == rewritten {
		return 0.5 // æ— æ”¹å˜
	}

	// åŸºäºé•¿åº¦å˜åŒ–å’Œå¤æ‚åº¦è¯„ä¼°
	originalComplexity := qr.calculateComplexity(original)
	rewrittenComplexity := qr.calculateComplexity(rewritten)

	if rewrittenComplexity > originalComplexity {
		return 0.8 // å¤æ‚åº¦æå‡
	} else if rewrittenComplexity == originalComplexity {
		return 0.6 // å¤æ‚åº¦æŒå¹³
	} else {
		return 0.4 // å¤æ‚åº¦é™ä½
	}
}

func (qr *QueryRewriter) calculateComplexity(query string) float64 {
	words := strings.Fields(query)
	uniqueWords := make(map[string]bool)

	for _, word := range words {
		uniqueWords[strings.ToLower(word)] = true
	}

	// å¤æ‚åº¦ = è¯æ±‡å¤šæ ·æ€§ + é•¿åº¦å› å­
	diversity := float64(len(uniqueWords)) / float64(len(words))
	lengthFactor := float64(len(words)) / 10.0
	if lengthFactor > 1.0 {
		lengthFactor = 1.0
	}

	return (diversity + lengthFactor) / 2.0
}

// è·å–é…ç½®
func (qr *QueryRewriter) GetConfig() *QueryRewriterConfig {
	return qr.config
}

// å¯ç”¨/ç¦ç”¨
func (qr *QueryRewriter) SetEnabled(enabled bool) {
	qr.enabled = enabled
}

// æ£€æŸ¥æ˜¯å¦å¯ç”¨
func (qr *QueryRewriter) IsEnabled() bool {
	return qr.enabled
}

// è·å–ç»Ÿè®¡ä¿¡æ¯
func (qr *QueryRewriter) GetStats() map[string]interface{} {
	return map[string]interface{}{
		"enabled":           qr.enabled,
		"chains_count":      len(qr.rewriteChains),
		"max_iterations":    qr.config.MaxIterations,
		"quality_threshold": qr.config.QualityThreshold,
	}
}

// è¾…åŠ©å‡½æ•°å·²ç§»è‡³iterative_retriever.goä¸­é¿å…é‡å¤å®šä¹‰

type QueryRewriteLog struct {
	OriginalQuery       string           `json:"original_query"`
	FinalRewrittenQuery string           `json:"final_rewritten_query"`
	RewriteSteps        []RewriteStepLog `json:"rewrite_steps"`
	TotalIterations     int              `json:"total_iterations"`
	QualityImprovement  float64          `json:"quality_improvement"`
	ProcessingTime      time.Duration    `json:"processing_time"`
	Timestamp           time.Time        `json:"timestamp"`
}

type RewriteStepLog struct {
	Iteration     int                    `json:"iteration"`
	ChainName     string                 `json:"chain_name"`
	Priority      int                    `json:"priority"`
	InputQuery    string                 `json:"input_query"`
	OutputQuery   string                 `json:"output_query"`
	Changes       []string               `json:"changes"`
	QualityScore  float64                `json:"quality_score"`
	ExecutionTime time.Duration          `json:"execution_time"`
	Metadata      map[string]interface{} `json:"metadata"`
}

type QueryRewriteResult struct {
	OriginalQuery    string        `json:"original_query"`
	RewrittenQueries []string      `json:"rewritten_queries"`
	QualityScores    []float64     `json:"quality_scores"`
	FinalQuery       string        `json:"final_query"`
	TotalIterations  int           `json:"total_iterations"`
	ProcessingTime   time.Duration `json:"processing_time"`
}

func (qr *QueryRewriter) RewriteQuery(originalQuery string) (*QueryRewriteResult, error) {
	startTime := time.Now()
	log := &QueryRewriteLog{
		OriginalQuery: originalQuery,
		Timestamp:     startTime,
		RewriteSteps:  make([]RewriteStepLog, 0),
	}

	result := &QueryRewriteResult{
		OriginalQuery:    originalQuery,
		RewrittenQueries: []string{originalQuery},
		QualityScores:    []float64{0.0},
		TotalIterations:  0,
		ProcessingTime:   0,
	}

	currentQuery := originalQuery
	initialQuality := qr.calculateInitialQuality(originalQuery)

	for iteration := 1; iteration <= qr.config.MaxIterations; iteration++ {
		iterationImproved := false

		// æŒ‰ä¼˜å…ˆçº§æ‰§è¡Œæ”¹å†™é“¾
		chains := qr.getSortedChains()
		for _, chain := range chains {
			stepStartTime := time.Now()

			// è°ƒç”¨æ”¹å†™é“¾å¤„ç†æŸ¥è¯¢
			result, err := chain.Process(context.Background(), currentQuery, make(map[string]interface{}))
			if err != nil {
				continue
			}

			rewrittenQuery := result.RewrittenQuery

			// è®°å½•æ”¹å†™æ­¥éª¤
			stepLog := RewriteStepLog{
				Iteration:     iteration,
				ChainName:     reflect.TypeOf(chain).Elem().Name(),
				Priority:      chain.Priority(),
				InputQuery:    currentQuery,
				OutputQuery:   rewrittenQuery,
				Changes:       qr.extractChanges(currentQuery, rewrittenQuery),
				ExecutionTime: time.Since(stepStartTime),
				Metadata:      make(map[string]interface{}),
			}

			// è®¡ç®—è´¨é‡åˆ†æ•°
			if rewrittenQuery != currentQuery {
				stepLog.QualityScore = qr.calculateQueryQuality(rewrittenQuery)
				stepLog.Metadata["improvement"] = stepLog.QualityScore > qr.calculateQueryQuality(currentQuery)

				currentQuery = rewrittenQuery
				iterationImproved = true
			} else {
				stepLog.QualityScore = qr.calculateQueryQuality(currentQuery)
				stepLog.Metadata["improvement"] = false
			}

			log.RewriteSteps = append(log.RewriteSteps, stepLog)
		}

		// æ£€æŸ¥è´¨é‡é˜ˆå€¼
		currentQuality := qr.calculateQueryQuality(currentQuery)
		if currentQuality >= qr.config.QualityThreshold {
			break
		}

		// å¦‚æœæœ¬è½®æ²¡æœ‰æ”¹è¿›ï¼Œåœæ­¢è¿­ä»£
		if !iterationImproved {
			break
		}

		result.RewrittenQueries = append(result.RewrittenQueries, currentQuery)
		result.QualityScores = append(result.QualityScores, currentQuality)
	}

	// å®Œæˆæ—¥å¿—è®°å½•
	log.FinalRewrittenQuery = currentQuery
	log.TotalIterations = len(result.RewrittenQueries) - 1
	log.ProcessingTime = time.Since(startTime)
	log.QualityImprovement = qr.calculateQueryQuality(currentQuery) - initialQuality

	// è¾“å‡ºè¯¦ç»†æ—¥å¿—
	qr.printQueryRewriteComparison(log)

	result.FinalQuery = currentQuery
	result.TotalIterations = log.TotalIterations
	result.ProcessingTime = log.ProcessingTime

	return result, nil
}

func (qr *QueryRewriter) printQueryRewriteComparison(log *QueryRewriteLog) {
	fmt.Println("\n" + strings.Repeat("=", 100))
	fmt.Println("ğŸ” QUERY REWRITE ANALYSIS - æŸ¥è¯¢æ”¹å†™ä¼˜åŒ–åˆ†æ")
	fmt.Println(strings.Repeat("=", 100))

	// 1. åŸå§‹æŸ¥è¯¢ä¿¡æ¯
	fmt.Println("\nğŸ“ 1. ORIGINAL QUERY - ç”¨æˆ·åŸå§‹æé—®")
	fmt.Println(strings.Repeat("-", 80))
	fmt.Printf("åŸå§‹æŸ¥è¯¢: %s\n", log.OriginalQuery)
	fmt.Printf("æŸ¥è¯¢é•¿åº¦: %d å­—ç¬¦\n", len(log.OriginalQuery))
	fmt.Printf("å¤„ç†æ—¶é—´: %v\n", log.Timestamp.Format("2006-01-02 15:04:05"))

	// åˆ†æåŸå§‹æŸ¥è¯¢ç‰¹å¾
	originalFeatures := qr.analyzeQueryFeatures(log.OriginalQuery)
	fmt.Println("\nğŸ” åŸå§‹æŸ¥è¯¢ç‰¹å¾åˆ†æ:")
	for feature, value := range originalFeatures {
		fmt.Printf("  - %s: %v\n", feature, value)
	}

	// 2. æ”¹å†™è¿‡ç¨‹è¯¦æƒ…
	fmt.Println("\nâš™ï¸ 2. REWRITE PROCESS - æ”¹å†™è¿‡ç¨‹è¯¦æƒ…")
	fmt.Println(strings.Repeat("-", 80))

	if len(log.RewriteSteps) == 0 {
		fmt.Println("âŒ æœªæ‰§è¡Œä»»ä½•æ”¹å†™æ­¥éª¤")
	} else {
		for i, step := range log.RewriteSteps {
			fmt.Printf("\nğŸ”„ æ­¥éª¤ %d - %s (ä¼˜å…ˆçº§:%d)\n", i+1, step.ChainName, step.Priority)
			fmt.Printf("  è¾“å…¥: %s\n", step.InputQuery)
			fmt.Printf("  è¾“å‡º: %s\n", step.OutputQuery)
			fmt.Printf("  è´¨é‡åˆ†æ•°: %.3f\n", step.QualityScore)
			fmt.Printf("  æ‰§è¡Œæ—¶é—´: %v\n", step.ExecutionTime)

			if len(step.Changes) > 0 {
				fmt.Println("  å˜åŒ–è¯¦æƒ…:")
				for _, change := range step.Changes {
					fmt.Printf("    â€¢ %s\n", change)
				}
			}

			if improvement, exists := step.Metadata["improvement"].(bool); exists {
				if improvement {
					fmt.Println("  âœ… è´¨é‡æå‡")
				} else {
					fmt.Println("  âšª æ— æ˜æ˜¾æ”¹è¿›")
				}
			}
		}
	}

	// 3. æœ€ç»ˆæ”¹å†™ç»“æœ
	fmt.Println("\nğŸ¯ 3. FINAL REWRITTEN QUERY - æœ€ç»ˆæ”¹å†™ç»“æœ")
	fmt.Println(strings.Repeat("-", 80))
	fmt.Printf("æœ€ç»ˆæŸ¥è¯¢: %s\n", log.FinalRewrittenQuery)
	fmt.Printf("æŸ¥è¯¢é•¿åº¦: %d å­—ç¬¦\n", len(log.FinalRewrittenQuery))

	// åˆ†ææœ€ç»ˆæŸ¥è¯¢ç‰¹å¾
	finalFeatures := qr.analyzeQueryFeatures(log.FinalRewrittenQuery)
	fmt.Println("\nğŸ” æœ€ç»ˆæŸ¥è¯¢ç‰¹å¾åˆ†æ:")
	for feature, value := range finalFeatures {
		fmt.Printf("  - %s: %v\n", feature, value)
	}

	// 4. å¯¹æ¯”åˆ†æ
	fmt.Println("\nğŸ“Š 4. COMPARISON ANALYSIS - å¯¹æ¯”åˆ†æ")
	fmt.Println(strings.Repeat("-", 80))

	// é•¿åº¦å¯¹æ¯”
	lengthChange := len(log.FinalRewrittenQuery) - len(log.OriginalQuery)
	fmt.Printf("é•¿åº¦å˜åŒ–: %+d å­—ç¬¦", lengthChange)
	if lengthChange > 0 {
		fmt.Println(" (æ‰©å±•)")
	} else if lengthChange < 0 {
		fmt.Println(" (å‹ç¼©)")
	} else {
		fmt.Println(" (æ— å˜åŒ–)")
	}

	// è´¨é‡æå‡
	fmt.Printf("è´¨é‡æå‡: %+.3f", log.QualityImprovement)
	if log.QualityImprovement > 0 {
		fmt.Println(" âœ… (æ”¹è¿›)")
	} else if log.QualityImprovement < 0 {
		fmt.Println(" âŒ (é€€åŒ–)")
	} else {
		fmt.Println(" âšª (æ— å˜åŒ–)")
	}

	// è¿­ä»£ç»Ÿè®¡
	fmt.Printf("è¿­ä»£æ¬¡æ•°: %d\n", log.TotalIterations)
	fmt.Printf("æ€»å¤„ç†æ—¶é—´: %v\n", log.ProcessingTime)

	// è¯­ä¹‰ç›¸ä¼¼åº¦
	similarity := qr.calculateSemanticSimilarity(log.OriginalQuery, log.FinalRewrittenQuery)
	fmt.Printf("è¯­ä¹‰ç›¸ä¼¼åº¦: %.3f", similarity)
	if similarity > 0.8 {
		fmt.Println(" âœ… (é«˜åº¦ç›¸ä¼¼)")
	} else if similarity > 0.6 {
		fmt.Println(" âšª (ä¸­ç­‰ç›¸ä¼¼)")
	} else {
		fmt.Println(" âš ï¸ (ä½ç›¸ä¼¼åº¦)")
	}

	// 5. æ”¹å†™æ•ˆæœæ€»ç»“
	fmt.Println("\nğŸ“‹ 5. REWRITE EFFECTIVENESS - æ”¹å†™æ•ˆæœæ€»ç»“")
	fmt.Println(strings.Repeat("-", 80))

	effectiveness := qr.evaluateRewriteEffectiveness(log)
	fmt.Printf("æ•´ä½“è¯„ä»·: %s\n", effectiveness.Overall)
	fmt.Printf("è¯­ä¹‰ä¿æŒ: %s\n", effectiveness.SemanticPreservation)
	fmt.Printf("ä¿¡æ¯ä¸°å¯Œ: %s\n", effectiveness.InformationEnrichment)
	fmt.Printf("æ£€ç´¢å‹å¥½: %s\n", effectiveness.RetrievalFriendliness)

	if len(effectiveness.Recommendations) > 0 {
		fmt.Println("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
		for _, rec := range effectiveness.Recommendations {
			fmt.Printf("  â€¢ %s\n", rec)
		}
	}

	fmt.Println("\n" + strings.Repeat("=", 100))
}

func (qr *QueryRewriter) extractChanges(original, rewritten string) []string {
	changes := make([]string, 0)

	// ç®€å•çš„å˜åŒ–æ£€æµ‹
	if len(rewritten) > len(original) {
		changes = append(changes, fmt.Sprintf("æŸ¥è¯¢æ‰©å±•: +%då­—ç¬¦", len(rewritten)-len(original)))
	} else if len(rewritten) < len(original) {
		changes = append(changes, fmt.Sprintf("æŸ¥è¯¢å‹ç¼©: -%då­—ç¬¦", len(original)-len(rewritten)))
	}

	// æ£€æµ‹æ–°å¢çš„å…³é”®è¯
	originalWords := strings.Fields(strings.ToLower(original))
	rewrittenWords := strings.Fields(strings.ToLower(rewritten))

	originalSet := make(map[string]bool)
	for _, word := range originalWords {
		originalSet[word] = true
	}

	newWords := make([]string, 0)
	for _, word := range rewrittenWords {
		if !originalSet[word] && len(word) > 2 {
			newWords = append(newWords, word)
		}
	}

	if len(newWords) > 0 {
		changes = append(changes, fmt.Sprintf("æ–°å¢å…³é”®è¯: %s", strings.Join(newWords, ", ")))
	}

	return changes
}

func (qr *QueryRewriter) analyzeQueryFeatures(query string) map[string]interface{} {
	features := make(map[string]interface{})

	features["å­—ç¬¦æ•°"] = len(query)
	features["è¯æ±‡æ•°"] = len(strings.Fields(query))
	features["åŒ…å«æŠ€æœ¯æœ¯è¯­"] = qr.containsTechnicalTerms(query)
	features["åŒ…å«é—®å·"] = strings.Contains(query, "?") || strings.Contains(query, "ï¼Ÿ")
	features["åŒ…å«ç‰¹æ®Šç¬¦å·"] = qr.containsSpecialChars(query)
	features["è¯­è¨€ç±»å‹"] = qr.detectLanguage(query)

	return features
}

func (qr *QueryRewriter) calculateSemanticSimilarity(query1, query2 string) float64 {
	// ç®€å•çš„è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®— (å®é™…é¡¹ç›®ä¸­åº”ä½¿ç”¨æ›´sophisticatedçš„æ–¹æ³•)
	words1 := strings.Fields(strings.ToLower(query1))
	words2 := strings.Fields(strings.ToLower(query2))

	set1 := make(map[string]bool)
	for _, word := range words1 {
		set1[word] = true
	}

	common := 0
	for _, word := range words2 {
		if set1[word] {
			common++
		}
	}

	total := len(set1)
	for _, word := range words2 {
		if !set1[word] {
			total++
		}
	}

	if total == 0 {
		return 1.0
	}

	return float64(common) / float64(total)
}

type RewriteEffectiveness struct {
	Overall               string   `json:"overall"`
	SemanticPreservation  string   `json:"semantic_preservation"`
	InformationEnrichment string   `json:"information_enrichment"`
	RetrievalFriendliness string   `json:"retrieval_friendliness"`
	Recommendations       []string `json:"recommendations"`
}

func (qr *QueryRewriter) evaluateRewriteEffectiveness(log *QueryRewriteLog) RewriteEffectiveness {
	effectiveness := RewriteEffectiveness{
		Recommendations: make([]string, 0),
	}

	// æ•´ä½“è¯„ä»·
	if log.QualityImprovement > 0.1 {
		effectiveness.Overall = "ä¼˜ç§€ âœ…"
	} else if log.QualityImprovement > 0 {
		effectiveness.Overall = "è‰¯å¥½ âšª"
	} else {
		effectiveness.Overall = "éœ€æ”¹è¿› âš ï¸"
		effectiveness.Recommendations = append(effectiveness.Recommendations, "è€ƒè™‘è°ƒæ•´æ”¹å†™ç­–ç•¥å‚æ•°")
	}

	// è¯­ä¹‰ä¿æŒè¯„ä»·
	similarity := qr.calculateSemanticSimilarity(log.OriginalQuery, log.FinalRewrittenQuery)
	if similarity > 0.8 {
		effectiveness.SemanticPreservation = "ä¼˜ç§€ âœ…"
	} else if similarity > 0.6 {
		effectiveness.SemanticPreservation = "è‰¯å¥½ âšª"
	} else {
		effectiveness.SemanticPreservation = "éœ€æ³¨æ„ âš ï¸"
		effectiveness.Recommendations = append(effectiveness.Recommendations, "æ”¹å†™å¯èƒ½åç¦»åŸå§‹æ„å›¾ï¼Œéœ€è¦è°ƒä¼˜")
	}

	// ä¿¡æ¯ä¸°å¯Œåº¦è¯„ä»·
	lengthIncrease := len(log.FinalRewrittenQuery) - len(log.OriginalQuery)
	if lengthIncrease > 20 {
		effectiveness.InformationEnrichment = "ä¸°å¯Œ âœ…"
	} else if lengthIncrease > 0 {
		effectiveness.InformationEnrichment = "é€‚ä¸­ âšª"
	} else {
		effectiveness.InformationEnrichment = "ç®€åŒ– âšª"
	}

	// æ£€ç´¢å‹å¥½åº¦è¯„ä»·
	if qr.containsTechnicalTerms(log.FinalRewrittenQuery) && len(strings.Fields(log.FinalRewrittenQuery)) > 3 {
		effectiveness.RetrievalFriendliness = "ä¼˜ç§€ âœ…"
	} else {
		effectiveness.RetrievalFriendliness = "ä¸€èˆ¬ âšª"
		effectiveness.Recommendations = append(effectiveness.Recommendations, "å¯ä»¥è¿›ä¸€æ­¥ä¸°å¯ŒæŠ€æœ¯å…³é”®è¯")
	}

	return effectiveness
}

func (qr *QueryRewriter) containsTechnicalTerms(query string) bool {
	technicalTerms := []string{
		"api", "æ•°æ®åº“", "ç®—æ³•", "æ¡†æ¶", "æ¶æ„", "python", "java", "go", "react", "vue",
		"docker", "kubernetes", "mysql", "redis", "nginx", "linux", "git", "http",
		"json", "xml", "rest", "grpc", "å¾®æœåŠ¡", "åˆ†å¸ƒå¼", "ç¼“å­˜", "æ¶ˆæ¯é˜Ÿåˆ—",
	}

	queryLower := strings.ToLower(query)
	for _, term := range technicalTerms {
		if strings.Contains(queryLower, term) {
			return true
		}
	}
	return false
}

func (qr *QueryRewriter) containsSpecialChars(query string) bool {
	specialChars := []string{"@", "#", "$", "%", "&", "*", "(", ")", "[", "]", "{", "}"}
	for _, char := range specialChars {
		if strings.Contains(query, char) {
			return true
		}
	}
	return false
}

func (qr *QueryRewriter) detectLanguage(query string) string {
	// ç®€å•çš„è¯­è¨€æ£€æµ‹
	chineseCount := 0
	englishCount := 0

	for _, r := range query {
		if r >= 0x4e00 && r <= 0x9fff {
			chineseCount++
		} else if (r >= 'a' && r <= 'z') || (r >= 'A' && r <= 'Z') {
			englishCount++
		}
	}

	if chineseCount > englishCount {
		return "ä¸­æ–‡"
	} else if englishCount > chineseCount {
		return "è‹±æ–‡"
	} else {
		return "æ··åˆ"
	}
}

func (qr *QueryRewriter) calculateInitialQuality(query string) float64 {
	// ç®€å•çš„åˆå§‹è´¨é‡è®¡ç®—
	score := 0.0

	// é•¿åº¦åˆ†æ•°
	if len(query) > 10 && len(query) < 200 {
		score += 0.3
	}

	// æŠ€æœ¯æœ¯è¯­åˆ†æ•°
	if qr.containsTechnicalTerms(query) {
		score += 0.4
	}

	// è¯æ±‡ä¸°å¯Œåº¦åˆ†æ•°
	words := strings.Fields(query)
	if len(words) > 3 {
		score += 0.3
	}

	return score
}

func (qr *QueryRewriter) calculateQueryQuality(query string) float64 {
	// æ›´è¯¦ç»†çš„è´¨é‡è®¡ç®—é€»è¾‘
	score := qr.calculateInitialQuality(query)

	// å¯ä»¥æ·»åŠ æ›´å¤šè´¨é‡è¯„ä¼°ç»´åº¦
	// å¦‚è¯­æ³•æ­£ç¡®æ€§ã€è¯­ä¹‰æ¸…æ™°åº¦ç­‰

	return score
}

func (qr *QueryRewriter) getSortedChains() []RewriteChain {
	// è¿”å›å·²é…ç½®çš„æ”¹å†™é“¾ï¼Œå®ƒä»¬å·²ç»æŒ‰ä¼˜å…ˆçº§æ’åº
	return qr.rewriteChains
}
