package aliyun

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io/ioutil"
	"log"
	"net/http"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"
)

// BatchEmbeddingService æ‰¹é‡embeddingæœåŠ¡
// åŸºäºé˜¿é‡Œäº‘text-embedding-async-v1æ¨¡å‹å®ç°å¼‚æ­¥æ‰¹å¤„ç†
type BatchEmbeddingService struct {
	APIEndpoint string // æ‰¹é‡embedding APIç«¯ç‚¹
	APIKey      string // APIå¯†é’¥
	TaskQueue   *TaskQueue
	Worker      *AsyncWorker
	client      *http.Client
}

// BatchEmbeddingRequest æ‰¹é‡embeddingè¯·æ±‚
type BatchEmbeddingRequest struct {
	Model string `json:"model"` // text-embedding-async-v1
	Input struct {
		URL string `json:"url"` // æ–‡ä»¶URLï¼ŒæŒ‡å‘åŒ…å«æ–‡æœ¬çš„JSONæ–‡ä»¶
	} `json:"input"`
	Parameters struct {
		TextType string `json:"text_type,omitempty"` // queryæˆ–document
	} `json:"parameters,omitempty"`
}

// BatchEmbeddingResponse æ‰¹é‡embeddingå“åº”
type BatchEmbeddingResponse struct {
	Output struct {
		TaskID     string `json:"task_id"`
		TaskStatus string `json:"task_status"`
	} `json:"output"`
	Usage struct {
		TotalTokens int `json:"total_tokens"`
	} `json:"usage"`
	RequestID string `json:"request_id"`
}

// BatchTaskStatus æ‰¹é‡ä»»åŠ¡çŠ¶æ€
type BatchTaskStatus struct {
	Output struct {
		TaskID     string `json:"task_id"`
		TaskStatus string `json:"task_status"` // PENDING, RUNNING, COMPLETED, FAILED
		Result     struct {
			Embeddings []struct {
				TextIndex int       `json:"text_index"`
				Embedding []float32 `json:"embedding"`
			} `json:"embeddings"`
		} `json:"result,omitempty"`
		Usage struct {
			TotalTokens int `json:"total_tokens"`
		} `json:"usage,omitempty"`
	} `json:"output"`
	RequestID string `json:"request_id"`
}

// BatchTask æ‰¹é‡ä»»åŠ¡
type BatchTask struct {
	TaskID     string                 `json:"task_id"`
	Texts      []string               `json:"texts"`
	SubmitTime time.Time              `json:"submit_time"`
	Status     string                 `json:"status"`      // PENDING, RUNNING, COMPLETED, FAILED
	RetryCount int                    `json:"retry_count"` // é‡è¯•æ¬¡æ•°
	Callback   func(TaskResult) error `json:"-"`           // å›è°ƒå‡½æ•°
	UserData   map[string]interface{} `json:"user_data"`   // ç”¨æˆ·è‡ªå®šä¹‰æ•°æ®
}

// TaskResult ä»»åŠ¡ç»“æœ
type TaskResult struct {
	TaskID      string                 `json:"task_id"`
	Status      string                 `json:"status"`
	Embeddings  [][]float32            `json:"embeddings,omitempty"`
	Error       string                 `json:"error,omitempty"`
	Texts       []string               `json:"texts"`
	UserData    map[string]interface{} `json:"user_data,omitempty"`
	ProcessTime time.Duration          `json:"process_time"`
}

// TaskQueue ä»»åŠ¡é˜Ÿåˆ—
type TaskQueue struct {
	tasks chan *BatchTask
	mutex sync.RWMutex
	size  int
}

// AsyncWorker å¼‚æ­¥worker
type AsyncWorker struct {
	service      *BatchEmbeddingService
	pollInterval time.Duration
	maxRetries   int
	ctx          context.Context
	cancel       context.CancelFunc
	running      bool
	runningMutex sync.RWMutex
}

// NewBatchEmbeddingService åˆ›å»ºæ–°çš„æ‰¹é‡embeddingæœåŠ¡
func NewBatchEmbeddingService(apiEndpoint, apiKey string, queueSize int) *BatchEmbeddingService {
	service := &BatchEmbeddingService{
		APIEndpoint: apiEndpoint,
		APIKey:      apiKey,
		TaskQueue:   NewTaskQueue(queueSize),
		client: &http.Client{
			Timeout: 30 * time.Second,
		},
	}

	// åˆ›å»ºå¼‚æ­¥worker
	service.Worker = NewAsyncWorker(service, 5*time.Second, 3)

	log.Printf("[æ‰¹é‡Embedding] æœåŠ¡åˆå§‹åŒ–å®Œæˆ, APIç«¯ç‚¹: %s, é˜Ÿåˆ—å¤§å°: %d", apiEndpoint, queueSize)
	return service
}

// NewTaskQueue åˆ›å»ºæ–°çš„ä»»åŠ¡é˜Ÿåˆ—
func NewTaskQueue(size int) *TaskQueue {
	return &TaskQueue{
		tasks: make(chan *BatchTask, size),
		size:  size,
	}
}

// createTextFile åˆ›å»ºåŒ…å«æ–‡æœ¬çš„ä¸´æ—¶JSONæ–‡ä»¶
func (s *BatchEmbeddingService) createTextFile(texts []string) (string, error) {
	// æ ¹æ®é˜¿é‡Œäº‘æ–‡æ¡£ï¼Œæ–‡ä»¶æ ¼å¼åº”è¯¥æ˜¯JSONæ•°ç»„
	// åˆ›å»ºåŒ…å«æ‰€æœ‰æ–‡æœ¬çš„JSONç»“æ„
	textData := map[string]interface{}{
		"inputs": texts,
	}

	// åºåˆ—åŒ–ä¸ºJSON
	jsonData, err := json.MarshalIndent(textData, "", "  ")
	if err != nil {
		return "", fmt.Errorf("åºåˆ—åŒ–æ–‡æœ¬æ•°æ®å¤±è´¥: %w", err)
	}

	// åˆ›å»ºä¸´æ—¶æ–‡ä»¶
	tempDir := "./data/temp"
	os.MkdirAll(tempDir, 0755)

	fileName := fmt.Sprintf("batch_texts_%d.json", time.Now().UnixNano())
	filePath := filepath.Join(tempDir, fileName)

	err = ioutil.WriteFile(filePath, jsonData, 0644)
	if err != nil {
		return "", fmt.Errorf("å†™å…¥æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// è¿”å›æ–‡ä»¶çš„HTTP URL
	// æ³¨æ„ï¼šå®é™…é¡¹ç›®ä¸­ï¼Œè¿™é‡Œåº”è¯¥è¿”å›ä¸€ä¸ªå…¬ç½‘å¯è®¿é—®çš„URL
	// è¿™é‡Œæˆ‘ä»¬å…ˆè¿”å›æœ¬åœ°è·¯å¾„ï¼Œéœ€è¦é…ç½®æ–‡ä»¶æœåŠ¡å™¨
	fileURL := fmt.Sprintf("http://localhost:8088/temp/%s", fileName)
	log.Printf("[æ‰¹é‡Embedding] åˆ›å»ºæ–‡æœ¬æ–‡ä»¶: %s", fileURL)

	return fileURL, nil
}

// NewAsyncWorker åˆ›å»ºæ–°çš„å¼‚æ­¥worker
func NewAsyncWorker(service *BatchEmbeddingService, pollInterval time.Duration, maxRetries int) *AsyncWorker {
	ctx, cancel := context.WithCancel(context.Background())
	return &AsyncWorker{
		service:      service,
		pollInterval: pollInterval,
		maxRetries:   maxRetries,
		ctx:          ctx,
		cancel:       cancel,
		running:      false,
	}
}

// SubmitBatchTask æäº¤æ‰¹é‡embeddingä»»åŠ¡
func (s *BatchEmbeddingService) SubmitBatchTask(fileURL string, callback func(TaskResult) error, userData map[string]interface{}) (string, error) {
	if fileURL == "" {
		return "", fmt.Errorf("æ–‡ä»¶URLä¸èƒ½ä¸ºç©º")
	}

	// ç®€å•éªŒè¯URLæ ¼å¼
	if !strings.HasPrefix(fileURL, "http://") && !strings.HasPrefix(fileURL, "https://") {
		return "", fmt.Errorf("æ–‡ä»¶URLå¿…é¡»æ˜¯æœ‰æ•ˆçš„HTTP/HTTPSåœ°å€")
	}

	log.Printf("[æ‰¹é‡Embedding] æäº¤æ‰¹é‡ä»»åŠ¡, æ–‡ä»¶URL: %s", fileURL)

	// æ„å»ºè¯·æ±‚
	req := BatchEmbeddingRequest{
		Model: "text-embedding-async-v1",
	}
	req.Input.URL = fileURL
	req.Parameters.TextType = "query" // ä½¿ç”¨queryç±»å‹ï¼Œä¸æˆåŠŸç¤ºä¾‹ä¿æŒä¸€è‡´

	// åºåˆ—åŒ–è¯·æ±‚
	reqBody, err := json.Marshal(req)
	if err != nil {
		return "", fmt.Errorf("åºåˆ—åŒ–è¯·æ±‚å¤±è´¥: %w", err)
	}

	// åˆ›å»ºHTTPè¯·æ±‚
	httpReq, err := http.NewRequest("POST", s.APIEndpoint, bytes.NewBuffer(reqBody))
	if err != nil {
		return "", fmt.Errorf("åˆ›å»ºHTTPè¯·æ±‚å¤±è´¥: %w", err)
	}

	// è®¾ç½®è¯·æ±‚å¤´
	httpReq.Header.Set("Content-Type", "application/json")
	httpReq.Header.Set("Authorization", "Bearer "+s.APIKey)
	httpReq.Header.Set("X-DashScope-Async", "enable") // ğŸ”¥ å…³é”®: å¯ç”¨å¼‚æ­¥æ¨¡å¼

	log.Printf("[æ‰¹é‡Embedding] å‘é€æ‰¹é‡embeddingè¯·æ±‚: %s", s.APIEndpoint)
	log.Printf("[æ‰¹é‡Embedding] è¯·æ±‚å¤´: Content-Type=%s, Authorization=Bearer %s..., X-DashScope-Async=%s",
		httpReq.Header.Get("Content-Type"),
		s.APIKey[:10]+"***",
		httpReq.Header.Get("X-DashScope-Async"))
	log.Printf("[æ‰¹é‡Embedding] è¯·æ±‚ä½“: %s", string(reqBody))

	// å‘é€è¯·æ±‚
	resp, err := s.client.Do(httpReq)
	if err != nil {
		return "", fmt.Errorf("APIè¯·æ±‚å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	// è¯»å–å“åº”
	respBody, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		return "", fmt.Errorf("è¯»å–å“åº”å¤±è´¥: %w", err)
	}

	// æ£€æŸ¥çŠ¶æ€ç 
	if resp.StatusCode != http.StatusOK {
		log.Printf("[æ‰¹é‡Embedding] APIè¿”å›é”™è¯¯çŠ¶æ€ç : %d, å“åº”: %s", resp.StatusCode, string(respBody))
		return "", fmt.Errorf("APIè¿”å›é”™è¯¯çŠ¶æ€ç : %d, å“åº”: %s", resp.StatusCode, string(respBody))
	}

	// è§£æå“åº”
	var batchResp BatchEmbeddingResponse
	if err := json.Unmarshal(respBody, &batchResp); err != nil {
		return "", fmt.Errorf("è§£æå“åº”å¤±è´¥: %w, å“åº”å†…å®¹: %s", err, string(respBody))
	}

	taskID := batchResp.Output.TaskID
	if taskID == "" {
		return "", fmt.Errorf("APIæœªè¿”å›æœ‰æ•ˆçš„task_id")
	}

	log.Printf("[æ‰¹é‡Embedding] ä»»åŠ¡æäº¤æˆåŠŸ, task_id: %s, çŠ¶æ€: %s", taskID, batchResp.Output.TaskStatus)

	// åˆ›å»ºæ‰¹é‡ä»»åŠ¡å¯¹è±¡
	task := &BatchTask{
		TaskID:     taskID,
		Texts:      []string{}, // ç°åœ¨ä½¿ç”¨æ–‡ä»¶URLï¼Œä¸å­˜å‚¨å…·ä½“æ–‡æœ¬
		SubmitTime: time.Now(),
		Status:     batchResp.Output.TaskStatus,
		RetryCount: 0,
		Callback:   callback,
		UserData:   userData,
	}

	// å°†æ–‡ä»¶URLå­˜å‚¨åœ¨UserDataä¸­
	if task.UserData == nil {
		task.UserData = make(map[string]interface{})
	}
	task.UserData["source_file_url"] = fileURL

	// å°†ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—
	select {
	case s.TaskQueue.tasks <- task:
		log.Printf("[æ‰¹é‡Embedding] ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—: %s", taskID)
	default:
		return "", fmt.Errorf("ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡ï¼Œæ— æ³•åŠ å…¥æ–°ä»»åŠ¡")
	}

	return taskID, nil
}

// QueryTaskStatus æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
func (s *BatchEmbeddingService) QueryTaskStatus(taskID string) (*BatchTaskStatus, error) {
	url := fmt.Sprintf("https://dashscope.aliyuncs.com/api/v1/tasks/%s", taskID)

	// åˆ›å»ºHTTPè¯·æ±‚
	req, err := http.NewRequest("GET", url, nil)
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºHTTPè¯·æ±‚å¤±è´¥: %w", err)
	}

	// è®¾ç½®è¯·æ±‚å¤´
	req.Header.Set("Authorization", "Bearer "+s.APIKey)

	log.Printf("[æ‰¹é‡Embedding] æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€: %s", taskID)

	// å‘é€è¯·æ±‚
	resp, err := s.client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("APIè¯·æ±‚å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	// è¯»å–å“åº”
	respBody, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–å“åº”å¤±è´¥: %w", err)
	}

	// æ£€æŸ¥çŠ¶æ€ç 
	if resp.StatusCode != http.StatusOK {
		log.Printf("[æ‰¹é‡Embedding] æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: %d, å“åº”: %s", resp.StatusCode, string(respBody))
		return nil, fmt.Errorf("æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: %d, å“åº”: %s", resp.StatusCode, string(respBody))
	}

	// è§£æå“åº”
	var status BatchTaskStatus
	if err := json.Unmarshal(respBody, &status); err != nil {
		return nil, fmt.Errorf("è§£æå“åº”å¤±è´¥: %w, å“åº”å†…å®¹: %s", err, string(respBody))
	}

	log.Printf("[æ‰¹é‡Embedding] ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢æˆåŠŸ: %s, çŠ¶æ€: %s", taskID, status.Output.TaskStatus)

	return &status, nil
}

// StartWorker å¯åŠ¨å¼‚æ­¥worker
func (s *BatchEmbeddingService) StartWorker() error {
	return s.Worker.Start()
}

// StopWorker åœæ­¢å¼‚æ­¥worker
func (s *BatchEmbeddingService) StopWorker() error {
	return s.Worker.Stop()
}

// Start å¯åŠ¨å¼‚æ­¥worker
func (w *AsyncWorker) Start() error {
	w.runningMutex.Lock()
	defer w.runningMutex.Unlock()

	if w.running {
		return fmt.Errorf("workerå·²åœ¨è¿è¡Œä¸­")
	}

	w.running = true
	log.Printf("[å¼‚æ­¥Worker] å¯åŠ¨worker, è½®è¯¢é—´éš”: %v, æœ€å¤§é‡è¯•æ¬¡æ•°: %d", w.pollInterval, w.maxRetries)

	// å¯åŠ¨worker goroutine
	go w.run()

	return nil
}

// Stop åœæ­¢å¼‚æ­¥worker
func (w *AsyncWorker) Stop() error {
	w.runningMutex.Lock()
	defer w.runningMutex.Unlock()

	if !w.running {
		return nil
	}

	log.Printf("[å¼‚æ­¥Worker] åœæ­¢worker")
	w.cancel()
	w.running = false

	return nil
}

// run workerä¸»å¾ªç¯
func (w *AsyncWorker) run() {
	ticker := time.NewTicker(w.pollInterval)
	defer ticker.Stop()

	log.Printf("[å¼‚æ­¥Worker] Workerå¼€å§‹è¿è¡Œ")

	for {
		select {
		case <-w.ctx.Done():
			log.Printf("[å¼‚æ­¥Worker] Workeræ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡º")
			return

		case <-ticker.C:
			// æ£€æŸ¥é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
			w.processQueuedTasks()

		case task := <-w.service.TaskQueue.tasks:
			// å¤„ç†æ–°åŠ å…¥çš„ä»»åŠ¡
			if task != nil {
				w.processTask(task)
			}
		}
	}
}

// processQueuedTasks å¤„ç†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
func (w *AsyncWorker) processQueuedTasks() {
	// éé˜»å¡åœ°æ£€æŸ¥é˜Ÿåˆ—
	select {
	case task := <-w.service.TaskQueue.tasks:
		if task != nil {
			w.processTask(task)
		}
	default:
		// é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­è½®è¯¢
	}
}

// processTask å¤„ç†å•ä¸ªä»»åŠ¡
func (w *AsyncWorker) processTask(task *BatchTask) {
	log.Printf("[å¼‚æ­¥Worker] å¼€å§‹å¤„ç†ä»»åŠ¡: %s, çŠ¶æ€: %s", task.TaskID, task.Status)

	startTime := time.Now()

	// æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
	status, err := w.service.QueryTaskStatus(task.TaskID)
	if err != nil {
		log.Printf("[å¼‚æ­¥Worker] æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: %s, é”™è¯¯: %v", task.TaskID, err)
		w.handleTaskError(task, err, startTime)
		return
	}

	// æ›´æ–°ä»»åŠ¡çŠ¶æ€
	task.Status = status.Output.TaskStatus

	switch status.Output.TaskStatus {
	case "COMPLETED":
		// ä»»åŠ¡å®Œæˆï¼Œå¤„ç†ç»“æœ
		w.handleTaskCompleted(task, status, startTime)

	case "FAILED":
		// ä»»åŠ¡å¤±è´¥
		w.handleTaskFailed(task, "ä»»åŠ¡æ‰§è¡Œå¤±è´¥", startTime)

	case "PENDING", "RUNNING":
		// ä»»åŠ¡ä»åœ¨å¤„ç†ä¸­ï¼Œé‡æ–°åŠ å…¥é˜Ÿåˆ—
		log.Printf("[å¼‚æ­¥Worker] ä»»åŠ¡ä»åœ¨å¤„ç†ä¸­: %s, çŠ¶æ€: %s, é‡æ–°åŠ å…¥é˜Ÿåˆ—", task.TaskID, status.Output.TaskStatus)
		select {
		case w.service.TaskQueue.tasks <- task:
			// æˆåŠŸé‡æ–°åŠ å…¥é˜Ÿåˆ—
		default:
			log.Printf("[å¼‚æ­¥Worker] é˜Ÿåˆ—å·²æ»¡ï¼Œä»»åŠ¡ %s æ— æ³•é‡æ–°åŠ å…¥é˜Ÿåˆ—", task.TaskID)
		}

	default:
		log.Printf("[å¼‚æ­¥Worker] æœªçŸ¥ä»»åŠ¡çŠ¶æ€: %s, ä»»åŠ¡: %s", status.Output.TaskStatus, task.TaskID)
		w.handleTaskError(task, fmt.Errorf("æœªçŸ¥ä»»åŠ¡çŠ¶æ€: %s", status.Output.TaskStatus), startTime)
	}
}

// handleTaskCompleted å¤„ç†ä»»åŠ¡å®Œæˆ
func (w *AsyncWorker) handleTaskCompleted(task *BatchTask, status *BatchTaskStatus, startTime time.Time) {
	log.Printf("[å¼‚æ­¥Worker] ä»»åŠ¡å®Œæˆ: %s, embeddingæ•°é‡: %d", task.TaskID, len(status.Output.Result.Embeddings))

	// æå–embeddingç»“æœ
	embeddings := make([][]float32, len(task.Texts))
	for _, emb := range status.Output.Result.Embeddings {
		if emb.TextIndex >= 0 && emb.TextIndex < len(embeddings) {
			embeddings[emb.TextIndex] = emb.Embedding
		}
	}

	// æ„å»ºä»»åŠ¡ç»“æœ
	result := TaskResult{
		TaskID:      task.TaskID,
		Status:      "COMPLETED",
		Embeddings:  embeddings,
		Texts:       task.Texts,
		UserData:    task.UserData,
		ProcessTime: time.Since(startTime),
	}

	// è°ƒç”¨å›è°ƒå‡½æ•°
	if task.Callback != nil {
		if err := task.Callback(result); err != nil {
			log.Printf("[å¼‚æ­¥Worker] å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: %s, é”™è¯¯: %v", task.TaskID, err)
		} else {
			log.Printf("[å¼‚æ­¥Worker] ä»»åŠ¡å›è°ƒæ‰§è¡ŒæˆåŠŸ: %s", task.TaskID)
		}
	}
}

// handleTaskFailed å¤„ç†ä»»åŠ¡å¤±è´¥
func (w *AsyncWorker) handleTaskFailed(task *BatchTask, errorMsg string, startTime time.Time) {
	log.Printf("[å¼‚æ­¥Worker] ä»»åŠ¡å¤±è´¥: %s, é”™è¯¯: %s", task.TaskID, errorMsg)

	// æ„å»ºä»»åŠ¡ç»“æœ
	result := TaskResult{
		TaskID:      task.TaskID,
		Status:      "FAILED",
		Error:       errorMsg,
		Texts:       task.Texts,
		UserData:    task.UserData,
		ProcessTime: time.Since(startTime),
	}

	// è°ƒç”¨å›è°ƒå‡½æ•°
	if task.Callback != nil {
		if err := task.Callback(result); err != nil {
			log.Printf("[å¼‚æ­¥Worker] å¤±è´¥ä»»åŠ¡å›è°ƒæ‰§è¡Œå¤±è´¥: %s, é”™è¯¯: %v", task.TaskID, err)
		}
	}
}

// handleTaskError å¤„ç†ä»»åŠ¡é”™è¯¯ï¼ˆé‡è¯•é€»è¾‘ï¼‰
func (w *AsyncWorker) handleTaskError(task *BatchTask, err error, startTime time.Time) {
	task.RetryCount++

	if task.RetryCount <= w.maxRetries {
		// æŒ‡æ•°é€€é¿ç­–ç•¥ï¼š2^retryCount ç§’ (2, 4, 8, 16, 32...)
		retryDelay := time.Duration(1<<uint(task.RetryCount)) * time.Second
		log.Printf("[å¼‚æ­¥Worker] ä»»åŠ¡é”™è¯¯ï¼Œå°è¯•é‡è¯•: %s, é‡è¯•æ¬¡æ•°: %d/%d, å»¶è¿Ÿ: %v",
			task.TaskID, task.RetryCount, w.maxRetries, retryDelay)

		// æŒ‡æ•°é€€é¿å»¶è¿Ÿåé‡æ–°åŠ å…¥é˜Ÿåˆ—
		time.AfterFunc(retryDelay, func() {
			select {
			case w.service.TaskQueue.tasks <- task:
				log.Printf("[å¼‚æ­¥Worker] ä»»åŠ¡é‡æ–°åŠ å…¥é˜Ÿåˆ—æˆåŠŸ: %s (å»¶è¿Ÿ %v)", task.TaskID, retryDelay)
			default:
				log.Printf("[å¼‚æ­¥Worker] é˜Ÿåˆ—å·²æ»¡ï¼Œä»»åŠ¡ %s é‡è¯•å¤±è´¥", task.TaskID)
			}
		})
	} else {
		log.Printf("[å¼‚æ­¥Worker] ä»»åŠ¡é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œæ ‡è®°ä¸ºå¤±è´¥: %s", task.TaskID)
		w.handleTaskFailed(task, fmt.Sprintf("é‡è¯•æ¬¡æ•°è¾¾åˆ°ä¸Šé™: %v", err), startTime)
	}
}

// GetQueueStatus è·å–é˜Ÿåˆ—çŠ¶æ€
func (s *BatchEmbeddingService) GetQueueStatus() map[string]interface{} {
	return map[string]interface{}{
		"queue_capacity": cap(s.TaskQueue.tasks),
		"queue_length":   len(s.TaskQueue.tasks),
		"worker_running": s.Worker.running,
	}
}
